{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# IN3063 Course work -  The Street View House Numbers (SVHN) Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of X_training is:  (32, 32, 3, 73257)\n",
      "Shape of y_training is:  (73257, 1)\n",
      "Shape of X_test is:  (32, 32, 3, 26032)\n",
      "Shape of y_test is:  (26032, 1)\n"
     ]
    }
   ],
   "source": [
    "import scipy.io\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Import to a python dictionary\n",
    "matTraining = scipy.io.loadmat('./train_32x32.mat')\n",
    "matTest = scipy.io.loadmat('./test_32x32.mat')\n",
    "\n",
    "X_training = matTraining.get(\"X\")\n",
    "y_training = matTraining.get(\"y\")\n",
    "\n",
    "\n",
    "X_test = matTest.get(\"X\")\n",
    "y_test = matTest.get(\"y\")\n",
    "\n",
    "print(\"Shape of X_training is: \", X_training.shape)\n",
    "print(\"Shape of y_training is: \", y_training.shape)\n",
    "print(\"Shape of X_test is: \", X_test.shape)\n",
    "print(\"Shape of y_test is: \", y_test.shape)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [9],\n",
       "       [2],\n",
       "       ...,\n",
       "       [1],\n",
       "       [6],\n",
       "       [9]], dtype=uint8)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_training[:200]\n",
    "y_training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing\n",
    "Load the dataset into X and y and check the dimensions\n",
    "The X_training is having 73257 samples of images with 32x32x3 pixels.\n",
    "The X_test is having 26032 samples of images with 32x32x3 pixels.\n",
    "The y_training is having the shape (73257,) with values of 1-10\n",
    "The y_test is having the shape (26032,) with values of 1-10\n",
    "\n",
    "\n",
    "**We will preprocess these by** \n",
    "    \n",
    "    1. Remove the color column with shape  (3,) \n",
    "    1.2 Convert the y values to a range of [0,8] instead of [1,9] for evaluation of the training to be easier.\n",
    "\n",
    "    2. Reshape the Training data to (73257, 1024)\n",
    "    3. Display images from training set\n",
    "    4. Hot encode the y sets\n",
    "    5. Visualize the y-distrubution\n",
    "    6. Scale the X and y sets to have values between [0.1,0.99]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 1 - drop the color column - convert y-values to [0,9]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import numpy\n",
    "numpy.set_printoptions(threshold=sys.maxsize)\n",
    "\n",
    "##\n",
    "X_training = X_training[:,:,0,:] #remove color Training\n",
    "X_test = X_test[:,:,0,:] #remove color Test\n",
    "\n",
    "\n",
    "y_training = y_training -1\n",
    "y_test = y_test -1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 2 - reshape the training sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Run only once\n",
    "\n",
    "X_training_new = []\n",
    "X_test_new = []\n",
    "\n",
    "\n",
    "for i in np.arange(73257):\n",
    "    reshaped = X_training[:,:,i].reshape(1024)\n",
    "    X_training_new.append(reshaped)\n",
    "    \n",
    "for i in np.arange(26032):\n",
    "    reshaped = X_test[:,:,i].reshape(1024)\n",
    "    X_test_new.append(reshaped)\n",
    "    \n",
    "X_training = np.array(X_training_new)\n",
    "\n",
    "X_test = np.array(X_test_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "new shape of X_training:  (73257, 1024)\n",
      "new shape of X_test:  (73257, 1024)\n"
     ]
    }
   ],
   "source": [
    "print(\"new shape of X_training: \", X_training.shape)\n",
    "print(\"new shape of X_test: \", X_training.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 3 - Display images from training set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(73257, 1024)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1440x288 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(20,4))\n",
    "print(X_training.shape)\n",
    "images = X_training #first 5 images in training set\n",
    "\n",
    "\n",
    "fig, ax = plt.subplots(1,10, figsize=(20,10))\n",
    "for i in np.arange(10):\n",
    "    actual = (y_training[i,:][0]) +1\n",
    "    ax[i].set_title(\"Label:{}\".format(actual))\n",
    "    #ax[i].imshow(X_training[i].reshape(32,32))\n",
    "   \n",
    "    ax[i].imshow(X_training[i].reshape(32,32))\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**As seen below there is a much more complex and noisy data set than the MNIST.**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 4 -  One hot encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "One hot encode: \n",
      " [[1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 1. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 1. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 0. 0. 0. 0. 0. 0. 1. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [0. 0. 1. 0. 0. 0. 0. 0. 0. 0.]\n",
      " [1. 0. 0. 0. 0. 0. 0. 0. 0. 0.]]\n",
      "labels: \n",
      " [[0]\n",
      " [8]\n",
      " [1]\n",
      " [2]\n",
      " [1]\n",
      " [4]\n",
      " [8]\n",
      " [2]\n",
      " [2]\n",
      " [0]]\n"
     ]
    }
   ],
   "source": [
    "a = np.arange(0,10,1)\n",
    "\n",
    "y_training_one_hot = (a==y_training).astype(float)\n",
    "y_test_one_hot = (a==y_test).astype(float)\n",
    "print(\"One hot encode: \\n\", y_training_one_hot[:10])\n",
    "print(\"labels: \\n\",y_training[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing 5 - visualize y distrubtuion\n",
    "We have moved all the y values one step to the left so the real value is (+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "valuesTraining, countsTraining = np.unique(y_training, return_counts=True)\n",
    "valuesTest, countsTest = np.unique(y_test, return_counts=True)\n",
    "\n",
    "\n",
    "fig, ax=plt.subplots(1,2, figsize=(15,5))\n",
    "\n",
    "ax[0].set_title(\"Training y-values distrubtion\")\n",
    "ax[0].bar(valuesTraining, countsTraining)\n",
    "ax[0].set_xticks(valuesTraining)\n",
    "\n",
    "\n",
    "ax[1].set_title(\"Test y-values distrubtion\")\n",
    "ax[1].bar(valuesTest, countsTest)\n",
    "ax[1].set_xticks(valuesTest)\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale X\n",
    "We scale the features to a values betweeen [0.01, 0.99] because if an activation is 0 and the derivative of the cost with respect to a weight is dependent on the activation the gradient will prevent a weight update. We are describing the back-propogation in later section, where we see why it is like that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,\n",
       "         13,  14,  15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,\n",
       "         26,  27,  28,  29,  30,  31,  32,  33,  34,  35,  36,  37,  38,\n",
       "         39,  40,  41,  42,  43,  44,  45,  46,  47,  48,  49,  50,  51,\n",
       "         52,  53,  54,  55,  56,  57,  58,  59,  60,  61,  62,  63,  64,\n",
       "         65,  66,  67,  68,  69,  70,  71,  72,  73,  74,  75,  76,  77,\n",
       "         78,  79,  80,  81,  82,  83,  84,  85,  86,  87,  88,  89,  90,\n",
       "         91,  92,  93,  94,  95,  96,  97,  98,  99, 100, 101, 102, 103,\n",
       "        104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116,\n",
       "        117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129,\n",
       "        130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142,\n",
       "        143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155,\n",
       "        156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "        169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181,\n",
       "        182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194,\n",
       "        195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207,\n",
       "        208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220,\n",
       "        221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233,\n",
       "        234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246,\n",
       "        247, 248, 249, 250, 251, 252, 253, 254, 255], dtype=uint8),\n",
       " array([ 14684,  11734,  12957,  15290,  17899,  21937,  26454,  31490,\n",
       "         36005,  41095,  46822,  53225,  59239,  66573,  73550,  81374,\n",
       "         89187,  97919, 105599, 113124, 121123, 129716, 137731, 146834,\n",
       "        154448, 163363, 172322, 180783, 189799, 198245, 205798, 215100,\n",
       "        222680, 231673, 240907, 249264, 258353, 265789, 275598, 282685,\n",
       "        290000, 296434, 304806, 312987, 320571, 327186, 334198, 341851,\n",
       "        347944, 355401, 363536, 369313, 378284, 382692, 389143, 394029,\n",
       "        401231, 406681, 412627, 417612, 423608, 427992, 432222, 438505,\n",
       "        444408, 448334, 454156, 459006, 463616, 466892, 472717, 478482,\n",
       "        484793, 485980, 492519, 496491, 502988, 506279, 509565, 513840,\n",
       "        519084, 522749, 526726, 528703, 533030, 536161, 539170, 543252,\n",
       "        546351, 549600, 551621, 554507, 554609, 556017, 558433, 559689,\n",
       "        561005, 563450, 564192, 564258, 565809, 563848, 564805, 565384,\n",
       "        564114, 562746, 561862, 561589, 560074, 557186, 555885, 554019,\n",
       "        553494, 550891, 547134, 545226, 543939, 540514, 540841, 537765,\n",
       "        534671, 531028, 528120, 524905, 523690, 519891, 518429, 514489,\n",
       "        512490, 510221, 507252, 498512, 495343, 492703, 486731, 480080,\n",
       "        476083, 471560, 465780, 460515, 454926, 450698, 445181, 441503,\n",
       "        437315, 431932, 426225, 418997, 414507, 408612, 401753, 397470,\n",
       "        392555, 385717, 379675, 372879, 366225, 359828, 353077, 344537,\n",
       "        338601, 330888, 324276, 318689, 312031, 305611, 300874, 295268,\n",
       "        289868, 282738, 276053, 268748, 261548, 254630, 249400, 242985,\n",
       "        237777, 233985, 228901, 225018, 218623, 213747, 206678, 202332,\n",
       "        198337, 191929, 188858, 183792, 179382, 174927, 169067, 165162,\n",
       "        162325, 158722, 155848, 150533, 148419, 145539, 143284, 141264,\n",
       "        137453, 133537, 131879, 128924, 127967, 125110, 121674, 119093,\n",
       "        116818, 115555, 111593, 108071, 103433, 101934,  98357,  96638,\n",
       "         94771,  91624,  89767,  87041,  83796,  80555,  78858,  76481,\n",
       "         75338,  72380,  70738,  68497,  66045,  66310,  63851,  60699,\n",
       "         58937,  57390,  56219,  53462,  50950,  48749,  47744,  46839,\n",
       "         46705,  46245,  44407,  42518,  42361,  41612,  40130,  38745,\n",
       "         37308,  35858,  36165,  33611,  30532,  31721,  36954,  55438]))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(X_training, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "max: 0.99\n",
      "minimum:  0.01\n"
     ]
    }
   ],
   "source": [
    "fac = 0.98 / 255\n",
    "add_fac = 0.01\n",
    "X_training_scaled =  np.asfarray(X_training) * fac + add_fac\n",
    "X_test_scaled =  np.asfarray(X_test) *fac + add_fac\n",
    "\n",
    "\n",
    "print(\"max:\", np.max(X_training_scaled))\n",
    "print(\"minimum: \", np.min(X_training_scaled))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rescale y one hot to 0.01 and 0.99\n",
    "we are saving the unscaled version"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_training_one_hot_unscaled = y_training_one_hot.copy()\n",
    "y_test_one_hot_unscaled = y_test_one_hot.copy()\n",
    "\n",
    "\n",
    "\n",
    "y_training_one_hot[y_training_one_hot==0] = 0.01\n",
    "y_training_one_hot[y_training_one_hot==1] = 0.99\n",
    "y_test_one_hot[y_test_one_hot==0] = 0.01\n",
    "y_test_one_hot[y_test_one_hot==1] = 0.99"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      " [0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.99 0.01]\n",
      " [0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      " [0.01 0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01]\n",
      " [0.01 0.99 0.01 0.01 0.01 0.01 0.01 0.01 0.01 0.01]]\n",
      "[[0]\n",
      " [8]\n",
      " [1]\n",
      " [2]\n",
      " [1]]\n"
     ]
    }
   ],
   "source": [
    "print(y_training_one_hot[:5])\n",
    "print(y_training[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************\n",
    "## Task 1: Implementing linear and ReLu layers\n",
    "forward and backward passess for linear layers and ReLU activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining activation functions linear, sigmoid and ReLU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe464b84ba8>]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "testInput = np.arange(-6,6,0.1)\n",
    "@np.vectorize\n",
    "def linear(x):\n",
    "    return x\n",
    "\n",
    "plt.title(\"Linear\")\n",
    "plt.plot(testInput, linear(testInput))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sigmoid\n",
    "\n",
    "$$ \\frac {1} {1+e^-x}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe464e2b390>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA2oAAAE/CAYAAAA39zBmAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3yV9d3/8dcnO0CYIYGwNwmEJUNFEJChqCh14GqLra211Xpbb2+9e7dq7U9rW1tbq3Vbbd2jKirKUFFAZO+9IYwMICEhZJ7v749zoAECCZDkOufk/Xw88iA55xrvc4B8z+f6jsucc4iIiIiIiEjwiPA6gIiIiIiIiBxLhZqIiIiIiEiQUaEmIiIiIiISZFSoiYiIiIiIBBkVaiIiIiIiIkFGhZqIiIiIiEiQUaEmNcLMbjSz6cF2XjObZWa31EGOT83s+7V07AIz61wLx+1hZkvNLN/Mfl7Txz/FedsHXlNkXZ1TRCTc1fd2+LhzrjazEbVwXLVfUqdUqEm1mdkFZvaNmeWZ2X4zm2tmgwCcc68558bWdSYvzmtmD5rZq8fluMQ590oNHPuEBs0518g5t+Vsj12J/wFmOecSnHNP1MLxATCzbWY2+sjPzrkdgddUXlvnFBEJR+HWDgfa09LABcN8M9tgZk+aWeuzzNTLOTfrbI4RyKf2SzylQk2qxcwaAx8DfwOaA22A3wDFXuaSs9IBWO11CBERqVoYt8NvOecS8L+miUArYPGZFGtmFlXT4US8pEJNqqs7gHPuDedcuXPusHNuunNuBYCZTTazOUc2NrOxZrY+cNXv72b21ZGeosC2c83scTPLNbMtZnZ+4PGdZpZVcRihmTUxs3+aWbaZbTezX5lZxEnOO8bM1gXO+yRgJ3tBZjbYzOYFMuwJXMWLqfB8LzObEbhqmWlmvzSzi4FfApMCwx+WB7adZWa3mFls4Hi9KxynpZkdNrMkM2tmZh8HXsuBwPdtA9s9DAwDngwc+8nA487Mulb3vTCzxwLH3mpml5zktX8BjKxwru7H9+ZV8t46M/uJmW0MHP8pM7MKz//IzNYGroquMbMBZvYvoD3wUeA8/2NmHQPHigrsl2JmUwLv8yYz+1GFYz5oZm8HXnO++YezDDzZ36mISBgLu3a4IudcqXNuNTAJyAburnDMy8xsWSDrN2bWp8Jz28zsXjNbARwys6jAY6MD7cthM2teYfv+ZpZjZtFm1sXMvjCzfYHHXjOzpoHtTtl+mdl1Zrao4msws7vMbErg+9hAe7zD/J8hnjGz+Oq8FyJHqFCT6toAlJvZK2Z2iZk1O9mGZpYIvAv8L9ACWA+cf9xmQ4AVgedfB94EBgFdgZvwFxCNAtv+DWgCdAYuBL4H3HyS874H/ApIBDYDQ0/xmsqBuwLbngdcBPw0cKwEYCbwGZASyPW5c+4z4BH8VwAbOef6Vjygc64Y+DdwfYWHrwW+cs5l4f8/9w/8vVntgcPAk4F9/w+YDdweOPbtlWSu6r0Ygv/9TgT+ALxYsZiqkHPUcefacIr3qaLL8P899Q28rnEAZnYN8GAgT2NgArDPOfddYAdweeA8f6jkmG8AGfjf56uBR8zsogrPT8D/76MpMIXA+yUiUs+EYzt8gsCwwg/xX7jEzAYALwG3BrI+C0wxs9gKu10PXAo0dc6VVTjWbmAecFWFbW8A3nXOleIvIn+Hv/1JBdrhb8uoRvs1BehhZt2OO/brge9/j7+47of/PW0D3H8674WICjWpFufcQeACwAHPA9mBXpDkSjYfD6x2zv078AvzCWDvcdtsdc79I/AL+S38vxwfcs4VO+emAyVAV/NP2J0E/K9zLt85tw34E/Ddk5x3jXPuyC/gv1Ry3oqvabFz7lvnXFnguM/ib4DAX5Dsdc79yTlXFDj3/Krep4DXObZQO/qL2zm3zzn3nnOu0DmXDzxc4ZynVM33Yrtz7vnA+/oK0Bqo7O/oTD3qnMt1zu0AvsTfAAHcAvzBObfQ+W1yzm2vxmtqh//f1b2B93kZ8MJxr2mOc25q4DX9C3+RKCJSr4RjO3wKu/EPhQT4EfCsc25+oCfxFfzDPc+tsP0TzrmdzrnDlRzraJscuHB5Hf9pkzc552YEXnM28Geq2SY75wrxF5RHjt0N6Im/iLRA7rucc/sD7f0jgXOLVJsKNak259xa59xk51xboDf+K1B/qWTTFGBnhf0c/h6TijIrfH84sN3xjzXCf0UuBqj4oX87/itT1Tnvzkq2A8D8w/0+NrO9ZnYQ/y/RxMDT7fBfCTwTXwDxZjbEzDrgL2beD5yzgZk9Gxg6chD4Gmhq1VtBqjrvxdEGMdCIgP99rCkVG9zCCsc+0/crBTjSiB1x0tcUOGecaR6CiNRD4dYOn0IbYH/g+w7A3YFhj7lmlou/zUmpsP2pzvEucJ6ZpQDD8Re6swHMPyXhTTPbFWiTX+U/nwOqo+KF2RuADwJtb0ugAf65dkcyfxZ4XKTaVKjJGXHOrQNext9QHG8P0PbID4ErS20r2a46coBS/L+oj2gP7DrJedsdd952lWx3xNPAOqCbc64x/rlnR4YJ7gS6nGQ/d6rAzjkf8Db+X943AB9XKETuBnoAQwLnHH4kbjWOfTrvxZk4hL9hOaLVaex7pu/XbqB5YKjpETX5mkREwlKYtMMnCMx9u5xAMYW/fXnYOde0wlcD59wbFXY7aTvjnMsFpuMfrn8D8EaggAT/sEcH9Am0yTdx7Jy6U7b3geMmmlk//G3+kWGPOfgL3V4VMjdxztXkhVOpB1SoSbWYWU8zu9v+s/BFO/y/lL6tZPNPgHQzuzLQ8/EzTu9D/1GBIRlvAw+bWUKgh+oX+K96VXbeXmb2ncB5f17FeROAg0CBmfUEbqvw3MdAKzP7r8CE4AQzGxJ4LhPoGGhMTuZ1/ENFbuQ/v7iPnPMwkBuY3PzAcftl4p8DcILTfC/OxDLgO4Fev67AD09j3xeA/zazc8yvayAfnPo17QS+AX5nZnHmnyD+Q+C1M38ZIiLhJ0zb4aPMv7hHKv55y63wD0ME/zDPnwRGqZiZNTSzS4+7wFeV1/HPq7uKE9vkAvxtchvgnuP2O2n7BRAYVvou8Ef8QzVnBB73BXI/bmZJgdfXxszGnUZmERVqUm35+CcezzezQ/gbhlVUWJXpCOdcDnAN/sUs9gFpwCLOfAnhO/D39mwB5uD/JfvSKc77aOC83YC5pzjuf+O/upaP/xfqWxWOlQ+MwX9Vby+wEf8qiQDvBP7cZ2ZLKjtwYD7bIfxDMz6t8NRfgHj8V9u+xT8UoqK/Alebf1XFyu5tVq334gw9jn9OQib++W3VLpacc+/gn2/3Ov738wP+M7/gd8CvAsM//ruS3a8HOuLvXXsfeMA5N+MMX4OISLgKx3YYAqsoA7n4F+jYB5wTWAgE59wi/PO9ngQOAJuAyaeZf0ogS6ZzbnmFx38DDADy8BeZ/z5uv6raL/C/F6OBd1yFhUyAewNZvw0Mq5yJf0SNSLXZf3p/RWpHoOcpA7jROfel13lERETqE7XDIqFJPWpSK8xsnJk1DSyfe2TuV2XDM0RERKSGqR0WCX0q1KS2nId/FcAc/MMHrzzJsrkiIiJS89QOi4Q4DX0UEREREREJMupRExERERERCTIq1ERERERERIJMlFcnTkxMdB07dvTq9CIiUocWL16c45xr6XWOUKE2UkSkfjhV++hZodaxY0cWLVrk1elFRKQOmdl2rzOEErWRIiL1w6naRw19FBERERERCTIq1ERERERERIKMCjUREREREZEg49kctcqUlpaSkZFBUVGR11EkhMTFxdG2bVuio6O9jiIiIiIiUiOCqlDLyMggISGBjh07YmZex5EQ4Jxj3759ZGRk0KlTJ6/jiIiIiIjUiKAa+lhUVESLFi1UpEm1mRktWrRQL6yIiIiIhJUqCzUze8nMssxs1UmeNzN7wsw2mdkKMxtwNoFUpMnp0r8ZEREREQk31elRexm4+BTPXwJ0C3z9GHj67GN56+GHH6ZXr1706dOHfv36MX/+fG655RbWrFlTq+cdP348ubm5Jzz+4IMP8thjj9XquUVE5OTM7GIzWx+4KHlfJc//wszWBC5Yfm5mHSo8V25mywJfU+o2uYiIhKoq56g55742s46n2OQK4J/OOQd8a2ZNzay1c25PDWWsU/PmzePjjz9myZIlxMbGkpOTQ0lJCS+88EKtn3vq1Km1fg4RETk9ZhYJPAWMATKAhWY2xTlX8erdUmCgc67QzG4D/gBMCjx32DnXr05Di4hIyKuJxUTaADsr/JwReCwkC7U9e/aQmJhIbGwsAImJiQCMGDGCxx57jIEDB/Liiy/y+9//npSUFLp160ZsbCxPPvkkkydPJj4+nnXr1rF9+3b+8Y9/8MorrzBv3jyGDBnCyy+/DMAbb7zBI488gnOOSy+9lN///vcAdOzYkUWLFpGYmMjDDz/MP//5T9q1a0fLli0555xzPHk/RCQ8OOcoKfdRVOqjuLSc4jIfRYE/i8t8lJT5KCkP/Fnmo7Tc/3O5z3H94PZex/faYGCTc24LgJm9if8i5dFCzTn3ZYXtvwVuqtOEIiHuUHEZK3flkXmwiF4pjemc2IiICE1tkPqtJgq1yv4XuUo3NPsx/uGRtG8fnA3/2LFjeeihh+jevTujR49m0qRJXHjhhUef3717N7/97W9ZsmQJCQkJjBo1ir59+x59/sCBA3zxxRdMmTKFyy+/nLlz5/LCCy8waNAgli1bRlJSEvfeey+LFy+mWbNmjB07lg8++IArr7zy6DEWL17Mm2++ydKlSykrK2PAgAEq1ETqIZ/PkV9URt7hUvIOl3KwqJSDh0vJLyojv7iMgqIyCopLKSgu51BxGYUlZRwqLqewtJzC4jIOl5ZzuKScw6XlFJWW46v0N/OpRRgq1Cq/IDnkFNv/EPi0ws9xZrYIKAMedc59UNlOodBGitQk5xwfrdjD07M2s37vwWN+RyXERXFB10R+OT6Vds0beBdSxEM1UahlAO0q/NwW2F3Zhs6554DnAAYOHHjKjwy/+Wg1a3YfrIF4/5GW0pgHLu91ym0aNWrE4sWLmT17Nl9++SWTJk3i0UcfPfr8ggULuPDCC2nevDkA11xzDRs2bDj6/OWXX46ZkZ6eTnJyMunp6QD06tWLbdu2sX37dkaMGEHLli0BuPHGG/n666+PKdRmz57NxIkTadDA/4tpwoQJNfMGiIjn8otKycovJvNgEdn5xewrKCGnwP/nvkMlHCgs4UDgz7zDpVUWV/HRkTSMjaJRbCTxMf4/m8RH07pxHA1iIomPiSQuOpL4aP/3sVERxEX7/4yNjiQuKoKYwFdsVAQxkZFHf46ONGIiI3DO1fdFe07nguRNwEDgwgoPt3fO7TazzsAXZrbSObf5hAOeRhspEup25R7m1x+s4ot1WaS2bsztI7vSr31TWjWOZ9XuPJbuyGXKsl3MWp/N3WO7M/n8jkRFBtVi5SK1riYKtSnA7YGhIEOAvFCdn3ZEZGQkI0aMYMSIEaSnp/PKK68cfc4/Fe/kjgyZjIiIOPr9kZ/LysqIiqreW17PPxSJhCSfz7H3YBE79xey88Bhdh04zK7cQnbnFrEn7zB784o4VFJ+wn5REUbzhjE0bxhDi0YxpKY0plmDaJo1iKFJfPTRr8bx0TSOi6ZxfBQJsdE0jI3UB5e6Ua0LkmY2Gvg/4ELnXPGRx51zuwN/bjGzWUB/4IRCTaS+mLsphx//cxE+B7++LI3J53ckssIwx7SUxlw7sB13jOrK/R+u4v99spZpq/fyj5sH0yg2qG4BLFKrqvzXbmZvACOARDPLAB4AogGcc88AU4HxwCagELi5JoJV1fNVW9avX09ERATdunUDYNmyZXTo0IFVq/x3Jxg8eDB33XUXBw4cICEhgffee+9or1l1DBkyhDvvvJOcnByaNWvGG2+8wR133HHMNsOHD2fy5Mncd999lJWV8dFHH3HrrbfW3IsUkbNysKiUjZkFbM72f23JPsS2nENs319ISZnvmG1bJsSS0jSe7skJDO/eklaN40huHEfLhFiSEmJJbBRLk/hozcUIbguBbmbWCdgFXAfcUHEDM+sPPAtc7JzLqvB4M6DQOVdsZonAUPwLjYjUS4u27eeWVxbRoUUDnv/ewFMOa0xpGs/z3xvI+0t3cc+7K/jhywt5+ebBxMdE1mFiEe9UZ9XH66t43gE/q7FEHisoKOCOO+4gNzeXqKgounbtynPPPcfVV18NQJs2bfjlL3/JkCFDSElJIS0tjSZNmlT7+K1bt+Z3v/sdI0eOxDnH+PHjueKKK47ZZsCAAUyaNIl+/frRoUMHhg0bVqOvUUSqxznHjv2FrN59kNW781i7J5/1e/PZlXv46DYxkRF0aNGAjokNGdkzifbNG9C+eQPaNW9AStM4YqP0gSLUOefKzOx2YBoQCbzknFttZg8Bi5xzU4A/Ao2AdwIjInY45yYAqcCzZubDf0ucR49bLVKk3liZkcfN/1hI6yZx/OuHQ2iZEFvlPmbGdwa0JTLC+K+3lnHba4t57rsDiYnSaAIJf1bVUL7aMnDgQLdo0aJjHlu7di2pqame5DkdBQUFNGrUiLKyMiZOnMgPfvADJk6c6HWsei1U/u1IcMs7XMqSHQdYuv0AS3fmsiIjj7zDpYB/eGLXpEb0aJVAj1YJdE9KoGtSI9o2i9fww2ows8XOuYFe5wgVlbWRIqFs5/5CJjw5hwYxUbzzk/NIaRp/2sd4c8EO7vv3Sq7ol8JfJvXTNBEJC6dqHzXQ9ww8+OCDzJw5k6KiIsaOHXvMQiAiEjpyC0v4dst+vt2yj2+37GN9Zj7O+Vc67NGqMePTW9GnbVN6pzShW3Ij4qLVOyYicrrKfY6731lOabnj1VuGnFGRBnDd4PZk5Rfz5xkbGNGjJRP7t63hpCLBRYXaGXjssce8jiAiZ8DncyzLyOWr9dl8tSGb5Rm5OOdfOXFgx2aMT2/NwA7N6NuuKQ01YV1EpEa8OGcLC7bu549X96FTYsOzOtbPRnbl6w3Z3P/hagZ3akGbMyz6REKBPomISFgrLitnzsYcpq/O5PN1meQUlBBh0LddU34+qhsXdEukb9ummu8gIlIL1u45yGPTNjCuVzJXn3P2PWCREcafr+3HJX/9mv9+ezmv3TJEizFJ2FKhJiJhp6zcx+xNOXy0fDczVmeSX1xGQmwUI3omMTo1iQu7t6RpgxivY4qIhLXSch93vbWMxvHRPDIxvcbmlLVv0YD7L0/j3vdW8vI32/jBBZ1q5LgiwUaFmoiEjfV783ln0U4+WLabnIJiGsdFcXHvVozv05qhXRLVayYiUofeWLCDdXvzefa759CiUdUrPJ6Oawe249NVe3l8xgau7N+G5g118U3Cjwo1EQlpRaXlfLJiD68v2MHi7QeIjjRG9kjiqnPaMrJHkoozEREPHCwq5S8zN3Je5xaMTUuu8eObGb+6NJVxf5nNE59v5MEJ3tx/V6Q26RPMcSIjI+nXrx+9evWib9++/PnPf8bn81W943HOP//8Mzr/tm3beP3114/+vGjRIn7+85+f0bGq6/rrr6dPnz48/vjjVW5bF3mmTJnCo48+WulzjRo1qtVzS+jIOljEn6av57zffc7d7yznwKESfnVpKvN/OZrnvjeQcb1aqUgTEfHIM7M2s/9QCf93aWqtLaPfNSmB6wa149Vvt7M151CtnEPES+pRO058fDzLli0DICsrixtuuIG8vDx+85vfVGv/8vJyIiMj+eabb87o/EcKtRtuuAGAgQMHMnBg7d16aO/evXzzzTds3769WtvXdh6ACRMmMGHChFo9h4SurTmHeHrWJt5fuosyn2N0ajI3n9+R87q00D11RESCwK7cw7w4Zyvf6d+G3m2a1Oq5/mt0dz5Yuovff7qOZ757Tq2eS6Su6XLzKSQlJfHcc8/x5JNP4pyjvLyce+65h0GDBtGnTx+effZZAGbNmsXIkSO54YYbSE9PB/7T8zNp0iSmTp169JiTJ0/mvffeY9u2bQwbNowBAwYwYMCAo4Xdfffdx+zZs+nXrx+PP/44s2bN4rLLLsPn89GxY0dyc3OPHqtr165kZmaSnZ3NVVddxaBBgxg0aBBz58494bUUFRVx8803k56eTv/+/fnyyy8BGDt2LFlZWfTr14/Zs2cfs88777xD79696du3L8OHDz/6Wi+77DIAsrOzGTNmDAMGDODWW2+lQ4cO5OTksG3bNnr27Mktt9xC7969ufHGG5k5cyZDhw6lW7duLFiwAID9+/dz5ZVX0qdPH84991xWrFgBwMsvv8ztt98OwNatWznvvPMYNGgQv/71r8/mr1NC3KasfH7+xlIu+tMsPly2m+sHt+fLu0fw/PcGcn7XRBVpIiJB4k/T1uOAu8f1qPVztUyI5ScXduGz1XtZuG1/rZ9PpC6pUKtC586d8fl8ZGVl8eKLL9KkSRMWLlzIwoULef7559m6dSsACxYs4OGHH2bNmjXH7H/dddfx1ltvAVBSUsLnn3/O+PHjSUpKYsaMGSxZsoS33nrr6HDCRx99lGHDhrFs2TLuuuuuo8eJiIjgiiuu4P333wdg/vz5dOzYkeTkZO68807uuusuFi5cyHvvvcctt9xywut46qmnAFi5ciVvvPEG3//+9ykqKmLKlCl06dKFZcuWMWzYsGP2eeihh5g2bRrLly9nypQpJxzzN7/5DaNGjWLJkiVMnDiRHTt2HH1u06ZN3HnnnaxYsYJ169bx+uuvM2fOHB577DEeeeQRAB544AH69+/PihUreOSRR/je9753wjnuvPNObrvtNhYuXEirVq2q+NuScLRzfyH//c5yxj7+NZ+vzeRHwzsz595RPHRFbzqe5f14RESkZm3OLuD9Zbu4eWjHOrvH2S3DOpPcOJbHZ2yok/OJ1JXgHfr46X2wd2XNHrNVOlxS+dynU3HOATB9+nRWrFjBu+++C0BeXh4bN24kJiaGwYMH06nTicvDXnLJJfz85z+nuLiYzz77jOHDhxMfH09eXh633347y5YtIzIykg0bqv7lMmnSJB566CFuvvlm3nzzTSZNmgTAzJkzjykQDx48SH5+PgkJCUcfmzNnDnfccQcAPXv2pEOHDmzYsIHGjRuf9HxDhw5l8uTJXHvttXznO9854fk5c+YcLRwvvvhimjVrdvS5Tp06He1d7NWrFxdddBFmRnp6Otu2bTu6/3vvvQfAqFGj2LdvH3l5ececY+7cuUe3+e53v8u9995b5fsk4eFgUSl/+3wjL3+zDTPjB0M78dORXbWyl4hIEHvuqy3EREbwo2Gd6+yc8TGR/GhYZ/7fJ2tZtjOXfu2a1tm5RWpT8BZqQWLLli1ERkaSlJSEc46//e1vjBs37phtZs2aRcOGlV/Zj4uLY8SIEUybNo233nqL66+/HoDHH3+c5ORkli9fjs/nIy4ursos5513Hps2bSI7O5sPPviAX/3qVwD4fD7mzZtHfPzJr1wdKTZPxzPPPMP8+fP55JNP6Nev39G5e9U5Zmzsf5bhjYiIOPpzREQEZWVlJ92/suFrGtJWv5T7HG8t3Mmfpq9nf2EJVw9oy11jupNSR1dmRUTkzOzNK+LfSzO4fnB7Emt4Of6qXDe4PX/7YhPPzNqsuWoSNoK3UDuDnq+alp2dzU9+8hNuv/12zIxx48bx9NNPM2rUKKKjo9mwYQNt2rSp8jjXXXcdL7zwAosWLeLll18G/L1xbdu2JSIigldeeYXy8nIAEhISyM/Pr/Q4ZsbEiRP5xS9+QWpqKi1atAD888yefPJJ7rnnHgCWLVtGv379jtl3+PDhvPbaa4waNYoNGzawY8cOevTowZ49e06ae/PmzQwZMoQhQ4bw0UcfsXPnzmOev+CCC3j77be59957mT59OgcOHKjyvags069//WtmzZpFYmLiCT18Q4cO5c033+Smm27itddeO63jS+hZvTuPX/57Jcsz8hjcsTmvXJ5W6xPRRUSkZrw4Zws+R532ph3RKDaK753XgSe/3MSmrAK6JmmVaAl9mqN2nMOHDx9dnn/06NGMHTuWBx54AIBbbrmFtLQ0BgwYQO/evbn11luP9g6dytixY/n6668ZPXo0MTH+YVs//elPeeWVVzj33HPZsGHD0R65Pn36EBUVRd++fStdLn/SpEm8+uqrR4c9AjzxxBMsWrSIPn36kJaWxjPPPHPCfj/96U8pLy8nPT2dSZMm8fLLLx/T61WZe+65h/T0dHr37s3w4cPp27fvMc8/8MADTJ8+nQEDBvDpp5/SunXrY4ZbVuXBBx88mvu+++7jlVdeOWGbv/71rzz11FMMGjTohGGREj4Ol5Tz8CdrmPDkXHblHuav1/XjrVvPVZEmIhIicgtLeH3+Di7v05p2zRt4kmHy+R2JjYrgua83e3J+kZpmZzIkriYMHDjQLVq06JjH1q5dS2pqqid55PQVFxcTGRlJVFQU8+bN47bbbjtheGRd0b+d0LV4+wH++53lbM05xPWD23Hfxak0aRDtdSypYWa22DlXu/f2CCOVtZEiwexvn2/kTzM28Omdw0htffL577XtgQ9X8fqCHXz9PyNp3URD5iX4nap9DN6hjxL0duzYwbXXXovP5yMmJobnn3/e60gSQkrKfPx5xgae+3ozrZvE8/otQzi/a6LXsURE5DQVl5Xz8jfbGNGjpadFGvhXgHx1/g5e/mYb/3uJLuBKaFOhJmesW7duLF261OsYEoJ27CvkjjeWsDwjj0kD2/Gry1JJiFMvmohIKPps1V72HSrh5qEnrn5d19o1b8CY1GTeXriTu0Z3Jy460utIImdMc9REpE59vGI3lz4xm605h3jmpgH8/uo+KtJERELYq99up0OLBgwLklER3z2vAwcKS/l01ckXTBMJBUFXqHk1Z05Cl/7NhIaych+//XgNt7++lG7Jjfjk58O4uHdrr2OJiMhZWLf3IAu3HeCmIR2IiAiO2+mc36UFnRMb8uq3O7yOInJWgqpQi4uLY9++ffrgLdXmnGPfvn3Vug+deGdfQTHffXEBL87ZyuTzO/LWred5tiqYiIjUnLzFPgsAACAASURBVFe/3U5MVARXn9PW6yhHmRk3ntuBxdsPsGb3Qa/jiJyxoJqj1rZtWzIyMsjOzvY6ioSQuLg42rYNngZCjrUhM5+b/7GQ7IJi/nRNX64KosZcRETOXEFxGe8v2cXlfVJo1jDG6zjHuHpAW/44bR2vzt/OIxPTvY4jckaCqlCLjo6mUyfvJ6KKSM2YszGH215dTFxMJO/+5Dz6tG3qdSQREakh7y/dxaGScm46t73XUU7QpEE0l/dJ4YOlu/jfS3pqLrSEpKAa+igi4eOdRTuZ/I8FpDSN54OfDVWRJiISZl6fv4NeKY3p1y44f79/97wOFJaU88Gy3V5HETkjKtREpMY9+9Vm7nl3Bed2bsE7t51Hm6a66aiISDhZvTuPtXsOct2gdpgFxyIix+vTtik9WyXw7uIMr6OInBEVaiJSY5xz/OGzdfzu03Vc2qc1L00eRGMNNxERCTvvLd5FTGQEl/dN8TrKKV19TluW78xlU1a+11FETpsKNRGpET6f4/4PV/P3WZu5fnB7nriuPzFR+hUjIhJuSst9fLhsF6PTkmjaILgWETneFf3aEBlhvLt4l9dRRE6bPkWJyFlzznH/lFX869vt3Dq8M49M7E1kkNxPR0REatas9dnsO1QSVEvyn0zLhFhG9mjJ+0szKPfp9k8SWlSoichZcc7x6w9X8eq3O7j1ws7cd0nPoJ2vICIiZ+/dxTtJbBTL8G4tvY5SLVcNaEvmwWLmbMrxOorIaVGhJiJnzDnHbz5a4y/ShnfmvotVpImIhLP9h0r4Yl0WE/unEBUZGh8jR6Um0bRBNO9pUREJMaHxP0xEgtJfZm7k5W+28cMLOqknTUSkHpiybBel5Y6rQmDY4xGxUZFM6JvCtNV7yTtc6nUckWpToSYiZ+Qfc7fy1883cu3Atvzq0lQVaSIi9cD7S3fRK6UxPVs19jrKablqQFuKy3x8tmqP11FEqk2Fmoictg+W7uI3H61hXK9kHpmYriJNRKQe2JZziOUZeVzRL7iX5K9Mn7ZN6NiiAVOW6+bXEjpUqInIaZm3eR/3vLuc8zq34K/X9Q+ZOQoiInJ2Pl7hL3Iu6xN6hZqZMaFvCvM27yMrv8jrOCLVok9YIlJtm7LyufVfi+jYoiHPfPcc4qIjvY4kIiJ1ZMry3Qzq2IyUpvFeRzkjl/dNwedg6goNf5TQoEJNRKolO7+Yyf9YSExUJC9NHkST+GivI4mISB1ZvzefDZkFTOgber1pR3RLTqBnqwQ+UqEmIUKFmohUqbisnJ+8upicgmJe/P5A2jVv4HUkERGpQ1OW7yIywrgkvbXXUc7KhH4pLN5+gIwDhV5HEamSCjUROSXnHA9OWc3i7Qd47Jq+9G3X1OtIIiJSh5xzfLR8D+d3aUFio1iv45yVywPz6z5arl41CX4q1ETklF6dv4M3FuzkZyO7hOQEchEROTvLM/LYsb+Qy0N42OMR7Zo3oH/7pnyk1R8lBKhQE5GTWrB1P7+ZsppRPZO4e0wPr+OIiIgHPlq+m5jICMb1auV1lBpxeZ8U1uw5yKasAq+jiJySCjURqVR2fjG3v76Eds0b8Jfr+hERoXuliYjUN845Pl25h2HdEsNmEalL+/jn2enm1xLsqlWomdnFZrbezDaZ2X2VPN/ezL40s6VmtsLMxtd8VBGpK+U+x3+9tZS8w6X8/cYBNI4Lj8ZZ5ExVox38hZmtCbSBn5tZhwrPfd/MNga+vl+3yUXOzvKMPHbnFTE+xBcRqSi5cRwDOzRj6sq9XkcROaUqCzUziwSeAi4B0oDrzSztuM1+BbztnOsPXAf8vaaDikjd+evnG5m7aR+/vaI3qa0bex1HxFPVbAeXAgOdc32Ad4E/BPZtDjwADAEGAw+YWbO6yi5ytj5duYfoSGN0arLXUWrUJemtWbPnINtyDnkdReSkqtOjNhjY5Jzb4pwrAd4ErjhuGwcc+TTXBNAMTZEQNXdTDn/7YiNXn9OWawe18zqOSDCosh10zn3pnDuy3ve3QNvA9+OAGc65/c65A8AM4OI6yi1yVpxzTF21h6FdE2nSILxGVlzc2z/f7tNV6lWT4FWdQq0NsLPCzxmBxyp6ELjJzDKAqcAdlR3IzH5sZovMbFF2dvYZxBWR2rT/UAl3vbWMzokN+e0Vvb2OIxIsqtMOVvRD4NMz3FckaKzefZCd+w8zvnf4DHs8ok3TePq1a8qnmqcmQaw6hVplKwi4436+HnjZOdcWGA/8y8xOOLZz7jnn3EDn3MCWLVuefloRqTXOOf7n3RXkFpbyxPX9iY+J9DqSSLCoTjvo39DsJmAg8Mcz2FcXMyWoTF25h8gIY0xaeA17POKS3q1YkZHHzv26+bUEp+oUahlAxfFPbTlxaOMPgbcBnHPzgDggsSYCikjdeG3+DmauzeR/Lu5Br5QmXscRCSbVaQcxs9HA/wETnHPFp7Mv6GKmBBfnHFNX+m9y3axhjNdxasUlvY+s/qjhjxKcqlOoLQS6mVknM4vBv1jIlOO22QFcBGBmqfgLNV0OFAkRm7IK+O3HaxjWLZEfDO3kdRyRYFNlO2hm/YFn8RdpWRWemgaMNbNmgUVExgYeEwlq6/bms21f4dFiJhy1b9GA3m0aM1XDHyVIVVmoOefKgNvxNyxr8a/uuNrMHjKzCYHN7gZ+ZGbLgTeAyc65Sod2iEhwKSv3cfc7y4mPieRP1/TV/dJEjlPNdvCPQCPgHTNbZmZTAvvuB36Lv9hbCDwUeEwkqH26ai8RBmN7heewxyMu6d2apTty2ZN32OsoIieIqs5Gzrmp+BcJqfjY/RW+XwMMrdloIlIXnv16C8t35vLE9f1JahzndRyRoFSNdnD0KfZ9CXip9tKJ1Lzpq/cyqGNzEhvFeh2lVl3cuxV/nLaeGWsy+d55Hb2OI3KMat3wWkTC07q9B/nLzA2MT2/F5X3Cd3iLiIhU3/Z9h1i3N5+xvVp5HaXWdWnZiC4tGzJtteapSfBRoSZST5WW+7j77eU0iY/mt1f0xkxDHkVEhKNFy9gwXe3xeON6teLbLfvJLSzxOorIMVSoidRTz8/ewurdB/l/V6bTIsyHtoiISPVNX51JWuvGtGvewOsodWJsr1aU+xxfrMuqemOROqRCTaQe2pJdwF9mbmR8eisu7h3+Q1tERKR6svOLWbzjAOPqwbDHI/q0aUKrxnEa/ihBR4WaSD3j8zn+998riYuK4MEJvbyOIyIiQWTGmkycg3G968ewR4CICGNsr2S+2pDN4ZJyr+OIHKVCTaSeeWvRTuZv3c8vx6eSlKBVHkVE5D+mr9lL++YN6JGc4HWUOjU2rRVFpT5mb9RtgCV4qFATqUey8ot4ZOpazu3cnEmD2nkdR0REgkh+USnfbNrHuF7J9W6BqSGdm9M4LoppqzO9jiJylAo1kXrkd1PXUVzq4+GJ6fWuERYRkVP7cn02JeW+erEs//GiIyO4KDWZz9dlUlbu8zqOCKBCTaTemLd5H+8v3cWtF3amS8tGXscREZEgM2NNJi0axjCgfTOvo3hibFoyuYWlLNx2wOsoIoAKNZF6oaTMx68/XEW75vH8bGRXr+OIiEiQKSnzMWt9FhelJhEZUT9HXAzv3pKYyAhmrtXwRwkOKtRE6oEX52xlU1YBD17ei7joSK/jiIhIkFmwdT/5RWWMTq0/qz0er2FsFOd3bRFY+dJ5HUdEhZpIuNuTd5gnPt/ImLRkLqrHDbCIiJzcjDV7iYuOYFi3ll5H8dSYtGR27C9kQ2aB11FEVKiJhLtHP11HuXPcf1ma11FERCQIOeeYuTaLC7q2JD6mfo+6ONKjqOGPEgxUqImEsUXb9vPhst3cOrwz7Zo38DqOiIgEoTV7DrIr9zBj0pK8juK55MZx9G3bhOlrVKiJ91SoiYSpcp/jwY9W07pJHLeN6OJ1HBERCVIz12RhBqN6ang8+Ic/Lt+ZS9bBIq+jSD2nQk0kTL2zaCerdh3kvkt60iAmyus4IiISpGas3cuA9s1omRDrdZSgMCbNfx+5mWuzPE4i9Z0KNZEwlF9UymPT1zOwQzMm9E3xOo6IiASp3bmHWbXrYL1e7fF43ZMb0a55PDPW7PU6itRzKtREwtDTszaTU1DC/ZenYVY/74cjIiJV+zywaMaYNBVqR5gZY1JbMXfzPgpLyryOI/WYCjWRMLMr9zAvztnKlf1S6NO2qddxREQkiM1cm0WnxIZ0adnQ6yhBZXRaEiVlPmZvzPE6itRjKtREwswfP1sHwD0X9/Q4iYiIBLOC4jLmbd7H6NQkjb44zqCOzWkcF8VMrf4oHlKhJhJGlu/M5YNlu/nhBZ1o0zTe6zgiIhLEZm/IpqTcx0Wan3aC6MgIRvRI4ot1WZT7nNdxpJ5SoSYSJpxzPDJ1LYmNYrQcv4iIVGnm2iyaxEczsEMzr6MEpdFpyew7VMKynbleR5F6SoWaSJiYtT6b+Vv38/OLupEQF+11HBERCWLlPscX6zIZ1TOJqEh9HKzMhd1bEhVhzFyr4Y/iDf3PFAkD5T7H7z9bR4cWDbhuUHuv44iISJBbsuMABwpLuSg1yesoQatJfDSDOzXXPDXxjAo1kTDw4bJdrNubz91jexATpf/WIiJyajPXZhIdaQzv3tLrKEFtdGoyG7MK2L7vkNdRpB7SJzqREFdcVs6fpm+gd5vGXJbe2us4IiISAmauyeTczi1orKHyp3TkRuAz12Z5nETqIxVqIiHu1W93sCv3MPde3JOICC2vLCIip7Y15xCbsw9xUU8Ne6xK+xYN6J7cSMMfxRMq1ERC2KHiMv7+5SbO79KCYd00fEVERKr2eWBxDC3LXz2jU5NZsG0/eYWlXkeRekaFmkgI+8fcrew7VMI943p4HUVERELEjDWZ9GyVQLvmDbyOEhJGpyVT7nPM2qDhj1K3VKiJhKi8wlKe/XoLo1OT6N9e98AREZGq5RaWsGj7gaNzr6Rq/do2JbFRDJ9rnprUMRVqIiHq+dlbyC8q4xdj1JsmIiLVM2t9NuU+x+g0FWrVFRFhjOqZxJfrsygt93kdR+oRFWoiISinoJiX5m7lsj6tSUtp7HUcEREJETPXZtIyIZY+bZp4HSWkXJSaTH5RGQu37fc6itQjKtREQtAzszZTVFrOf43u7nUUEREJESVlPr5an81FPZO0SvBpGtYtkZioCGau0fBHqTsq1ERCTNbBIv717Xau7N+GrkmNvI4jIiIhYsHW/eQXl2m1xzPQICaKoV1aMHNtJs45r+NIPaFCTSTEPP3VZsp8jjsv6uZ1FBERCSEz12YSGxXBBV0TvY4SkkanJbNjfyGbsgq8jiL1hAo1kRCSebCI1+bv4Dv929ChRUOv44iISIhwzjFzbSYXdE0kPibS6zgh6aKe/p7IGWt182upGyrURELI07M24/M57hil3jQREam+DZkFZBw4rGGPZ6FVkzjS2zRh5hoValI3VKiJhIi9eUW8vmAHVw1oS/sWukmpiIhU38xAL9Do1CSPk4S20anJLN2ZS05BsddRpB5QoSYSIp6etQmfz3H7qK5eRxERkRAzY00mfds1JalxnNdRQtrotCScgy/WafVHqX0q1ERCQObBIt5YuJOrz2lLu+bqTRMRkerLOljEsp25jFFv2llLa92YlCZxzNDwR6kD1SrUzOxiM1tvZpvM7L6TbHOtma0xs9Vm9nrNxhSp3579agvlPsdPR6g3TURETs/ngd6f0Wman3a2zIzRacnM3phNUWm513EkzFVZqJlZJPAUcAmQBlxvZmnHbdMN+F9gqHOuF/BftZBVpF7Kyi/itfnbmdi/jeamiXikqguWZjbczJaYWZmZXX3cc+VmtizwNaXuUov4zVyTSbvm8fRITvA6SlgYk5ZMUamPuZtyvI4iYa46PWqDgU3OuS3OuRLgTeCK47b5EfCUc+4AgHNOA3dFasgLs7dSWu7jZyPVmybihepcsAR2AJOBykaUHHbO9Qt8TajVsCLHKSwpY86mHEanJmNmXscJC0M6taBRbNTRBVpEakt1CrU2wM4KP2cEHquoO9DdzOaa2bdmdnFNBRSpz/YVFPOvedu5ol8bOiXqvmkiHqnygqVzbptzbgXg8yKgyMnM2ZhDcZmPMVqWv8bEREVwYY+WzFybhc/nvI4jYaw6hVpll1+O/1cZBXQDRgDXAy+YWdMTDmT2YzNbZGaLsrOzTzerSL3z4pytFJWVqzdNxFvVuWB5KnGBtu9bM7uyZqOJnNrMtZkkxEUxqFNzr6OElTGpyWTnF7NiV57XUSSMVadQywDaVfi5LbC7km0+dM6VOue2AuvxF27HcM4955wb6Jwb2LJlyzPNLFIv5BWW8s952xmf3pquSY28jiNSn1XnguWptHfODQRuAP5iZl0qPYkuZkoNK/c5vliXxcgeSURHaqHvmjSiR0siI4wZa/Z6HUXCWHX+1y4EuplZJzOLAa4Djp8M/QEwEsDMEvEPhdxSk0FF6ptX5m2joLiM29WbJuK16lywPCnn3O7An1uAWUD/k2yni5lSo5buOEBOQYlWe6wFTRvEMKhjMy3TL7WqykLNOVcG3A5MA9YCbzvnVpvZQ2Z2ZFL0NGCfma0BvgTucc7tq63QIuGuoLiMl+ZuZXRqEqmtG3sdR6S+q84Fy0qZWTMziw18nwgMBdbUWlKRCmasySQ60hjRQ4V/bRib1ooNmQVsyznkdRQJU9XqB3fOTXXOdXfOdXHOPRx47H7n3JTA98459wvnXJpzLt0592ZthhYJd699u53cwlLNTRMJAtW5YGlmg8wsA7gGeNbMVgd2TwUWmdly/BcyH3XOqVCTWuecY/qaTM7t3ILGcdFexwlLYwI9lepVk9oS5XUAETlWUWk5z8/eygVdE+nfvpnXcUQE/wVLYOpxj91f4fuF+IdEHr/fN0B6rQcUOc7m7AK25hziBxd08jpK2GrXvAGprRszY00mPxre2es4EoY0s1QkyLy9aCc5BcXqTRMRkTM2bbW/l0fL8teuMWnJLNq+n30FxV5HkTCkQk0kiJSW+3j2qy2c06EZ53bWUsoiInJmZqzJpG/bJrRqEud1lLA2Ni0Zn4PP12V5HUXCkAo1kSAyZdluduUe5mcju2BW2YrgIiIip5Z5sIhlO3OPzqGS2tMrpTFtmsYzfbXmqUnNU6EmEiR8PsffZ22iZ6sERvZI8jqOiIiEqJlr/UXD2F6tPE4S/syMMWnJzNmUzeGScq/jSJhRoSYSJKav2cvm7EP8dGRX9aaJiMgZm746kw4tGtAtqZHXUeqFMWnJFJX6+HqjblQvNUuFmkgQcM7x91mb6diiAZemt/Y6joiIhKj8olLmbd7H2LRkXfSrI4M7NadJfLSGP0qNU6EmEgTmbMphRUYet17YhcgINawiInJmvlyfTUm5j3Ea9lhnoiMjuKhnEp+vy6S03Od1HAkjKtREgsDTszaT3DiW7wxo43UUEREJYdNW7SWxUSwDdB/OOjW2VytyC0tZsHW/11EkjKhQE/HYsp25fLN5H7dc0JnYqEiv44iISIgqKi3ny/VZjO2VTIRGZ9SpC7u3JC46gmmr93odRcKICjURjz09axNN4qO5fkh7r6OIiEgIm7Mxh8KScg179EB8TCQXdm/JtNV78fmc13EkTKhQE/HQpqx8pq3O5PvndaBRbJTXcUREJIRNW72XhLgozuvcwuso9dK4Xq3IPFjM8oxcr6NImFChJuKhZ77aQlx0BJOHdvI6ioiIhLCych8z12ZyUc8kYqL08c4LF/VMJirCmKbVH6WG6H+yiEd25x7mg6W7uG5Qe5o3jPE6joiIhLAF2/ZzoLBUwx491KRBNOd1acG01XtxTsMf5eypUBPxyAuztwLwo+GdPU4iIiKhbvrqTGKjIriwR0uvo9RrY3u1YmvOITZmFXgdRcKACjURDxw4VMIbC3ZwRb82tGka73UcEREJYT6fY9rqvQzr1pIGMZrv7KVxacmYwacrtfqjnD0VaiIeeGXeNg6XlvOTC9WbJiIiZ2dZRi578ooYn65hj15LahzHOe2b8emqPV5HkTCgQk2kjhWWlPHyN9sYk5ZMt+QEr+OIiEiI+3TlHqIjjYtSk72OIsAl6a1ZtzefLdka/ihnR4WaSB17c8FOcgtLuW1EF6+jiIhIiHPOMXXlXi7omkiT+Giv4whwcW9/z+anqzT8Uc6OCjWROlRa7uOF2VsY3Kk5A9o38zqOiIiEuJW78tiVe5hL0lt7HUUC2jSNp1+7phr+KGdNhZpIHZqybDe784q47UL1pomIyNmbunIvURHG2DQNewwm49NbsWrXQXbsK/Q6ioQwFWoidcTnczzz1WZ6tkpghJZPFhGRs+Sc49NVezivSwuaNtD9OIPJJb39PZzqVZOzoUJNpI58vi6LjVkF3DaiC2bmdRwREQlxa/YcZPu+QsZr2GPQade8AeltmjBV89TkLKhQE6kDzjn+PmsT7ZrHc6kaVBERqQGfrdpLhKFhj0HqkvRWLN+Zy67cw15HkRClQk2kDizYup+lO3L58fAuREXqv52IiJwd5xyfrNjDuZ1b0KJRrNdxpBLjjwx/XKnhj3Jm9IlRpA48/dVmEhvFcM05bb2OIiIiYWDNnoNsyTnEZX1SvI4iJ9ExsSG92zTmoxUq1OTMqFATqWWrd+cxa302Nw/tRFx0pNdxREQkDHy8Yg+REXb0nl0SnC7rk8Lynbns3K/VH+X0qVATqWXPfLWFRrFR3HRuB6+jiIhIGHDO8fGK3QztmkjzhlrtMZgdmZf+sXrV5AyoUBOpRdtyDvHJit3ceG57msRHex1HRETCwIqMPHbuP8xlfbQ4VbBr17wB/do15eMVu72OIiFIhZpILXpu9haiIiP44dBOXkcREZEw8dHy3URHGuN6adhjKLi8bwqrdx9kS3aB11EkxKhQE6klWQeLeHdRBlef05akxnFexxERkTDg8zk+WbmHC7u31EiNEHFpemvMNPxRTp8KNZFa8uLcrZT5fNw6vLPXUUREJEws2XGAPXlFWu0xhLRqEsegDs01/FFOmwo1kVqQV1jKq/O2c2mfFDq0aOh1HBERCRMfr9hDbFQEo3WT65ByWd/WbMgsYP3efK+jSAhRoSZSC/45bxuHSsr56YguXkcREZEwUVbu4+MVu7koNYlGsVFex5HTMD69NZERxpTlu7yOIiFEhZpIDSssKeOluVu5qGcSqa0bex1HRETCxNzN+8gpKOGKfm28jiKnKbFRLBd0TeTDZbtxznkdR0KECjWRGvbGgp0cKCzlpyO7eh1FRETCyIdLd9E4LooRPVp6HUXOwJX9U8g4cJjF2w94HUVChAo1kRpUXFbO819v4dzOzTmnQzOv44iISJgoLClj2uq9XNqnNbFRkV7HkTMwNq0V8dGRfLBMwx+lelSoidSg95fsYu/BIn6m3jQREalBM9ZkcqikXMMeQ1jD2CjGpCXz8Yo9lJT5vI4jIUCFmkgNKSv38cxXm0lv04QLuiZ6HUdERMLIh8t2k9IkjsEdm3sdRc7Clf1TyC0s5esN2V5HkRCgQk2khnyycg/b9hXys5FdMTOv44iISJjYf6iErzdkc3m/FCIi1L6EsmHdWtK8YYyGP0q1qFATqQE+n+PJLzbRPbkRY3VvGxERqUGfrNhNmc9xpYY9hrzoyAguTW/NzLWZFBSXeR1Hgly1CjUzu9jM1pvZJjO77xTbXW1mzswG1lxEkeA3fU0mG7MK+NnIrrraKSIiNerfS3fRs1WCbvkSJq7s34aiUh+frtzjdRQJclUWamYWCTwFXAKkAdebWVol2yUAPwfm13RIkWDmnOOpLzfRsUUDLk1v7XUcEakFVV2wNLPhZrbEzMrM7Orjnvu+mW0MfH2/7lJLONiUVcDSHblcNaCt11Gkhgxo35ROiQ15d3GG11EkyFWnR20wsMk5t8U5VwK8CVxRyXa/Bf4AFNVgPpGg99WGbFbuyuO2EV2IitRoYpFwU80LljuAycDrx+3bHHgAGIK/PX3AzHTvDqm295ZkEBlhXNE/xesoUkPMjKvPacv8rfvZub/Q6zgSxKrzqbINsLPCzxmBx44ys/5AO+fcxzWYTSToOeefm5bSJI6J/XW1UyRMVXnB0jm3zTm3Ajh+ze1xwAzn3H7n3AFgBnBxXYSW0Ffuc7y/ZBcXdm9JUkKc13GkBk3s3wYzfyEucjLVKdQqm3Djjj5pFgE8Dtxd5YHMfmxmi8xsUXa2liWV0Ddv8z4WbT/AbSO6EBOl3jSRMFXlBcta2lfqubmbcth7sIirz9GFwHCT0jSeoV0SeW9JBj6fq3oHqZeq88kyA2hX4ee2wO4KPycAvYFZZrYNOBeYUtmCIs6555xzA51zA1u2bHnmqUWCxF8/30hy41iuGdiu6o1FJFSd8oJlTe2ri5lyvPeWZNAkPpqLUpO8jiK14Kpz2rBz/2EWbtvvdRQJUtUp1BYC3cysk5nFANcBU4486ZzLc84lOuc6Ouc6At8CE5xzi2olsUiQ+HbLPuZv3c9tF3YhLjrS6zgiUnuqumBZI/vqYqZUdLColM9W7WVC3xRio9TGhKNxvVrRKDZKi4rISVVZqDnnyoDbgWnAWuBt59xqM3vIzCbUdkCRYPXE5xtpmRDLdYPbex1FRGrXKS9YVmEaMNbMmgUWERkbeEzklD5ZsYfiMp+GPYaxBjFRXJremk9W7uGQ7qkmlajWpBrn3FTnXHfnXBfn3MOBx+53zp3QUDnnRqg3TcLdom37+WbzPm4d3lm9aSJhrjoXLM1skJllANcAz5rZ6sC++/Gvirww8PVQ4DGRU3pz4U66JzeiT9smXkeRWnTNwLYUlpTzyQrdU01OFOV1AJFQ9JeZG2nRMIYbh3TwOoqI1AHn3FRg6nGP3V/h+4X4hzVWtu9LwEu1GlDCyto9B1m+M5f7L0vDrLJpjhIuue/XAgAAIABJREFUzunQjK5JjXhj4Q6uHaT57nIsLVMncpoWbtvPnE05/OTCLsTHqDdNRERq1psLdhATGcHE/logNNyZGdcNasfSHbms///t3Xl8VNX9//HXSSb7vhJCCPu+IyAiKgIibljrBiha16qVtl+7qLXW2lpba9XauqLYuq+4oCIiCgrKvgiEnQAJSwhJyEbWSc7vjxst+gMJkMlNZt7Px2MemeVm8r6QzLmfe849J6/M7TjSwqhQEzlGj3yymeToMK4crt40ERFpWlW1dbyzajfj+6aREBXqdhxpBj8enEFocBCvLs1xO4q0MCrURI7B4uxCvtpWyE1ndFZvmoiINLmP1u2ltMrLxGEaBhcoEqNCGdenDe+s2k1VbZ3bcaQFUaEmcgwe+WQzKTHqTRMREd94dWkuHZMiOaVzkttRpBlNGpZJSWUtH2fluR1FWhAVaiKN9NW2ApZsL+KWUVo3TUREmt62/eUs3V7EZUPbaxKRAHNK5yTaJ0Zo+KN8hwo1kUaw1vLQnM20iQ1jktZNExERH3hlSQ6eIKO10wJQUJBh4tBMFmcXsTW/3O040kKoUBNphPmb9rNi5wGmju6m3jQREWlylTV1vLk8l/F900iNCXc7jrjg8qHtCQk2vLR4p9tRpIVQoSZyFPX1ln/M2UT7xAguG6KLu0VEpOm9t3o3pVVepuga6ICVHB3Guf3aMmPFLg5We92OIy2ACjWRo5idlUfWnlJ+OaY7oR79yYiISNOy1vLCop30aBPDsE6JbscRF111SgfKqr28u3q321GkBdBRp8gPqKu3PPzJZrqmRvMjLTwqIiI+sDKnmPV7S5lySgdNIhLgBmcm0LttLC8u2om11u044jIVaiI/4J1Vu9maX85tZ3UnOEiNp4iINL0XF+0gJszDRTohGPCMMVx1Sgc25pWxbMcBt+OIy1SoiRxBVW0dj3yymX7t4hjfJ83tOCIi4ocKyquZtTaPi0/KICrM43YcaQEuHNiO2HAPLyza4XYUcZkKNZEjeGnxTnYXV3LHOT0JUm+aiIj4wCtLcqipq+dKTSIiDSJCg7lsSHtmr8tjb0ml23HERSrURA6jtKqWx+Zt5bRuyZzaNdntOCIi4oeqvXW8sGgno3qk0DU12u040oJcPaIj9dby/Feaqj+QqVATOYxpn2dTXFHL7eN7uh1FRET81MzVeygor+b6kZ3djiItTPvESMb3TeOVJTs1VX8AU6Em8j35pVVMX7idCQPS6dsuzu04IiLih6y1TF+4nZ5pMZzaNcntONICXTeyE6VVXmas3OV2FHGJCjWR73lozma89fX8alx3t6OIiIif+mpbIRvzyrh2ZCdNyS+HNTgzgYHt43lu4Xbq6zVVfyBSoSZyiA17S3ljRS5XndKRDklRbscRERE/9eyCbJKjQ5kwIN3tKNJCGWO4bmQndhRW8OnGfLfjiAtUqIkc4v5ZG4gND2Hq6K5uRxERET+1Nb+MeZv2M2V4R8JDgt2OIy3YOX3TaBcfwTMLst2OIi5QoSbSYP6mfBZsKeDnY7oRHxnqdhwREfFTT87PJjwkiCuHZ7odRVo4T3AQ15zakaXbi1ixUwtgBxoVaiKAt66e+2dtoENSJFO0lo2IiPjI7uJK3lu9m0nDMkmKDnM7jrQCk4ZlkhAZwpPzt7odRZqZCjUR4NWlOWzeV84d43sS6tGfhYiI+MYzX2RjDNxwmqbkl8aJCvPwkxGdmLshn415pW7HkWakI1IJeMUVNTz0yWaGd05kfN80t+OIiIifKiiv5tWlOfxoYDvS4yPcjiOtyNUjOhAVGsyT87e5HUWakQo1CXiPfLKZ0spa7rmgj6ZIFhERn/nPl9upqavnplFd3I4irUx8ZCiTT87k/a/3kFNY4XYcaSYq1CSgbcor46UlOVxxcgd6tY11O46IiPip0qpaXli0k/F90uiSEu12HGmFrj+tM56gIJ76Qr1qgUKFmgQsay33vp9FdJiH287S4tYiIuI7zy3cTlmVl5+dqeVf5Pi0iQ3n0iEZvLk8l10H1KsWCFSoScD6cO1evtpWyK/GdSchStPxi4iIb5RU1DJ94XbG9W5D33ZxbseRVuxnZ3bFYHh8nnrVAoEKNQlIZVW1/On99fRtF8sVJ2s6fhER8Z3pC7Mpq/Lyy7EavSEnJj0+gonD2vPm8lxyi9Sr5u9UqElA+ufcLewvr+bPF/YlOEgTiIiIiG8UV9Tw3Jc7OLdfGr3TdS20nLhbRnUlKMjw2GdaV83fqVCTgLN+Tyn//WoHk4ZlMigzwe04IiLix55ZkM3BGi+/GKPeNGkaaXHhTB6WyVsrd7Gz8KDbccSHPG4HEGlO9fWWu99bR1xECL89u4dvf9jBAtj7NRRsdm4HC6CmHKrLITgUwqIhLAbiO0BKD0jpCam9IVh/liIi/qCgvJr/frmD8/q1pUdajNtxxI/cMqoLry7N4dG5W3j48oFuxxEf0RGhBJSXl+awYucB/nHpAOIjm3gCkfo62P45bPkEsj+H/Kz/vRYeBzFtITQaQqOg3gule6CqGNbNAFvvbBcWCx1HQudR0GsCxLZt2owiItJs/vXpFqq89fyfZhaWJpYaG85PTu3ItC+yuf60zhpW66dUqEnA2FtSyQMfbWRk12QuHtyu6d44fwOsegnWvgXleeAJh8zh0O8eyBjq9JZFpcCRFtP2VkNRNuzLgh0LnCJv0yz46HbodDoMmAh9fgwh4U2XWUREfGp7wUFeWZLDxKHttW6a+MQtZ3TltaW5/G32Rl64dpjbccQHVKhJQLDWcve76/DW13P/Rf0wRyqaGv+GkD0fFj0GW+dCUAh0Pxv6XwbdxkFIROPfyxMGqb2cW79LnOcKtsLaN2HN6/DuzfDJH2DoDTD0OohKPrHsIiLicw9+vJFQTxC/GNvN7Sjip+IiQ5g6uiv3fbiBhVsKGNlNxwf+RpOJSED4cO1e5m7I51dn9SAzKfLE3mz7Anh2LLz4I9i7Bs78PfxqE0x8GXpfeGxF2pEkd4Uz74Sfr4KrZkL6IJh/P/yzH3z6J6gsPvGfISIiPrEq5wCz1uZxw2mdSY3RaAjxnSmndKBdfAR//WgD9fXW7TjSxFSoid8rOljDH2dm0a9dHNec2vH432jfenjxx/D8+VC2F87/J/xyLZzxG4hKarK832EMdD4DrngTblkCPc6FBQ/BowPgq3+Dt8Y3P1dERI6LtZa/ztpIcnQoN5ze2e044ufCPMH8+uzuZO0p5b2vd7sdR5qYCjXxe3e/u46SyloevLQ/nuDj+JWvLoOP74KnRsKelTDuPpi6AoZc07zXjaX2hEumw08XQMYQmPN7J9P2L5ovg4iI/KAP1+5l6Y4ifjm2O9FhusJEfO/CAe3o2y6WBz7axMFqr9txpAmpUBO/9v7Xe/hw7V5+ObY7PdOOY0akjR/CY0Nh0eMweApMXQkjpjbN8Mbj1bY/XDkDJr8B3ip4/gKYcQNUFLmXSUREqKjxcv+HG+jVNpZJwzLdjiMBIijI8McL+pBXWsUT87UItj9RoSZ+K7+sirvfW8eA9vH89FiHn1QUwYzr4bXJEJkM138KFzwKkYm+CXs8up8NP1sCZ9wOWe/A48Ngw/tupxIRCVhPzd/GnpIq7p3Qh+CgE5y0SuQYDOmYyEWD2vHMF9u1CLYfUaEmfslay+/eXktlTR0PXTrg2IY8bpkLj5/sFD+j7oQb50HGSb4LeyJCIuDM38GN85112l6/0uldqypxO5mISEDJLargqS+ymTAgnWGdWtBJPQkYd5zTE0+w4c8fbHA7ijSRRh29GmPGG2M2GWO2GmPuOMzrtxlj1htj1hhjPjXGdGj6qCKN99KSHOZuyOe343vSNbWR69d4q2H2nfDyxc4U+DfOh1F3QHCIL6M2jbS+cMNnMOp3zgLaT50GuUvdTiUiEjDu+3A9wcZw57k93Y4iAapNbDhTR3dj7oZ9zNuU73YcaQJHLdSMMcHA48A5QG9gkjGm9/c2WwUMsdb2B94C/t7UQUUaa8u+Mu77YD2nd0/hmhEdG/dNBVvhmTGw+Ak4+Sa4YR6k9fNpziYXHAKjbodrZzuPnxsPXzwI9fXu5hLxA404YRlmjHm94fUlxpiODc93NMZUGmNWN9yeau7s4ntzsvL4OGsfU8d0pW2ci9cwS8C7dmRHOqdEcfe766io0cQirV1jetSGAVuttdnW2hrgNeDCQzew1s6z1lY0PFwMZDRtTJHGqaqt4+evrSY6zMM/Lu1PUGOuEVg3A6adAaW7nQk6znmgeWdzbGrth8FNC6HPRfDZffDKpXCw0O1UIq1WI09YXgccsNZ2BR4BHjjktW3W2oENt5uaJbQ0m7KqWv7wXhY902K44TRNxy/uCvMEc/9F/dh1oJJH525xO46coMYUau2A3EMe72p47kiuAz463AvGmBuNMcuNMcv379/f+JQijfTA7I1s2FvKg5f2P/oio94a+PDX8Na10KYP3LTAmaDDH4THwsXPwvmPONP3P62hkCIn4KgnLBseP99w/y1gjDFGs0kEgIfmbGZfWRV//XE/Qo5nCRiRJja8cxITh7bn2YXbWbdb16y3Zo35RDlcQ3PYpc+NMVcCQ4AHD/e6tXaatXaItXZISkpK41OKNMLsdXv5z5c7+MmIjozu2eaHNy7dC/89F5Y9A6fcCj/5EOL8rCPYGBhyLVz3CQR54D/nwrJnwR72z1dEjqwxJyy/3cZa6wVKgKSG1zoZY1YZYz43xpzm67DSfFblHOD5RTu4angHBmUmuB1H5Ft3ntOLhMgQfvfOWurq1e63Vo0p1HYB7Q95nAHs+f5GxpixwF3ABGttddPEE2mcHQUH+c2baxjQPp7fndvrhzfeuQiePh32rYdL/wtn/6V1TBhyvNIHwk8/h86j4MNfwXu3Qm2V26lEWpPGnLA80jZ7gUxr7SDgNuAVY8xhF3XUqJPWpaq2jttnrKFNTDi/PruH23FEviMuMoQ/XNCHNbtKeHZBtttx5Dg1plBbBnQzxnQyxoQCE4GZh25gjBkEPI1TpGmaGWlWVbV13PLySoKCDI9PHkSo5wi/1tY6PUrPnw9hMXDDp851XIEgIgEmvw6n/xZWvwT/GQ8lu91OJdJaNOaE5bfbGGM8QBxQZK2tttYWAlhrVwDbgO6H+yEaddK6PPzJZjbvK+evF/cjJtyPT/ZJq3VB/7aM692Gh+ZsZlNemdtx5DgctVBrGMJxK/AxsAF4w1qbZYz5kzFmQsNmDwLRwJsNs1rNPMLbiTQpay33vJfF+r2lPHzZADISIg+/obca3v+F06PUZbQzlX3qUXre/E1QMIy+Cya+AgVbYNooyFnidiqR1uCoJywbHl/dcP8S4DNrrTXGpDRMRoIxpjPQDdDp7VZu6fYinlmQzaRhmZzZI9XtOCKHZYzh/h/3Iybcw21vrKbGq1mgW5tGXfVqrZ1lre1ure1irf1Lw3N/sNbObLg/1lrb5pBZrSb88DuKNI0XF+/k9eW53HpmV8b0OsJ1aeX58PwFsPJ5OO1XMOk1iIhv3qAtSc/z4Pq5EBYN/z0PVr7gdiKRFq2RJyynA0nGmK04Qxy/mcL/dGCNMeZrnElGbrLWFjXvHkhTOljt5ddvfk1GQgR3nRdgJ/yk1UmODuMvF/Uja08pj32mWSBbG4/bAUSO16Jthdz7/nrG9krltrMOO5II9qyG1yZDRRFc8hz0vbh5Q7ZUqb2cXsW3roWZUyFvHZx9PwTrI0HkcKy1s4BZ33vuD4fcrwIuPcz3zQBm+DygNJv7PlxP7oEKXr/xFKLD9JkpLd/4vmn8eFA7Hp+/jVE9UxmsiW9aDc0jK61SblEFt7y8go5JkTxy+cDDr5e27m1n0WcMXPexirTvi0iAyW86s14ufRpe+rFT0IqIyGHN/HoPry7N5aend2FYp0S344g02j0T+tA2Lpypr6yipKLW7TjSSCrUpNUpqazluueX4a23PHPVkP//Iu76emeh57eugbb94cZ50HaAO2FbumCPM+vlhU9AziJ4ZjTkb3Q7lYhIi7Oj4CC/e3stgzPj+dW4I4ziEGmh4iJCeGzyYPaVVvHbGV9jtVRPq6BCTVqVGm89t7y8guz9B3n6ypPonBL93Q2qy+GNKfDFgzDoSrj6fYjWhd5HNegKuPoDqDkIz46FTbPdTiQi0mJUe+u49dWVBAcZ/jVpkBa2llZpYPt4bh/fk4+z9vHCop1ux5FG0CeNtBrWWu56Zy1fbi3kbxf3Z0TX5O9uULQdpo+DTbNg/AMw4THwhLkTtjXKPNnpfUzqDK9OhAUPa3FsERHgvg82sG53KQ9e0v/IswuLtALXjezE6J6p/OXDDazOLXY7jhyFCjVpNR6Zu4U3V+zi52O6cclJGd99MftzeOZMKN0NV86A4TeBOdz6s/KD4jLgmtnQ98fw6b0w43qoqXA7lYiIa15flsOLi3dy4+mdGdcnze04IickKMjw0KUDSI0N46YXV5BfVuV2JPkBKtSkVfjPl9v516dbuPSkDP5vbLf/vWAtLHkaXrwIolKdmQy7jHYvqD8IjYSLp8OYP8C6Gc7i2MW5bqcSEWl2K3MOcPe7WZzWLZnfnt3D7TgiTSIhKpRpU4ZQXFnDLS+t1PpqLZgKNWnx3l65i3vfX8/Zfdrw1x/3w3zTU1ZbBe/eAh/9FrqNc9YGS+riblh/YUzDmnOvQmG2szj2joVupxIRaTb7Squ46cUVpMWF8+9Jg/DoujTxI73TY3nwkgEs33mAP76fpclFWih96kiLNnvdXn7z1hpO7ZrEoxMPaShLdjk9PV+/AmfcARNfgfBYd8P6ox7nOL2UEQnw/ARY/JSuWxMRv3ew2st1zy+jvNrLtKtOIj4y1O1IIk3uggHp3DyqC68syWH6wu1ux5HDUKEmLdbsdXnc+soqBmTE8fSUIYSHBDsvZH8OT58OBVvh8pfhzDshSL/KPpPS3SnWup8Ns2+Hd36q69ZExG956+q59ZWVrN9TyuOTB9MzTScBxX/9ZlwPzumbxl9mbWDW2r1ux5Hv0dGttEhOkbaS/hlxPH/tMKLDPE5PzsJ/wos/gshkp3jodb7bUQNDeGxDUfx7WPMGTD8LCre5nUpEpElZa7n7vSzmbdrPfT/qx5k9tbyL+LegIMMjlw9kcGYCv3x9NSt2FrkdSQ6hQk1anA/W7OHWV1bSr6FIiwkPgcpieP1KmHsP9JrgFGkpWnC0WQUFwRm/gSvfcmbXnHYmbHjf7VQiIk3m0U+38OrSHG4Z1YXJJ2e6HUekWYSHBPPMVUNoFx/Bdc8vZ1NemduRpIEKNWlRXlmSw9RXVzEoM/5/RdqeVc5Qx82z4ez74dL/Qlj0Ud9LfKTrWLjxc2filtevhI/vgrpat1OJiJyQaV9s459zt3DJSRn8epxmeJTAkhgVyvPXDCPME8QVzy4he3+525EEFWrSQlhreXL+Nn73zlrO6J7CC9eeTGyYB5ZMcxaxrvfCNR/BKT/T+mgtQUIHuHY2DPspLHoM/nMOHNjhdioRkePy4uKd3D9rI+f1b8sDF/cnKEjtjASezKRIXr7+ZOqt5Ypnl5BbpOvR3aZCTVxXV2/548wsHpi9kQsGpDNtyhAivCXw2mT46DfQeRT8dAG0H+Z2VDmUJwzO/bvTw7l/Ezx1OmS943YqEZFj8urSHO5+dx1jeqbyyGUDCVaRJgGsa2oML143jIPVXiY/u1jFmstUqImrDlZ7ufGF5Ty/aCfXj+zEPy8fSGjOAnjyVNg6F8b/DSa/AVFJbkeVI+lzEdy0wLlm8M2fwHu3QrWGTIhIy/fcwu3c+fZaRvVI4fErBhPq0WGRSJ/0OF647mRKKmq5/OlFbC846HakgKVPJHHNnuJKLp+2iHmb8vnzhX34/dmdCZ5zF7wwAUIj4bpPYPjNGurYGiR0dIamjrwNVr0ET42E3KVupxIROaIn5m/lTx+s5+w+bXh6ykn/WwJGRBjYPp5XbxxOlbeey55exOZ9mmDEDSrUxBWLthVywb8XsqOggmevHsKUDsXwzJmw+HEYer0z1DF9oNsx5VgEh8DYe+CaWVBfB8+dDZ/+GbzVbicTEflWfb3lzx+s5++zN3HhwHQenzyYMI+KNJHv65Mex+s3DgfgsqcXsXyHpu5vbirUpFlZa3lu4XaunL6E+MgQ3r1pKKP3PAvPjIaKIpj8Jpz3kNOjJq1ThxFw85cwYBIs+AdMG+XM3Cki4rKq2jqmvrqK6Qu385MRHXn4soF4gnUoJHIk3drEMOOmESREhjL52SV8pEWxm5U+naTZFFfU8NMXV/CnD9YzumcqMy+KoOs758MXf4f+l8HPFkP3cW7HlKYQHgs/esK5vrDyADwzBubeC7WVbicTkQBVWF7NlOlL+HDtXu46txf3XNBbE4eINEJmUiQzbh5B3/RYbnllJc98kY211u1YAUGFmjSL5TuKOO9fC5m3KZ97z27PtOTXiXrhbOcgftJrcNFTEJHgdkxpat3PhlsWwYCJsPBheOIUyJ7vdioRCTDrdpcw4bEvWbOrhH9PGsQNp3fG6PpnkUZLjArllRuGc07fNP4yawO3vfE1VbV1bsfyeyrUxKeqvXX87aONXPb0IoINzB1XyNUrL8csfQaG3QA/WwI9znE7pvhSRILTu3bVTGdimBcuhBnXQ6mGT4iI7727ajcXP/kV1lreumkEFwxIdzuSSKsUHhLMY5MG86uzuvPu6t1c8tRX7C7WSBlfUqEmPrNudwkT/v0lT32+jVv7evks5SE6zLsVolPg+rlw7oPOEDkJDJ3PgJsXwem/hfUz4bEh8NW/wVvjdjIR8UOVNXXc+fYafvn6aga0j2fm1JH0y4hzO5ZIqxYUZJg6phvPTBnCzoIKzn10AXOy8tyO5bdUqEmTO1jt5b4P1jPhsYVwcD9f9v2A27Zegyd/HZz3MNwwDzKGuB1T3BASDqPvcq5H7HAqzPk9PDEcNnwAGu8uIk1k874yLnx8Ia8uzeXmUV14+fqTSY4OczuWiN8Y27sN708dSfvECG58cQV/nJmloZA+4HE7gPgPay1z1u/j3plZHCgp5smOSxhX9DJmWyUMvQ7OuEMLV4sjsTNc8QZsnuMUa69fAR1Gwln3qogXkeNWV2+ZvjCbf8zZTGy4hxeuHcbp3VPcjiXilzomRzHj5hH8ffYmpi/czlfbCvjHpQPonxHvdjS/oUJNmsTGvFL+9P56lm3bx8/jv+SmhBmE5BVA93PgrD9BSne3I0pL1H0cdBkNK/8L8/4Kz46BHufB6N9Dm95upxORVmTb/nJ+8+bXrMwp5qzebbj/on6kxKgXTcSXwjzB3H1+b07rlsztM9Zw0RNfcfMZXZg6pqvWJ2wCKtTkhOwpruRfn27h3eXZTAlfwLT4D4iuynOGtY15GTKHux1RWrpgj7PIef/LYfFT8NW/4MkR0OdHcPpvoE0ftxOKSAtWVVvHE/O38dT8bYSHBPHPywdy4cB0zeoo0oxG9Uhlzi/P4N4Psnhs3lZmrdvLfRf2ZUTXZLejtWrGrXUQhgwZYpcvX+7Kz5YTV1hezZPztzFj8UYuNZ9xa/hsYmv3Q/uT4YzbnV4SNZJyPCqKnElGlj4DNWXQ83wY+X8aEtnKGWNWWGv1n9hIaiMbZ96mfO6dmcWOwgouGJDO3ef1IjU23O1YIgFt3qZ87nkvi5yiCn40MJ07zulFWpz+Lo/kh9pH9ajJMckrqWLaF9nMXbqKSXY2X4Z+RmR9OaSPhDOmQ6fTVaDJiYlMhLH3wIipsORpWPIkbPwAMkfAiFuh+3gI0nAKkUC2Ma+Uv3y4gQVbCuiUHMVL153MyG46cy/SEpzZI5VT/i+JJ+Zt5anPs/k4ax83nt6Zn57RmchQlR7HQj1q0igb80qZ/kU2u9d8xhXmY8YHLyPIWEyvC2DELyDjJLcjir+qLoOVL8LiJ6AkF+I7OEMlB13pFHXSKqhH7diojTy8nMIK/vXZFt5euYuY8BB+PqYbU4Z3INSjSaxFWqKcwgoemL2RD9fuJTUmjFtHd+Xyoe11/dohfqh9VKEmR1RbV8+nG/J558s1tMuZySTPPLqZXdSHxRE0eIpzsJzYye2YEijqap2etSXTIOcr8IRD7wth8NXQYYR6cls4FWrHRm3kd+UWVfDE/K28uXwXwUGGKcM7cOvorsRHhrodTUQaYcXOIv720UaW7ThAelw4PxvdlUtOylDBhgo1OUY7Cw/y9rLt7F42k9E18xgbvJJQvHjbDsYz5GrodymERrkdUwLZ3jWw4r+w9k2oLnWm++8/EfpfppMHLZQKtWOjNtKxbncJ077I5sO1ewk2hsknZ3LzqC600XVoIq2OtZYvtxby0CebWJVTTEpMGNee2okrhmcSGx7idjzXqFCTozpwsIbZa3axZelHdN3/CeODl5FoyqkJS8Qz4FKCBl8FaX3djinyXTUHYf17sPoV2LHAeS5jGPS5yOlti2vnbj75lgq1YxPIbaS3rp5P1u/j+UU7WJxdRHSYhytOzuSaUztpQgIRP2Ct5atthTz1+TYWbCkgKjSYi0/K4KpTOtA1NcbteM1OhZocVkF5NZ+v20nu8llk7PuMM4NWkmTKqA2KwNvtbCJOmuzM3hgcuGc5pBUpzoW1b8C6d2DfWue5jKHQ41zoeR4kd9fwSBepUDs2gdhG5hRW8NaKXN5Yvou80iraxUcw5ZQOTBqWSVyE2iERf7RudwnPfbmdD77eS01dPad0TuLyoe0Z3zeN8JDAGBapQk0A5wzGhj2lfL16GZUb59ClZBEnmw2Em1qqgqOp6jiGuJMuxnQbByERbscVOX4FWyDrXeeatr2rnecSOkLXs6DbWc46f2HRrkYMNCrUjk2gtJElFbXMztrLu6v2sCi7EGPgtG4pTBnegdE9UwkO0skVkUBQWF7Na8tyeW2XOd+dAAAP1klEQVRZDrlFlcSEezi/fzoXDkxnWMdEgvz4s0CFWgDbVXSQNWtXU7LpC+L2LmJQ/VramiIAiiI6UN9lDEmDLsR0PFU9Z+KfSnbDplmwdS5s/wJqKyDIA+2GQOcznKItYyiERrqd1K+pUDs2/txGFlfUMHdDPrPX5fH55nxq6ywdkiK5ZHAGF5+UQXq8ThSKBKr6esvi7YW8sSyXj7P2UVlbR1psOOf2a8vZfdowpGOi353AUaEWILx19WzevZ+dWUuo2r6Y2ILV9KlbT5o5AEBZcBzFqcOJ6zOW2N5nadIFCTy1VZCzCLLnO0Xb3tVg653CLX2Qc31bxhDnFtdeQyWbkAq1Y+NPbaS1lq355czftJ95m/JZsr2IunpLWmw45/Vvy4QB6fTPiMPo701EDlFR4+WT9ft4/+s9fLG5gJq6epKiQjmzZypn9khlZLdkvxgWrULND9V469m+azd7N6+gMnc1YQXrSK/YRFd24TH1ABR62lCcNIio7qeR2udMglJ7QZDWmhH5VmUx5C51pvvPWQx7VoG3ynktMgnaDoT0gdCmL6T1c2aX1GLbx0WF2rFp7W3kvtIqFm0r5MutBXy1rZDdxZUAdEuNZmzvNozvk6biTEQarbzay/xN+XyctY/PN+VTWuUlOMgwICOOU7smM6JLMoMy41vldW0q1Fqxqhovu3blsH/HOir2bMQUbiG2bCvtand8O4QRoMTEsj+mF/VpA0joejLJPU/FxLZ1MblIK1RXC/vWwa7lsGe10+OWvwFsnfO6JwKSu0FqL0jpAUndnMcJnSBEs9H9EBVqx6Y1tZHeuno27ytndW4xK3YeYNmOInKKKgCIiwhheOdETu+ewqgeqbTTsEYROUHeunpW5xYzb1M+X24tZM2uYuothAYH0S8jjqEdExmUGc+g9vGktoKlPFSotWB1dfXsL9hH0Z5sSvftpLpgB+bATsIP5hJfvZv0+jyiTdW321cTSl5oJuWxXTGpvYjvNJg23YcQHNtWw7REfMFbDfs3Qt46yF/vFG77N0Lp7kM2MhDbzhlOnNAR4jtAQgeIy3BuMW0D/hpQFWrHpqW2kdXeOrbml7NhbxnrdpeQtaeEdbtLqax1TmYkRoUypEMCwzolcnKnJHqnx/rd9SQi0rKUVtWyNLuIZTuKWLqjiLW7SvDWO/VNelw4fdvF0bddHH3SY+nZNpb0uPAW1Zv/Q+2jp5FvMB54FAgGnrXW/u17r4cBLwAnAYXA5dbaHScSujWz1lJZWcGBgn2UF+VRcSCP6pI8vKX7oHwfIRX7iazOJ9ZbQHJ9IWmmmrRDvr+KUAqC21ASlcGWmOF4kjsR0643aZ37EZ7cgQ4avijSfDxh0HaAcztUdRkUboWCrVC0DYq2Q1E2bJkD5fu+9yYGolOdgi02HaLbQEya81xUKkSlQFSyM9wyPE4nXcR1ZVW17CioILugnG355WzdX87mfeVsLzhIXcMBUERIML3TY7l8aHsGto9nYPt4OiRFtqgDIBHxf7HhIYzt3YaxvdsAUFVbR9aeElblFPP1rhKydpcwZ/3/2uWYcA892sTQNTWarqnRdEmNplNSFBkJEXiCW9Yx9lELNWNMMPA4cBawC1hmjJlprV1/yGbXAQestV2NMROBB4DLfRG4OdTV1VFxsJSqg2VUlpdQfbCU6opiaivK8FYUU1dZSn1lCVSXElRVQnBtKaG1pUR4S4iuKyXWlhFtKjncHHJVhHDAJFAWkkxxTA8KIttg4jMIS8okJrUDye27EZmQToYxZDT7notIo4XFOBOQpA/6/1+rrYTiHCjZ9b9b2R4oy4MDOyF3CVQUHv59gzwQkQgRCRDZ8DU83ingwuMgPBbCYp2vodHO/bBo535olPPVE+rbfZdW72C1l70lVewprmRPcSW7iyvJLaogp+FWUF7z7bZBBjITI+maGs34Pmn0SIuhV9sYOiVHq7dMRFqc8JBgTuqQyEkdEr99rqyqlo15ZWzMK2NTXimb8sqYs34fry3L/XYbT5AhIyGC9omRZCZG0j4xkvT4CNrFh5MeH0FKdFizF3KN6VEbBmy11mYDGGNeAy4EDi3ULgT+2HD/LeAxY4yxPhxXmZezhb0bl1DvrcF6a6ivq8V6a7DeamxdjTNcyVsDddUYbzWmvgbjrSaovorguio8ddV46p1bqK0itL6aMKoJt9VEmmpigKOtjV5jgyk30RwMiqYyOJqq0CTKQjuzKzwBIpMIjkoiJCaFiMS2xCSlEZ+SQXh0Am2NQVePifixkAjnGraUHkfepq4WyvOhogDK98PB/U7x9s2t8oBzK86BqrVQ5ZwcapQgD4REOUsOhERASCR4whvuRzj3PeHOdXWecAgOdXoOg8OcIi84zBmqGRzq3AZMDPhevhMZWWKMuRPnhGYd8HNr7ce+zrs4u5A9xZUUltdQUF5Nflk1+WVV5JdWk1daRVmV9zvbBxloGxdBZmIko3um0ik5mk7JkXRMjqJjUlSrvEBfROQbMeEhDO2YyNCOid95vuhgDdv2O6MFdhQcZGdhBbkHKvhgzV5KKmu/s22QgZSYMNrEhpMaE0ZKTDhjeqZ+25PnC40p1NoBuYc83gWcfKRtrLVeY0wJkAQUNEXIw8ldPouha/5w1O2qbQjVJoRaQqgllJqgULwmhFoThjconIrQKMqCI6gLDqfe4xzQ2JBITGgkJiyG4PAYgsOjCYmMIzw6nrCoWCJjE4mOTSI0PJJEY0g8agoRke8JDoG4ds6tserrnGKtqtT5Wl3uDMGsKYOag87j2oNQU+GsF1dbccj9SmdGy/L8hhNZVQ236v89/mbSlEMFeWDgpKbb71boREaWGGN6AxOBPkA6MNcY093aw/1jN53fv7uOrfnlAIR6gkiJDiM1NozOKVGM6JJEWlwEaXFhpMdF0C4hgjax4YS0sCE/IiK+lhgVSmLU/1/AgdMLt6e4it3FFewtqWJfSZXztayaXQcqWZVTTJvYMNcLtcOdRv1+T1ljtsEYcyNwI0BmZmYjfvSRdT3tMrZ2GYInJJTgkDCCPaGEhoXjCQ3HExpGaFgEISGhhAUFEXZCP0lEpIUICnaGQkYk+Ob96+vgmxEJdbXO/bqao3+f/zvukSUNz79mra0Gthtjtja83yJfBn5s8iDCPMEkR4cSHebRdWMiIscoJjyEHmkh9Eg78hg7X0/K2JhCbRfQ/pDHGcCeI2yzyxjjAeKAou9tg7V2GjANnBmtjifwNxJS2pKQogGEIiJNJigYghqGR8qhTmRkSTtg8fe+9xi6UY9Pz7RYX/8IEZGA5+uTYI0Z57AM6GaM6WSMCcUZwjHze9vMBK5uuH8J8Jkvr08TERFpRicysqRRI07AGXVijFlujFm+f//+Y4woIiL+5qiFmrXWC9wKfAxsAN6w1mYZY/5kjJnQsNl0IKlhSMdtwB2+CiwiItLMjmVkCd8bWdKY7wWcUSfW2iHW2iEpKSlNFF1ERFqrRq2jZq2dBcz63nN/OOR+FXBp00YTERFpEb4dWQLsxhlZMvl723wzsmQRh4wsMcbMBF4xxjyMM5lIN2BpsyUXEZFWq1GFmoiISKBquObsm5ElwcBz34wsAZZba2fijCx5sWFkSRFOMUfDdm/gTDziBX7m6xkfRUTEP6hQExEROYoTGVlirf0L8BefBhQREb+jRVNERERERERaGBVqIiIiIiIiLYwKNRERERERkRZGhZqIiIiIiEgLo0JNRERERESkhTHWWnd+sDH7gZ0n+DbJQEETxGnpAmU/IXD2VfvpX7SfR9fBWqtVnBtJbeQx0X76F+2n/wmUfT3e/Txi++haodYUjDHLrbVD3M7ha4GynxA4+6r99C/aT2mJAuX/S/vpX7Sf/idQ9tUX+6mhjyIiIiIiIi2MCjUREREREZEWprUXatPcDtBMAmU/IXD2VfvpX7Sf0hIFyv+X9tO/aD/9T6Dsa5PvZ6u+Rk1ERERERMQftfYeNREREREREb/jF4WaMWaqMWaTMSbLGPN3t/P4kjHm18YYa4xJdjuLLxhjHjTGbDTGrDHGvGOMiXc7U1Myxoxv+F3daoy5w+08vmCMaW+MmWeM2dDwN/kLtzP5kjEm2BizyhjzgdtZfMkYE2+Meavh73ODMeYUtzNJ46iN9B9qI1s/tZH+x5ftY6sv1IwxZwIXAv2ttX2Af7gcyWeMMe2Bs4Act7P40CdAX2ttf2AzcKfLeZqMMSYYeBw4B+gNTDLG9HY3lU94gV9Za3sBw4Gf+el+fuMXwAa3QzSDR4HZ1tqewAACY59bPbWRfkdtZOunNtL/+Kx9bPWFGnAz8DdrbTWAtTbf5Ty+9AjwW8BvLyy01s6x1nobHi4GMtzM08SGAVuttdnW2hrgNZwDKL9ird1rrV3ZcL8M5wOrnbupfMMYkwGcBzzrdhZfMsbEAqcD0wGstTXW2mJ3U0kjqY30I2ojWz+1kf7F1+2jPxRq3YHTjDFLjDGfG2OGuh3IF4wxE4Dd1tqv3c7SjK4FPnI7RBNqB+Qe8ngXfvrh/A1jTEdgELDE3SQ+80+cA8N6t4P4WGdgP/CfhiEszxpjotwOJY2iNtJ/qY1s5dRG+gWfto+epnojXzLGzAXSDvPSXTj7kIDTfTwUeMMY09m2wuksj7KfvwPGNW8i3/ih/bTWvtewzV04wwNebs5sPmYO81yr+z1tLGNMNDAD+KW1ttTtPE3NGHM+kG+tXWGMGeV2Hh/zAIOBqdbaJcaYR4E7gLvdjSWgNhK1kf5CbaQfCaA20qftY6so1Ky1Y4/0mjHmZuDthkZnqTGmHkjGqW5blSPtpzGmH9AJ+NoYA85Qh5XGmGHW2rxmjNgkfuj/E8AYczVwPjCmNR5M/IBdQPtDHmcAe1zK4lPGmBCcBuhla+3bbufxkVOBCcaYc4FwINYY85K19kqXc/nCLmCXtfabs75v4TRE0gKojVQb6SfURvqXQGkjfdo++sPQx3eB0QDGmO5AKFDgaqImZq1da61NtdZ2tNZ2xPmlGNwaG6CjMcaMB24HJlhrK9zO08SWAd2MMZ2MMaHARGCmy5manHGOlKYDG6y1D7udx1estXdaazMa/iYnAp/5YQMEQMNnTa4xpkfDU2OA9S5GksZTG+lH1Ea2fmoj/Yuv28dW0aN2FM8Bzxlj1gE1wNV+doYp0DwGhAGfNJwZXWytvcndSE3DWus1xtwKfAwEA89Za7NcjuULpwJTgLXGmNUNz/3OWjvLxUxy4qYCLzccQGUD17icRxpHbaR/URvZ+qmN9D8+ax+NPq9FRERERERaFn8Y+igiIiIiIuJXVKiJiIiIiIi0MCrUREREREREWhgVaiIiIiIiIi2MCjUREREREZEWRoWaiIiIiIhIC6NCTUREREREpIVRoSYiIiIiItLC/D+qaWFdW+0ytQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@np.vectorize\n",
    "def sigmoid(x):\n",
    "    x = np.array(x)\n",
    "    return 1 / (1+ np.e ** -x)\n",
    "\n",
    "@np.vectorize\n",
    "def sigmoid_derivative(x):\n",
    "    return sigmoid(x) * (1 - sigmoid(x))\n",
    "\n",
    "fig,ax  = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].set_title(\"Sigmoid activation function\")\n",
    "ax[0].plot(testInput, sigmoid(testInput))\n",
    "ax[0].plot(testInput, sigmoid_derivative(testInput))\n",
    "ax[0].legend([\"Sigmoid\", \"Derivative of sigmoid\"])\n",
    "\n",
    "ax[1].set_title(\"Sigmoid Derivative\")\n",
    "ax[1].plot(testInput, sigmoid_derivative(testInput))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Relu\n",
    "\n",
    "$$ $$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<matplotlib.lines.Line2D at 0x7fe464da3898>]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "@np.vectorize\n",
    "def ReLU(x):\n",
    "    return np.maximum(0.0, x )\n",
    "\n",
    "@np.vectorize\n",
    "def ReLU_derivative(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1\n",
    "\n",
    "fig,ax  = plt.subplots(1,2,figsize=(15,5))\n",
    "ax[0].set_title(\"The ReLU activation function\")\n",
    "ax[0].plot(testInput, ReLU(testInput))\n",
    "ax[0].plot(testInput, ReLU_derivative(testInput))\n",
    "ax[0].legend([\"ReLU\", \"Derivation of ReLU\"])\n",
    "\n",
    "\n",
    "ax[1].set_title(\"Derivation of ReLU\")\n",
    "ax[1].plot(testInput, ReLU_derivative(testInput))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "### Defining a simple Neural Network\n",
    "\n",
    "  #### We define a simple ANN with \n",
    "      1. one input layer with 32 x 32 nodes as it is the image size.\n",
    "      2. one hidden layer with 16 nodes\n",
    "      3. one output layer with 10 nodes (one for each number (label))\n",
    "     \n",
    "  #### We initlize the weights to a random value between 0 and 1 (We will optimize this initliation in later stages)\n",
    "  ### Terminology of  variable names in the network\n",
    "      \n",
    "      a = (vectorized) activations\n",
    "      z = (vectorized) the intermediate output when weights are added with activations\n",
    "      \n",
    "  \n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        self.inputLayerSize = 1024\n",
    "        self.hiddenLayerSize = 16\n",
    "        self.outputLayerSize = 10\n",
    "        self.initilize_weights()\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "    \n",
    "         \n",
    "    def initilize_weights(self):\n",
    "        self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "    \n",
    "    \n",
    "    def feedForward(self, x):\n",
    "        #propogate inputs through network\n",
    "        # x is input into network = a0\n",
    "        #return the activation of the last layers = probabilities of the classes\n",
    "        \n",
    "        \n",
    "        self.z1 = np.dot(x, self.W1)\n",
    "        self.a1 = sigmoid(self.z1) #sigmoid activation function\n",
    "        \n",
    "        self.z2 = np.dot(self.a1, self.W2)\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        \n",
    "        return self.a2\n",
    "        \n",
    "        \n",
    "    def backward():\n",
    "        None\n",
    "    \n",
    "    def costFunction():\n",
    "        None\n",
    "        \n",
    "            \n",
    "    def train():\n",
    "        None\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer size : 1024\n",
      "\n",
      "Hidden layer size : 16\n",
      "\n",
      "Output layer size : 10\n",
      "\n",
      "Parameters to train in W1: 16384\n",
      "\n",
      "Parameters to train in W2: 160\n",
      "\n",
      "Total parameters:  16544\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "NN.summary()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Labels:  [0]\n",
      "[0.99982468 0.99940693 0.99988305 0.99961411 0.99964417 0.99974582\n",
      " 0.9995916  0.99933666 0.99975547 0.99541231] \n",
      "\n",
      "\n",
      "Labels:  [8]\n",
      "[0.99982468 0.99940693 0.99988305 0.99961411 0.99964417 0.99974582\n",
      " 0.9995916  0.99933666 0.99975547 0.99541231] \n",
      "\n",
      "\n",
      "Labels:  [1]\n",
      "[0.99982468 0.99940693 0.99988305 0.99961411 0.99964417 0.99974582\n",
      " 0.9995916  0.99933666 0.99975547 0.99541231] \n",
      "\n",
      "\n",
      "Labels:  [2]\n",
      "[0.99982468 0.99940693 0.99988305 0.99961411 0.99964417 0.99974582\n",
      " 0.9995916  0.99933666 0.99975547 0.99541231] \n",
      "\n",
      "\n",
      "Labels:  [1]\n",
      "[0.99982468 0.99940693 0.99988305 0.99961411 0.99964417 0.99974582\n",
      " 0.9995916  0.99933666 0.99975547 0.99541231] \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for i in range(5):\n",
    "    \n",
    "    output = NN.feedForward(X_training_scaled[i])\n",
    "    print(\"Labels: \", y_training[i])\n",
    "    print(output , \"\\n\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Before we train the network with sigmoid activation function it is good the get better initlization\n",
    "##### As almost all values are close to 1 the sigmoids vanishing gradient will make it hard (or very slow) to train."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight initilization\n",
    "\n",
    "It is a good idea to initlize our weight in a better way than we've done so far.\n",
    "The initila initlization used in the forward pass was random values between 0 and 1.\n",
    "\n",
    "A good idea for sigmoid is to intilize the values within the range:\n",
    "\n",
    "$$ \\frac {-1}{\\sqrt n} , \\frac {1}{\\sqrt n}$$\n",
    "\n",
    "The weights should be over the normal distrubution and we use the defined helper function from tutorial 4 to get that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAD4CAYAAAAAczaOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAQYElEQVR4nO3df6yeZX3H8fdHOnD+LD8OyNqysthsQ+OUnSDOTI31Bz8M5Q/YIG5U16RZxOnGflDnEhKNCc5tOONG1lhmWYyKTEOjOO0KzixZmUUNCqg9Q0ePZfQYkM0RdZ3f/XGuzmM57Tk9z3Oe08P1fiUnz31f93U/9/dqw+e5uHo/90lVIUnqw1OWugBJ0ugY+pLUEUNfkjpi6EtSRwx9SerIiqUu4GhOO+20Wrt27VKXIUnLyt133/2dqhqb7dhxHfpr165lz549S12GJC0rSf79SMdc3pGkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4c19/IlY5na7d8akmu+63rL16S6+rJwZm+JHXE0Jekjhj6ktQR1/S1rC3Vurq0XDnTl6SOGPqS1BFDX5I6YuhLUkcMfUnqyJyhn+SmJAeSfHVG23uSfC3JPUk+kWTljGNvSzKR5OtJXjuj/YLWNpFky/CHIkmay3xm+h8ELjisbSfw/Kp6AfAN4G0ASc4BrgCe18756yQnJDkB+CvgQuAc4MrWV5I0QnOGflV9HnjksLbPVtXBtrsbWN22NwAfqaofVNU3gQngvPYzUVUPVNUPgY+0vpKkERrGmv5vAZ9u26uAfTOOTba2I7U/QZLNSfYk2TM1NTWE8iRJhwwU+kneDhwEPnSoaZZudZT2JzZWba2q8aoaHxsbG6Q8SdJhFvwYhiQbgdcB66vqUIBPAmtmdFsN7G/bR2qXJI3Igmb6SS4ArgUuqarHZxzaAVyR5KQkZwPrgH8FvgCsS3J2khOZ/sfeHYOVLkk6VnPO9JN8GHgFcFqSSeA6pu/WOQnYmQRgd1X9dlXdm+QW4D6ml32urqr/be/zZuAzwAnATVV17yKMR3rSW8qHzPkLXJa/OUO/qq6cpXnbUfq/C3jXLO23A7cfU3WSpKHyG7mS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjiz42TvSTEv5LVFJ8+dMX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZM7QT3JTkgNJvjqj7ZQkO5Psba8nt/YkeV+SiST3JDl3xjkbW/+9STYuznAkSUczn+fpfxB4P3DzjLYtwK6quj7JlrZ/LXAhsK79vBi4EXhxklOA64BxoIC7k+yoqkeHNRBN87n2ko5mzpl+VX0eeOSw5g3A9ra9Hbh0RvvNNW03sDLJmcBrgZ1V9UgL+p3ABcMYgCRp/ha6pn9GVT0E0F5Pb+2rgH0z+k22tiO1S5JGaNi/LjGztNVR2p/4BslmYDPAWWedNbzKJA1sqZYPv3X9xUty3Sejhc70H27LNrTXA619Elgzo99qYP9R2p+gqrZW1XhVjY+NjS2wPEnSbBYa+juAQ3fgbARum9F+VbuL53zgsbb88xngNUlObnf6vKa1SZJGaM7lnSQfBl4BnJZkkum7cK4HbkmyCXgQuLx1vx24CJgAHgfeCFBVjyR5J/CF1u8dVXX4Pw5LkhbZnKFfVVce4dD6WfoWcPUR3ucm4KZjqk6SNFR+I1eSOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUkWE/cE34THtJxy9n+pLUEUNfkjpi6EtSRwx9SeqIoS9JHfHuHUnHvaW8I+7J9qsanelLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHBgr9JL+X5N4kX03y4SRPTXJ2kruS7E3y0SQntr4ntf2JdnztMAYgSZq/BYd+klXAW4Dxqno+cAJwBfBu4IaqWgc8Cmxqp2wCHq2q5wI3tH6SpBEadHlnBfDTSVYATwMeAl4J3NqObwcubdsb2j7t+PokGfD6kqRjsODQr6pvA38GPMh02D8G3A18t6oOtm6TwKq2vQrY18492Pqfevj7JtmcZE+SPVNTUwstT5I0i0GWd05mevZ+NvAzwNOBC2fpWodOOcqxHzdUba2q8aoaHxsbW2h5kqRZDLK88yrgm1U1VVX/A3wc+BVgZVvuAVgN7G/bk8AagHb82cAjA1xfknSMBgn9B4Hzkzytrc2vB+4D7gQua302Are17R1tn3b8jqp6wkxfkrR4BlnTv4vpf5D9IvCV9l5bgWuBa5JMML1mv62dsg04tbVfA2wZoG5J0gIM9Juzquo64LrDmh8Azpul7/eBywe5niRpMH4jV5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOmLoS1JHBnoMw/Fu7ZZPLXUJknRccaYvSR0x9CWpI4a+JHXE0Jekjhj6ktSRJ/XdO5I0qKW6C/Bb11+8KO/rTF+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1ZKDQT7Iyya1Jvpbk/iQvSXJKkp1J9rbXk1vfJHlfkokk9yQ5dzhDkCTN16Az/b8E/qGqfgH4JeB+YAuwq6rWAbvaPsCFwLr2sxm4ccBrS5KO0YJDP8mzgJcB2wCq6odV9V1gA7C9ddsOXNq2NwA317TdwMokZy64cknSMRtkpv9zwBTwt0m+lOQDSZ4OnFFVDwG019Nb/1XAvhnnT7a2n5Bkc5I9SfZMTU0NUJ4k6XCDhP4K4Fzgxqp6EfDf/HgpZzaZpa2e0FC1tarGq2p8bGxsgPIkSYcbJPQngcmquqvt38r0h8DDh5Zt2uuBGf3XzDh/NbB/gOtLko7RgkO/qv4D2Jfk51vTeuA+YAewsbVtBG5r2zuAq9pdPOcDjx1aBpIkjcagT9n8HeBDSU4EHgDeyPQHyS1JNgEPApe3vrcDFwETwOOtryRphAYK/ar6MjA+y6H1s/Qt4OpBridJGozfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpIwOHfpITknwpySfb/tlJ7kqyN8lHk5zY2k9q+xPt+NpBry1JOjbDmOm/Fbh/xv67gRuqah3wKLCptW8CHq2q5wI3tH6SpBEaKPSTrAYuBj7Q9gO8Eri1ddkOXNq2N7R92vH1rb8kaUQGnem/F/gj4Edt/1Tgu1V1sO1PAqva9ipgH0A7/ljr/xOSbE6yJ8meqampAcuTJM204NBP8jrgQFXdPbN5lq41j2M/bqjaWlXjVTU+Nja20PIkSbNYMcC5LwUuSXIR8FTgWUzP/FcmWdFm86uB/a3/JLAGmEyyAng28MgA15ckHaMFz/Sr6m1Vtbqq1gJXAHdU1euBO4HLWreNwG1te0fbpx2/o6qeMNOXJC2exbhP/1rgmiQTTK/Zb2vt24BTW/s1wJZFuLYk6SgGWd75f1X1OeBzbfsB4LxZ+nwfuHwY15MkLYzfyJWkjhj6ktQRQ1+SOmLoS1JHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpIwsO/SRrktyZ5P4k9yZ5a2s/JcnOJHvb68mtPUnel2QiyT1Jzh3WICRJ8zPITP8g8PtV9YvA+cDVSc4BtgC7qmodsKvtA1wIrGs/m4EbB7i2JGkBFhz6VfVQVX2xbf8XcD+wCtgAbG/dtgOXtu0NwM01bTewMsmZC65cknTMhrKmn2Qt8CLgLuCMqnoIpj8YgNNbt1XAvhmnTbY2SdKIDBz6SZ4B/D3wu1X1n0frOktbzfJ+m5PsSbJnampq0PIkSTMMFPpJforpwP9QVX28NT98aNmmvR5o7ZPAmhmnrwb2H/6eVbW1qsaranxsbGyQ8iRJhxnk7p0A24D7q+ovZhzaAWxs2xuB22a0X9Xu4jkfeOzQMpAkaTRWDHDuS4HfBL6S5Mut7Y+B64FbkmwCHgQub8duBy4CJoDHgTcOcG1J0gIsOPSr6p+ZfZ0eYP0s/Qu4eqHXkyQNzm/kSlJHDH1J6oihL0kdMfQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SeqIoS9JHTH0Jakjhr4kdcTQl6SOGPqS1BFDX5I6YuhLUkcMfUnqiKEvSR0x9CWpI4a+JHXE0Jekjhj6ktQRQ1+SOjLy0E9yQZKvJ5lIsmXU15ekno009JOcAPwVcCFwDnBlknNGWYMk9WzUM/3zgImqeqCqfgh8BNgw4hokqVsrRny9VcC+GfuTwItndkiyGdjcdr+X5Osjqm2YTgO+s9RFjJhj7oNjHpG8e6DTf/ZIB0Yd+pmlrX5ip2orsHU05SyOJHuqanyp6xglx9wHx7z8jXp5ZxJYM2N/NbB/xDVIUrdGHfpfANYlOTvJicAVwI4R1yBJ3Rrp8k5VHUzyZuAzwAnATVV17yhrGJFlvTy1QI65D455mUtVzd1LkvSk4DdyJakjhr4kdcTQH4IkpyTZmWRvez35KH2fleTbSd4/yhqHbT5jTvLCJP+S5N4k9yT59aWodVBzPTokyUlJPtqO35Vk7eirHJ55jPeaJPe1v9NdSY54T/hyMd/HwyS5LEklWba3cBr6w7EF2FVV64Bdbf9I3gn800iqWlzzGfPjwFVV9TzgAuC9SVaOsMaBzfPRIZuAR6vqucANwGBfq1lC8xzvl4DxqnoBcCvwp6Otcrjm+3iYJM8E3gLcNdoKh8vQH44NwPa2vR24dLZOSX4ZOAP47IjqWkxzjrmqvlFVe9v2fuAAMDayCodjPo8OmflncSuwPslsX0RcDuYcb1XdWVWPt93dTH/fZjmb7+Nh3sn0B9z3R1ncsBn6w3FGVT0E0F5PP7xDkqcAfw784YhrWyxzjnmmJOcBJwL/NoLahmm2R4esOlKfqjoIPAacOpLqhm8+451pE/DpRa1o8c055iQvAtZU1SdHWdhiGPVjGJatJP8IPGeWQ2+f51u8Cbi9qvYtl0ngEMZ86H3OBP4O2FhVPxpGbSM056ND5tlnuZj3WJL8BjAOvHxRK1p8Rx1zm7DdALxhVAUtJkN/nqrqVUc6luThJGdW1UMt4A7M0u0lwK8meRPwDODEJN+rquP2dwoMYcwkeRbwKeBPqmr3IpW6mObz6JBDfSaTrACeDTwymvKGbl6PSknyKqY//F9eVT8YUW2LZa4xPxN4PvC5NmF7DrAjySVVtWdkVQ6JyzvDsQPY2LY3Arcd3qGqXl9VZ1XVWuAPgJuP58CfhznH3B618Qmmx/qxEdY2TPN5dMjMP4vLgDtq+X7rcc7xtqWOvwEuqapZP+yXmaOOuaoeq6rTqmpt++93N9NjX3aBD4b+sFwPvDrJXuDVbZ8k40k+sKSVLZ75jPnXgJcBb0jy5fbzwqUpd2HaGv2hR4fcD9xSVfcmeUeSS1q3bcCpSSaAazj63VvHtXmO9z1M/9/qx9rf6bJ+ftY8x/yk4WMYJKkjzvQlqSOGviR1xNCXpI4Y+pLUEUNfkjpi6EtSRwx9SerI/wEqZnirSgTFUwAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from scipy.stats import truncnorm\n",
    "\n",
    "def truncated_normal(mean=0, sd=1, low=0, upp=10):\n",
    "    return truncnorm(\n",
    "        (low - mean) / sd, (upp - mean) / sd, loc=mean, scale=sd)\n",
    "X = truncated_normal(mean=0, sd=0.4, low=-0.5, upp=0.5)\n",
    "s = X.rvs(10000)\n",
    "plt.hist(s)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weights better distributed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        self.inputLayerSize = 1024\n",
    "        self.hiddenLayerSize = 16\n",
    "        self.outputLayerSize = 10\n",
    "        self.initilize_weights()\n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "    \n",
    "         \n",
    "    def initilize_weights(self):\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "    \n",
    "        rangeW1 = 1 / np.sqrt(self.inputLayerSize) #Get the range to be as defined above \n",
    "        distrubutionW1 = truncated_normal(mean=0,sd=1, low=-rangeW1, upp=rangeW1) # Create a normal distrubtion trunctaed within the range\n",
    "        self.W1 = distrubutionW1.rvs((self.inputLayerSize,self.hiddenLayerSize)) #Randomly distribute the normal distrubtion with correct dimensions \n",
    "        \n",
    "        rangeW2 = 1 / np.sqrt(self.hiddenLayerSize)\n",
    "        distrubutionW2 = truncated_normal(mean=0, sd=1, low=-rangeW2, upp=rangeW2)\n",
    "        self.W2 = distrubutionW2.rvs((self.hiddenLayerSize, self.outputLayerSize))\n",
    "    \n",
    "    \n",
    "    def feedForward(self, x):\n",
    "        #propogate inputs through network\n",
    "        # x is input into network = a0\n",
    "        #return the activation of the last layers = probabilities of the classes\n",
    "        \n",
    "        \n",
    "        self.z1 = np.dot(x, self.W1)\n",
    "        self.a1 = sigmoid(self.z1) #sigmoid activation function\n",
    "        \n",
    "        self.z2 = np.dot(self.a1, self.W2)\n",
    "        self.a2 = sigmoid(self.z2)\n",
    "        \n",
    "        return self.a2\n",
    "        \n",
    "        \n",
    "    def backward():\n",
    "        None\n",
    "    \n",
    "    def costFunction():\n",
    "        None\n",
    "        \n",
    "            \n",
    "    def train():\n",
    "        None\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feedforward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label: [0]\n",
      "[0.61203287 0.64257953 0.53393847 0.54966332 0.54207879 0.53887957\n",
      " 0.55231639 0.5432149  0.64110247 0.44149603]\n",
      "Label: [8]\n",
      "[0.61523972 0.64043963 0.53363865 0.54420737 0.5418447  0.53840078\n",
      " 0.55548714 0.54120562 0.63819848 0.44306874]\n",
      "Label: [1]\n",
      "[0.61491502 0.63959372 0.52890024 0.53826784 0.53804181 0.54698187\n",
      " 0.5459276  0.54472392 0.65278513 0.43590236]\n",
      "Label: [2]\n",
      "[0.61443661 0.64345606 0.52576082 0.5426554  0.54109742 0.54398686\n",
      " 0.54156497 0.55104049 0.64886752 0.44749211]\n",
      "Label: [1]\n",
      "[0.60959294 0.64139381 0.53209468 0.543189   0.53983279 0.54135677\n",
      " 0.54685133 0.54377048 0.6454084  0.43970828]\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "for i in np.arange(5):\n",
    "    print(\"Label:\", y_training[i])\n",
    "    print(NN.feedForward(X_training_scaled[i]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The better range of weights values made the output of the network more suitable for training as it outputed an average of 50% for each label. As we are using sigmoid which is subject to vanishing gradients, it is desireable.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Backpropogate\n",
    "\n",
    "    A network is not useful if it is not trained to generelize (predict label of unseen data). In order to train the model we need to implement backprogation. We will improve our model in a few step in order to train the model.\n",
    "    \n",
    "    1. Add biases to increase the flexibillity of the network in training. \n",
    "    2. Implement cost function and the derivative of the cost function\n",
    "    3. Implement backpropogation as a class method (backwards) that returns the partial derivatives of the cost functions to the weight matrix.\n",
    "    4. Set learning rate\n",
    "    5. Update the weight matrix in opposite direction of the partial derivatives of the weight matrix.\n",
    "    6. Implement performance metrics to be used when analysing different network architectures and hyper-parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Add bias\n",
    "\n",
    "The feedforward method in our network right now is defined by taking the weighted sum and feed into the activation function sigmoid. That is delta = activation function:\n",
    " $$\\delta\\big(w_{1}x_{1}+w_{2}x_{2}+..+w_{i}x_{i}\\big) $$ \n",
    " \n",
    "When adding the bias to each neuron the neuron gets a broader range of when it can be active. An important aspect when implementing the ReLU, that is always returing 0 if weighted sum is 0 or less.\n",
    "\n",
    "$$\\delta\\big(w_{1}x_{1}+w_{2}x_{2}+..+w_{i}x_{i} + b\\big) $$ "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Cost function Mean Squared Error\n",
    "In order to get use backprogation we need a cost function that we can take the derivative of to get the partial derivative of the cost function in respect to the weight vectors. \n",
    "\n",
    "\n",
    "### We define a cost function of squared error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(-0.0001, 0.0005)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZ0AAAEWCAYAAAC9qEq5AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAgAElEQVR4nOzdd3gU1f7H8fdJbxAggVAChBYgkEISgvQgSBEFEZAmAgrYuNxrQfF3LVe8eO0oCigqVRQQaSqIIoQuEHoPAQKEmlBSSd3z+2M2MYSUTdnMbnJez7MPW2bOfHZJ9puZOXOOkFKiKIqiKBXBRu8AiqIoStWhio6iKIpSYVTRURRFUSqMKjqKoihKhVFFR1EURakwqugoiqIoFUYVHcWiCSGeFUJcE0IkCyE8KnC7/yeE+KaitlfS7QshxgohtldkJkUpD6roKCYRQowUQkQav/yvCCHWCyG6lLHNGCFEryJetwc+AXpLKd2klDfKsr0ithMuhIjN+5yU8l0p5XhzbM8UebcvhPARQkghhF1p2yvuszY3IcQCIcR/zdR2mT+f0rQnhHhBCHFVCJEghJgnhHAsj+1XdqroKMUSQrwIfAq8C3gBjYDZwEAzb9oLcAKOmXk7SjGEELZ6Z7AkQog+wFSgJ+ADNAXe1jOT1ZBSqpu6FXoD3IFkYGgRyziiFaXLxtungKPxNU/gF+A2cBPYhvbHzmLAANwxtv9KvjZ9gRRAGl/fhPbLLQG7PMtFAOON98cC24GPgFvAOaBfnmVrAfONGW8BqwFXYwaDcTvJQH3gP8B3edYdgFb8bhu32TrPazHAy8BhIAFYBjgV8lmdB0KM9x83vh8/4+PxwGrj/dztAxfyfA7JQMfi3mu+bRb4WQM/AleNmbcCbfKsswCYA6wz/j/0AjyAn4FEYC/wX2B7nnVaAX8Y/59PAY8Zn58IZAIZxu3/XEjOTsZ2E4z/dsr3GffK89iUz2cH8LmxvZNAz9K2V0DW74F38zzuCVzV+/fVGm5qT0cpTke0vY1VRSzzb+A+IAgIBMKA142vvQTEArXR9lz+D5BSytFov9wPS+3Q2Qd5G5RSRgFtjA9rSCnvNzFvB7QvPE/gA+BbIYQwvrYYcDG2WweYIaVMAfoBl4053KSUl/M2KITwBX4A/mV8H+uAn4UQDnkWewzoCzQBAtC+9AqyBQg33u8GnAW653m8pYB1uhn/rWHMt8uE95qriM96PdDC+FnsB5bkW3UkMB2ohlbgZqEVoLrAGOMNACGEK1rB+d7Y3ghgthCijZRyrrHtD4zbfzh/RiFELeBXYCZacfsE+NXE83hFfT5njZ/PW8BK43ZK215ebYBDeR4fArwq8ryjtVJFRymOBxAvpcwqYplRwDQp5XUpZRzaYYbRxtcygXpAYyllppRymzT+aWgm56WUX0sps4GFxm17CSHqoRWXZ6SUt4xZCvqCL8gw4Fcp5R9Syky0vQtntL/Mc8yUUl6WUt5E2xsIKqStLfxdZLoC/8vzuDsFF53CFPheTV1ZSjlPSpkkpUxH+0s/UAjhnmeRNVLKHVJKA9r/42DgLSllqpTyuHGbOR4CYqSU86WUWVLK/cBPwBAT4/QHTkspFxvX/wFt7+SeAlUC14FPjf/Xy9AKdP8ytJeXG9oeVI6c+9XKqf1KSxUdpTg3AM9iTqrWRztslOO88TmAD4Fo4HchxFkhxFTzxMx1NeeOlDLVeNcNaAjclFLeKkWbd70/45fwRaBBQdsFUo3bLMgWoKsQoi5gi3YorrMQwgftUObBEuQq7L0WSwhhK4R4TwhxRgiRiHa4CbS9ghwX89yvDdjley7v/cZAByHE7Zwb2h8jdU16J/f+DGF83KCAZU11Kd8fOHl/LssqGaie53HO/aRyar/SUkVHKc4uIA14pIhlLqN96eRoZHwO41/SL0kpm6L91fqiEKKncbmS7vGkGP91yfOcqV9qF4FaQogaBbxWXI673p/xEFZD4JKJ2/57Q1JGoxWlycBWKWUSWvGYiHZ+xFCKfCZtOt/jkWgdQXqhFTsf4/OikHXigCzAO89zDfPcvwhskVLWyHNzk1I+W8j288v/MwTaz1HOZ5xC4f/vhbXdIN/hxtyfy1K2l9cxtEPJOQKBa9JMPSwrE1V0lCJJKROAN4FZQohHhBAuQgh7IUQ/IUTOuYEfgNeFELWFEJ7G5b8DEEI8JIRobvzlTwSyjTeAa2i9fkzNEof2JfS48S/1J4FmJq57Be0cxmwhRE3je8g5dn8N8Mh3aCmv5UB/IURPYzful4B0YKep2fPZAkzi70NpEfke5xeH1hHA5M+qAPk/62po7+EG2pfvu0WtbDyEtxL4j/FnoBXwRJ5FfgF8hRCjjZ+tvRCivRCidSHbz2+dcf2RQgg7IcQwwM/YLmh7gMON7YZy92G7wj6fOsBk4zpDgdbG7ZS2vbwWAU8JIfyEEDXRzmEuKGJ5xUgVHaVYUspPgBfRfrHi0P6qnYTW+wu0XkyRaL23jqCdlM65JqMFsBHtcMQuYLaUMsL42v/QitVtIcTLJsaZAExB+7JsQ8m++EejnZs4iXa8/1/G93cSrXCeNWa56xCMlPIUWk+zz4F4tD22h6WUGSXYdl5b0L70txby+C7GQ2fTgR3GfPeVYpv5P+tFaIebLgHHgb9MaGMS2l7RVbROGT+gFS6Me2y9geFoexNXgffRejYCfAv4Gbe/Ol+7GPcQHkIr6DeAV4CHpJTxxkXeQPsD4xbaOcPv86xb2OezG+3nL974+pA8eyKlaS9v3t/QOm9sRvscz6N1VlCKIcx7TldRlMpKCPE+UFdKOabYhSuYEGIsWlf6Ml3ArJQ/taejKIpJhBCthBABQhMGPEXRXekV5R66Fh0hRF8hxCkhRHRBvZqEEI5CiGXG13cbe/jkvPaa8flTxquDi2zTOAzHOSHEQeOtsC6tiqIUrBraeZ0UtPNcHwNrdE2kWB3dDq8Zh9WIAh5Au3hwLzDC2P8/Z5nngAAp5TNCiOHAICnlMCGEH9rx5DC0LpAb0a5gp7A2hRALgF+klCsq5A0qiqIo99BzTycMiJZSnjWekF3KvWN5DeTvC9BWAD2NvaAGAkullOlSynNo14GEmdimoiiKopNyGZW1lBpw98VlsWjDVhS4jJQySwiRgHaFfAPu7m0Ty98XkRXV5nQhxJvAn8BU45XYdxFCTES7ZgJnZ+eQhg0b5l+kWCmZkrg7kjouAhe7e0Yl0ZXBYMDGxrJO5dlmp+GSGssdB0+yHAu6jEZflviZgcpVUiqXaSRwMcmAqx14OJcuV1RUVLyUsnZBr+lZdAr6Ns5/rK+wZQp7vqBPKKfN19C6cToAc4FXgWn3LKyNEzUXIDQ0VEZGRhaUvUiZ2QbaT/uNgMaeLHoyrMTrm1NERATh4eF6x7jX3B6k3L6O65SjcO/wYbqy1M9M5SoZlcs0P+2L5aUfDzEl1Innh/QsfoUCCCHyjy6RS8/yGsvdVzR78/fVwvcsYxyGxR1tBNvC1i20TSnlFalJRxtp2GzVwN7Whvsb2bE1Ko7o68nm2kzlEjYB19RYOFeSoccURSlPUkoW7oqhWW1X/DzMUx70LDp7gRZCiCbG0XqHA2vzLbOWv0eyHQJsMo6ltBbtamJHIUQTtAvA9hTVpnHAx5whTB4BjprzzYV72+Nga8OiXTHm3Ezl0eZRMu2qwZ6v9U6iKFXWgYu3ORybwJhOPggzHXHQregYRy2eBGwATgDLpZTHhBDThBADjIt9izY8STTaFfFTjeseQ+uyeRz4DXheSpldWJvGtpYIIY6gXTHvyd9XzJtFdUfBw4H1WbEvlsS0THNuqnKwd+JKvQfg1Dq4fbH45RVFKXeLdsbg5mjHo8HexS9cSnqe00FKuY6/x0LKee7NPPfTgKGFrDsdbaiKYts0Pm/qfCzlZmwnH37aH8uKyFie7NKkojdvUTIzM4mNjSUtLa3QZdLbPU+K3wg4FwtOlnNY0t3dnRMnTugd4x4qV8kUlcvJyQlvb2/s7e0rOJXluJ6Uxq9HrjCqQ2PcHM1XGnQtOpWdv7c7IY1rsnBXDGM7+WBjY1knyCtSbGws1apVw8en8N32pKQkqmXEQWYKeLUEYRk9epKSkqhWzfKmSVG5SqawXFJKbty4QWxsLE2aVN0/Dn/YfZHMbMkTHfMP9l2+LOO3uhIb28mH8zdSiYi6rncUXaWlpeHh4VH8cWJXTzBkwZ3bFRNMqfKEEHh4eBS5F17ZZWQZWLL7PN18a9O0tklTMpWaKjpm1rdtXbyqOzJ/R4zeUXRn0olJx2pg6wgpceYPpChG5jppbi3WH73C9aR0xnXyMfu2VNExM3tbG0bf15htp+NV92lTCKHt7WSmQkZK8csrilImUkq+3X6OprVd6e5b4PWc5UoVnQowPKyR6j5dEi61tPM5KfHFL1uBDh48yLp19/RRyTVixAgCAgKYMWNGuW1z7dq1vPfeewCsXr2a48ePF7OGopTM/gu3OBybwLjOTSrkvLMqOhXA081RdZ8uCRs7cK4Fd25BdpbeaXIVVXSuXr3Kzp07OXz4MC+88EK5bXPAgAFMnaoNlq6KjmIO87bHUN3JjsHBDYpfuByoolNBxnbyITUjmx8jY/WOYh1cPQEJqeU35fyiRYsICAggMDCQ0aNHA3D+/Hl69uxJQEAAPXv25MKFCwD8+OOPtG3blsDAQPr27UtGRgZvvvkmy5YtIygoiGXLlt3Vdu/evbl+/TpBQUFs27aN8PBwcoZQio+Px8fHB4AFCxbw6KOP0rdvX1q0aMErr7yS28Zvv/1GcHAwgYGB9OzZM3f5SZMmsXPnTtauXcuUKVMICgrizJkzHD58mPvuu4+AgAAGDRrErVu3AAgPD+fVV18lLCwMX19ftm3bVm6foVK5xN5KZf3RK4zo0AgXh4rpzKy6TFeQnO7Ti3bFMK6Kd59+++djHL+ceM/z2dnZ2Nra/v1E5h3gBtifLbZNv/rVeevhNoW+fuzYMaZPn86OHTvw9PTk5s2bAEyaNIknnniCMWPGMG/ePCZPnszq1auZNm0aGzZsoEGDBly8eBEHBwemTZtGZGQkX3zxxT3tr127loceeoiDBw8Wm/XgwYMcOHAAR0dHWrZsyT/+8Q+cnJyYMGECW7dupUmTJrn5cnTq1IkBAwbw0EMPMWTIEAAGDhzIrFmz6N69O2+++SZvv/02n376KQBZWVns2bOHdevW8fbbb7Nx48ZicylVz6Jd5xFC8ERHnwrbptrTqUA53ac3naza3adNZmsPUmpdqMto06ZNDBkyBE9PTwBq1aoFwK5duxg5ciQAo0ePZvv27QB07tyZsWPH8vXXX5OdnV3m7efVs2dP3N3dcXJyws/Pj/Pnz/PXX3/RrVu33OtEcvIVJiEhgYSEBLp37w7AmDFj2Lp1a+7rjz76KAAhISHExMSUa36lckhJz+KHPRfo27YuDWo4V9h21Z5OBerbti713Z34ZvtZevl56R1HN4Xtkdxz8Z40wLXjYO8EHs3LtE0ppUndYnOW+fLLL9m9eze//vorXbp04dChQyXanp2dHQaDAeCe6z8cHR1z79va2pKVlWVyPlPlbCOnfUXJ76f9sSSlZfFk54q9IFbt6VQge1sbxnb24a+zNzl6KUHvOJZP2GjndtKTILNsF+717NmT5cuXc+OGdo4o5/BVp06dWLp0KQBLliyhS5cuAJw5c4YOHTowbdo0PDw8uHjxItWqVSMpKcmk7fn4+LBv3z4AVqwofrLajh07smXLFs6dO3dXvrzybt/d3Z0aNWrknq9ZvHhx7l6PohTHYJDM3xFDYMMaBDeq2DmsVNGpYMPaN8LVwZZvthV/nkIBXDwAAall6z7dpk0b/v3vf9O9e3cCAwN58cUXAZg5cybz588nICCAxYsX89lnnwEwZcoU/P39adu2LZ06dSIwMJAePXpw/PjxAjsS5Pfyyy8zZ84cOnXqRHx88dlr167N3LlzefTRRwkMDGTYsGH3LDN8+HA+/PBD2rVrx5kzZ/jyyy+ZMmUKAQEBHDx4kDfffLOAlhXlXhFR1zkXn8KTnc03mnShpJTqVsgtJCREltbmzZsLfe3ttcdks9d+lZdvp5a6/dIqKpc5HT9+vNhlEhMTC37hxjkpLx+SMjurfEOZqNBcOlO5Sqa4XKb8jJqDHr+To77+S4ZN/0NmZGUXukxZcgGRspDvVbWno4NxnX0wSMnCnYVOrqfk5eoJMlu7bkdRlDI5dTWJ7dHxPNHRB3vbii8BqujooGEtF/q1rcf3u8+Tkq5O8hbLwRXsnLXx2GT+Gc0VRSmJ+TvO4WRvw8iwRrpsXxUdnTzVtQmJaVn8GKkmLCtWznhsWWlqPDZFKYP45HRWHrjEoHbe1HR10CWDKjo6CW5Uk+BGNZi3I4Zsg/rrvVjONUHYqtGnFaUMFu2MITPbwPiu+s0bpIqOjiZ0bcqFm6n8cfyq3lEsn42t1pMtLQGyM/ROoyhWJzUji0V/nadXay+amXnOnKKooqOj3m3q0rCWM99sO6d3FOuQMx5bSvmNx6YoVcWPkbHcTs1kYremuuZQRUdHtjaCJzs3IfL8LQ5cUD2zimXnCI7VtWt2pKHEq9va2hIUFESbNm0IDAzkk08+yR01oCQ6depU4nUAYmJi+P7773MfR0ZGMnny5FK1ZSpzTLeQ49NPPyU1NbXA17Zt20abNm0ICgrizp075bbNd999967Hpf2/qGqysg18s/0s7RrVILRxTV2zqKKjs6GhDanmZMc329XejknKMJ21s7MzBw8e5NixY/zxxx+5g2GaKmcMtp07d5Z423Bv0QkNDWXmzJmlassU5ppuIUdRRWfJkiW8/PLLHDx4EGfn8hvXK3/RKe3/RVWz4dg1Lt68w9Pdmuo+S6oqOjpzc7RjZFgj1h+5wsWbBf8CK3k4VgdbhzKPUFCnTh3mzp3LF198gZSS7OxspkyZQvv27QkICOCrr74CICIigv79+zNy5Ej8/f0BcHPTjocPGzbsrvl1xo4dy08//URMTAxdu3YlODiY4ODg3C/GqVOnsm3bNoKCgpgxYwYRERE89NBDGAwGfHx8uH3770LavHlzrl27RlxcHIMHD6Z9+/a0b9+eHTt23PNe0tLSGDduHP7+/rRr147NmzcD9063kNe1a9cYNGgQgYGBBAYG5mb85JNPaNu2LW3bts0dsTolJYX+/fsTGBhI27ZtWbZsGTNnzuTy5cv06NGDHj163NX2woULWb58OdOmTWPUqFG57zPHpEmTWLBgAaANF/TWW28RHByMv78/J0+eBCA5OTn3PQUEBPDTTz8xdepU7ty5Q1BQEKNGjbrr/0JKyZQpU2jbti3+/v65I0ZEREQQHh7OkCFDCAkJYdSoUcgq1u1eSsncrWfw8XDhAb+6esdRA35agrGdfZi34xzfbDvL2wPb6h3H/NZPhatH7nnaOTsLbE34kczOgOx0sHfRerQB1PWHfu+VKEbTpk0xGAxcv36dNWvW4O7uzt69e0lPT6dz58707t0bgH379rFw4cLcEaBzDB8+nGXLlvHggw+SkZHBn3/+yZw5c5BS8scff+Dk5MTp06cZMWIEkZGRvPfee3z00Uf88ssvgPaFCGBjY8PAgQNZtWoV48aNY/fu3fj4+ODl5cXIkSN54YUX6NKlCxcuXKBPnz6cOHHirhyzZs0C4MiRI5w8eZLevXsTFRVV5HQLkydPpnv37qxatYrs7GySk5PZt28f8+fPZ/fu3Ugp6dChA927d+fs2bPUr1+fX3/9FdBGuHZ3d+eTTz5h8+bNuSN35xgzZgyRkZG50zDkvM/CeHp6sn//fmbPns1HH33EN998wzvvvIO7uztHjmg/J7du3WLw4MF88cUXBb6flStXcvDgQQ4dOkR8fDzt27enW7duABw4cIBjx45RrVo1+vbty44dO3LH2KsKdp+7yaHYBP77SFtsLWBKFbWnYwHquTszMKgByyIvciM5Xe84ls/WHhCQXfZZWHP+6v39999ZtGgRQUFBdOjQgRs3bnD69GlAmx4gf8EB6NevH5s2bSI9PZ3169fTrVs3nJ2dyczMZMKECfj7+zN06FCTZvscNmxY7l/nS5cuzR17bePGjUyaNImgoCAGDBhAYmLiPYOObt++PXdSulatWtG4cWOioqKK3N6mTZt49tlnAe1cl7u7O9u3b2fQoEG4urri5ubGo48+yrZt2/D392fjxo28+uqrbNu2DXd392LfT0kUNA3Dxo0bef7553OXqVmz6PMQ27dvZ8SIEdja2uLl5UX37t3Zu3cvAGFhYXh7e2NjY0NQUFCVm+ph7taz1HJ1YEiIt95RALWnYzGe6d6UFftiWbjrPC8+4Kt3HPMqZI/kTv6pDYpy+wKk3oK6bbTprUvh7Nmz2NraUqdOHaSUfP755/Tp0+euZSIiInBxcSlwfScnJ8LDw9mwYQPLli1jxIgRAMyYMQMvLy8OHTqEwWDAycmp2CwdO3YkOjqauLg4Vq9ezeuvvw6AwWBg165dRZ4XKa/DRYW14+vry759+1i3bh2vvfYavXv3LtHgonmneYDCp3rIOw2DLOFUD0V9BgVNJVFVnL6WxKaT1/lXrxY42dsWv0IFUHs6FqJ5nWo84OfFol0xamgcU7h4AgZIvXcKAFPExcXxzDPPMGnSJIQQ9OnThzlz5pCZqe09RUVFkZJS/OgHw4cPZ/78+Wzbti23YCUkJFCvXj1sbGxYvHhxbgeEoqZGEEIwaNAgXnzxRVq3bo2HhwegnZfJO1NpQYeWunXrxpIlS3JzX7hwgZYtWxaZu2fPnsyZMwfQOkgkJibSrVs3Vq9eTWpqKikpKaxatYquXbty+fJlXFxcePzxx3n55ZfZv39/se8nr8aNG3P8+HHS09NJSEjgzz//LHad/O87Zypue3v73P+j/J/BsmXLyM7OJi4ujq1btxIWFlbsdiq7r7edxcnepkJnBi2OKjoW5JnuzbidmsnSvWponGI5uIC9a4nGY8s5Cd2mTRt69epF7969eeuttwAYP348fn5+BAcH07ZtW55++mmT/iLu3bs3W7dupVevXjg4aMOKPPfccyxcuJD77ruPqKgoXF1dAQgICMDOzo7AwMACuzAPGzaM77777q5pDWbOnElkZCQBAQH4+fnx5Zdf3rPec889R3Z2Nv7+/gwbNowFCxbc9dd9QT777DM2b96Mv78/ISEhHDt2jODgYMaOHUtYWBgdOnRg/PjxtGvXjiNHjhAWFkZQUBDTp0/P3QubOHEi/fr1u6cjQX4NGzbkscceIyAggFGjRtGuXbuiP1Tg9ddf59atW7Rt25bAwMDczhETJ07MbSevQYMGERAQQGBgIPfffz8ffPABdevqf9JcT9cT01h94DJDQxpSS6chbwpU2PDTFXED+gKngGhgagGvOwLLjK/vBnzyvPaa8flTQJ8StPk5kGxKPnNNbVCUoXN2yo7vbixyyPGysMqpDQqTckPKS/ulvJNQylSmsdah+vVirbkq29QG760/IZtM/UXGxCeXav1KN7WBEMIWmAX0A/yAEUIIv3yLPQXcklI2B2YA7xvX9QOGA23QisxsIYRtcW0KIUKBip0mr4SeDW/G5YQ01h68rHcUy+dcQzufo8ZjU5S7JKZl8t2u8/RtW5fGHq56x7mLnofXwoBoKeVZKWUGsBQYmG+ZgcBC4/0VQE+hnV0cCCyVUqZLKc+h7dWEFdWmsSB9CLxi5vdVJuEta9OqbjW+2noGgxoItGjCRju3k54IWarXn6LkWLzrPEnpWTwX3lzvKPfQs+g0APKevIg1PlfgMlLKLCAB8Chi3aLanASslVJeKaf8ZiGE4OnuTYm6lsymk9f1jlOupDkuynPVTriTUraLRZWqzSw/mzq5k5HNvO3n6OZbm7YNyrd7e3nQs8t0Qf0h8//PF7ZMYc8XVESlEKI+MBQILzaUEBOBiQBeXl7FXthWmOTk5FKvW80g8XASvL92P3bXy28IkbLmKgs3NzdiY2Nxd3cvtCtsdna2Sb2h8nOyc8M2JZ4U4abt/ZSz0uYyN5WrZArLJaUkISGBlJQUXX43yvt3cuP5TG6kZNC5RlKZ2jXXd4WeRScWaJjnsTeQ/0RGzjKxQgg7wB24Wcy6BT3fDmgORBu/8FyEENHGc0V3kVLOBeYChIaGyvDw8NK8t9zhN0rrH47n+M/Px3HzCSDUp1ap2ynvXKWVmZlJbGwsly5dKnSZtLQ0k65puUdWGiRfB5cMcCj/IdtLncvMVK6SKSqXk5MTgYGB2NvbV3Cq8v2dzMgy8H+7NhPauCYTB3Us0zhr5vqu0LPo7AVaCCGaAJfQOgaMzLfMWmAMsAsYAmySUkohxFrgeyHEJ0B9oAWwB20P6J42pZTHgNz+k0KI5IIKjiV5rH1DPvvzNHMizvDt2PIrOnqxt7cv8Kr+vCIiIkzqTnsPKWFOJ23Onae3aTONlqNS5zIzlatkLDVXeVpz8BKXE9KYPshf94E9C6PbOR3jOZpJwAbgBLBcSnlMCDFNCDHAuNi3gIcQIhp4EZhqXPcYsBw4DvwGPC+lzC6szYp8X+XFxcGOsZ2a8OfJ65y4kqh3HMsmBLQfr43ndnGP3mkURRfZBsmcLWdoXa864S1r6x2nULpeHCqlXCel9JVSNpNSTjc+96aUcq3xfpqUcqiUsrmUMkxKeTbPutON67WUUq4vqs0CtqvftHklMLaTD26OdnyxOVrvKJYvYJg2AvXer/VOoii6+P3YVc7GpfBceDOL3csBNSKBRXN3seeJjo1Zd+QK0deT9Y5j2RzdIGgkHFutnd9RlCpESsmsiGh8PFx40L+e3nGKpIqOhXuqSxOc7GyZrfZ2itd+PBgyYd/C4pdVlEpk6+l4jl5K5NnwZhYxfUFRVNGxcB5ujozq0Ig1hy5z/kbxA1BWaZ4toGkPiJwH2WrQVKXqmL05mrrVnRjUzjKmLyiKKjpWYGK3ptjaCOZEnNE7iuULmwhJl+HUr3onUZQKERlzk93nbjKhW1Mc7Cz/K93yEyrUqe7E8PYN+Wl/LJdu39E7jmXz7QPujWCP6lCgVA2f/XmaWq4OjGdK4T8AACAASURBVAhrWPzCFkAVHSvxdPdmAHy1Re3tFMnGFto/CTHb4FrxM3YqijXbf+EW207HM6FrU1wcrGNOTlV0rESDGs4MDvZm6d6LXE9MK36FqqzdE2DrCHu/0TuJopjVZxtPU9PYy9VaqKJjRZ4Nb0a2QTJ369niF67KXD2g7WA4tBTSEvROoyhmcfDibbZExTGhW1NcHa1jLwdU0bEqjT1cGRhYnyW7L3AjWQ3lX6SwCZCZohUeRamEPtsYRQ0Xe4uaitoUquhYmed6NCctK5tvt5/TO4plaxAMDUK0DgWVaNh6RQE4dPE2m0/FMaFrU9ysaC8HVNGxOs3ruNHfvx4Ld8ZwMyVD7ziWLWwi3DgNZyP0TqIo5Wrmn6dxd7auczk5VNGxQv/s2YLUzGx1bqc4fo+Ai4fqPq1UKkdiE/jz5HXGd2lCNaeKn4qhrFTRsUItvKoxILA+C3fGEK/O7RTO3gmCx0DUerh9Qe80ilIuPvvzNNWd7BjT2UfvKKWiio6VmtyzBelZ2eq6neKEPqn9GzlP3xyKUg6OXkpg44lrPNWlKdWtcC8HVNGxWs1qu/FIuwYs2nVeXbdTlBoNoeWD2iCgmepzUqzb55tOU83JjrFWupcDquhYtcn3tyDLOHGTUoSwCXDnJhxbpXcSRSm1o5cS2HDsGk92boK7s3Xu5YAqOlbNx9OVwcENWLL7AlcT1F/xhWrSHTx9Yc9cvZMoSql9/Psp3J3teapr0dO+WzpVdKzcP+5vgcEgmR2h5tsplBDQfgJc3g+x+/ROoygltu/8TTafiuOZ7s2s9lxODlV0rFzDWi481r4hS/dcVCNQFyVwODi4qemsFasjpeTDDafwdHNkTCfruy4nP1V0KoHnezQH4ItNam+nUE7VtcJzdCWkxOudRlFMtiP6Bn+dvcmkHs2sZiTpoqiiUwk0qOHM8LCG/Bh5kYs3U/WOY7naj4fsdNi/SO8kimISKSUf/n6K+u5OjOjQSO845UIVnUriufDm2NgIPt14Wu8olqtOa/Dpql2zY8jWO42iFOvPE9c5dPE2k3u2wNHOVu845UIVnUqirrsTYzv5sPJALKeuJukdx3KFTYSEixD1m95JFKVIBoPko99P4ePhwuAQb73jlBtVdCqRZ7s3w83Bjg83nNI7iuVq+SBUb6C6TysW79cjVzh5NYkXHvDF3rbyfFVXnneiUNPVgae7N2XjiWvsO39T7ziWydYOQsdpI0/HRemdRlEKlJVtYMYfUbT0qsbDAfX1jlOuVNGpZJ7s0gRPN0feX38KqeaRKVjwGLCxV9NZKxZr5YFLnI1P4YUHfLGxEXrHKVeq6FQyLg52/LNnc/bE3CQiKk7vOJbJrQ60GQSHfoB0df5LsSxpmdnM+COKQG93+rTx0jtOuVNFpxIa1r4RjWq58MFvpzAY1N5OgcImQHoiHF6mdxJFucuCnTFcSUjjtQdbI0Tl2ssBnYuOEKKvEOKUECJaCDG1gNcdhRDLjK/vFkL45HntNePzp4QQfYprUwjxrRDikBDisBBihRDCzdzvTy8Odja81NuXE1cS+fnwZb3jWCbv9lAvEPZ8o6azVizG7dQMZm+O5v5WdbivqYfeccxCt6IjhLAFZgH9AD9ghBDCL99iTwG3pJTNgRnA+8Z1/YDhQBugLzBbCGFbTJsvSCkDpZQBwAVgklnfoM4eDqhPq7rV+Pj3KDKyDHrHsTw547HFnYCY7XqnURQAZm2OJik9i1f7ttI7itnouacTBkRLKc9KKTOApcDAfMsMBBYa768Aegptf3MgsFRKmS6lPAdEG9srtE0pZSKAcX1noFL/eWtjI3i1bysu3Exl2V41a2aB/IeAc001HptiEWJvpbJw53kGB3vTsm41veOYjZ4D+TQALuZ5HAt0KGwZKWWWECIB8DA+/1e+dRsY7xfaphBiPvAgcBx4qaBQQoiJwEQALy8vIiIiSvKeciUnJ5d63XIjJb41bfhw/XE8U87hbCcsI1ch9MjW1DOchsfX8NdvK0h38rSYXKZQuUrG0nPNPZyOlAY6ut2wiJzm+rz0LDoFnSHLv/dR2DKFPV/Qnltum1LKccZDcJ8Dw4D59yws5VxgLkBoaKgMDw8vKHuxIiIiKO265alGs1sMmr2T44b6vBTe0mJyFUSXbIE+8NlqOjqchPDXC1zEUj8zlatkLDlXHd9gdm3YxsRuTRncr7XekQDzfV56Hl6LBRrmeewN5D/rnbuMEMIOcAduFrFusW1KKbOBZcDgMr8DK9CuUU0eDqzP19vOciVBTX1wj5o+4NsH9i2ArHS90yhV1Hu/naS6kz3PdW+udxSz07Po7AVaCCGaCCEc0DoGrM23zFpgjPH+EGCT1K54XAsMN/ZuawK0APYU1qbQNIfcczoPAyfN/P4sxit9WmIwwEcb1BX4BWo/AVLi4Hj+Hz9FMb/jN7LZGhXHpB7NcXex7gnaTKFb0ZFSZqH1INsAnACWSymPCSGmCSEGGBf7FvAQQkQDLwJTjeseA5ajnZv5DXheSpldWJtoh+MWCiGOAEeAesC0CnqrumtYy4VxnbXBQM8nqtGV79HsfqjVVHUoUCqcwSBZfiqDBjWcGd3R+idoM4WuMwJJKdcB6/I992ae+2nA0ELWnQ5MN7FNA9C5HCJbred6NGd55EWWnszgiYdlpbzorNRsbLS5djb8H1w5pF2/oygVYNWBS8QkGpgxzBcn+8oxdUFx1IgEVYS7sz3/6uXLiZsGNp28rnccyxM0EuxdYI/a21EqRmpGFh9sOElTdxsGBjYofoVKQhWdKmRkh0bUdRG8u+4EmdnqgtG7ONcE/6Fw5EdIVSN0K+b35ZazXEtMZ2Qrh0o3qGdRVNGpQuxtbXispQNn4lJYuvdi8StUNWETICsNDi7RO4lSyV26fYevtpzh4cD6NK9ZNQ6r5VBFp4ppV8eWDk1q8ekfUSSlZeodx7LU9YdGnbQpD9R01ooZffCb1nn21b4tdU5S8VTRqWKEELze348bKRl8sSla7ziWJ2w83IqB6I16J1Eqqf0XbrHm4GUmdG2Kd00XveNUOFV0qiB/b3ceC/Vm3o5znI1L1juOZWn1MLjVVR0KFLOQUjLt5+PUrubIs+HN9I6jC1V0qqgpfVrhZGfLO78c1zuKZbFzgJCxEP0H3Dijdxqlkll76DIHL97mlT4tcXXU9YoV3aiiU0XVrubIP3u1YPOpODadvKZ3HMsSMhZs7CBynt5JlErkTkY2760/SdsG1Rkc7K13HN2oolOFPdHRh2a1XXnnlxOkZ6kT57mq14PWD8OBxZCRqncapZKYs+UMVxLSeKO/X5XqIp2fKjpVmIOdDW8+3IZz8SnM3xGjdxzLEjYR0hK063YUpYzO30jhyy1nGBBYnw6VdEZQU6miU8V1961Nr9ZefP7naa4npukdx3I06gh12mgdCtR01koZTfv5OPY2gn/3t4xpC/Skio7CGw+1JjNb8t5vVWbg7eIJoV0seu0I1RPV56KU3p8nrvHnyetM7tkCr+pOesfRnSo6Co09XBnftQkr919i3/lbesexHAGPgaM7DS79qncSxUqlZWbz9s/HaVbblXGdm+gdxyKooqMA8HyP5nhVd+SttUfJNqjDSQA4uEK7UdSO2wlJV/VOo1ihuVvPcuFmKtMGtsXBTn3dgio6ipGrox1vPOTH0UuJLN4Vo3ccy9F+PDYyG/Yt1DuJYmUu3kxl1uZo+vvXo3NzT73jWAxVdJRc/f3r0bWFJx/9HsU11alA49GMmzXbadfsZKux6hTT/ffX49gI1XkgP1V0lFxCCN4Z2JaMbIMaqSCPSw36Q/JVOPmL3lEUKxFx6jobjl1j0v3NqV/DWe84FkUVHeUuPp6uPB/enF8OX2Hb6Ti941iEGx7BUKORGo9NMcmdjGzeWHOUpp5aBx3lbqroKPd4JrwpTTxdeWP1UdIy1UgFCFttOuvzO+DaMb3TKBZu5qbTXLx5h+mD/HG0q1pz5ZhCFR3lHo52trwzsC0xN1KZE6EGvQSg3Wiwc1J7O0qRTl5N5OutZxka4k3HZlV75IHCFFt0hBC2QogXKiKMYjm6tPBkQGB95kSc4Vx8it5x9OdSC9oOgcPL4M5tvdMoFshgkPzfyiNUd7bn/x5UnQcKU2zRkVJmAwMrIItiYV5/qDWOdja8ueYoUg0Fo41QkJkKh37QO4ligZbsucD+C7d5vX9raro66B3HYpl6eG2HEOILIURXIURwzs2syRTd1anmxJS+Ldl2Op5VBy7pHUd/9YPAu712iM1g0DuNYkGuJ6bxwfqTdG7uwaB2DfSOY9FMLTqdgDbANOBj4+0jc4VSLMfjHRoT2rgm0345TlxSut5x9Bc2EW6egbOb9U6iWJC3fz5OeraB/z7ijxBVd9oCU5hUdKSUPQq43W/ucIr+bGwE7w0OIDU9m//8rHpu4TcQXDxVhwIl16aT1/j1yBUm39+cJp6uesexeCYVHSGEuxDiEyFEpPH2sRDC3dzhFMvQvI4bk3s259fDV9hwrIqPQWbnqM0sGvUb3DqvdxpFZ0lpmfx71VFa1HFjYrdmesexCqYeXpsHJAGPGW+JwHxzhVIsz9Pdm9GqbjXeWH2UhDtVfDiY0HHa1AeR3+qdRNHZu+tOci0xjQ+GBKgBPU1k6qfUTEr5lpTyrPH2NtC0rBsXQvQVQpwSQkQLIaYW8LqjEGKZ8fXdQgifPK+9Znz+lBCiT3FtCiGWGJ8/KoSYJ4SwL2v+qsTe1oYPhgQQn5zOe+tP6B1HX+7e0Ko/7F8MmXf0TqPoZEd0PD/sucD4rk1p16im3nGshqlF544QokvOAyFEZ6BMv21CCFtgFtAP8ANGCCH88i32FHBLStkcmAG8b1zXDxiO1rmhLzDbeD1RUW0uAVoB/oAzML4s+auiAO8aTOjalB/2XGRndLzecfTVfgLcuQlHV+qdRNFBSnoWr/50mKaerrz4gK/ecayKqUXnGWCWECJGCBEDfAE8XcZthwHRxj2nDGAp914PNBDIGVN+BdBTaF1DBgJLpZTpUspzQLSxvULblFKuk0bAHsC7jPmrpH/18sXHw4WpK4+QmpGldxz9NOkGni1hz1w1nXUV9P5vJ7l0+w4fDAnAyV4NdVMSdsUtIISwAVpKKQOFENUBpJSJ5bDtBsDFPI9jgQ6FLSOlzBJCJAAexuf/yrduTuf4Its0HlYbDfyzoFBCiInARAAvLy8iIiJMfkN5JScnl3pdcyqPXMObGXhvTxqTv/mTx/0cyycY1veZ1a8Zju/pr9j381ySqre0mFx6q+y5Tt7MZtGeNB5obEdyzGEiYiwjV3kzV65ii46U0iCEmAQsL6dik6Ogzuz5/2QsbJnCni9ozy1/m7OBrVLKbQWFklLOBeYChIaGyvDw8IIWK1ZERASlXdecyiNXOHDV7hgLdsYwrndIuU1QZXWfWXoIfPw9IVn7ILysO/7lmEtnlTnXnYxs3vpsK41qufDZU11xcSj2K7RCcpmDuXKZenjtDyHEy0KIhkKIWjm3Mm47FmiY57E3cLmwZYQQdoA7cLOIdYtsUwjxFlAbeLGM2au8V/u2oqmnK1N+PERiWhXtzeZYDYJGwLFVkKymgagKPthwkvM3Unl/cEC5FJyqyNSi8yTwPLAV2Ge8RZZx23uBFkKIJkIIB7SOAWvzLbMWGGO8PwTYZDwnsxYYbuzd1gRogXaeptA2hRDjgT7ACCmlGsOkjJwdbPn4sUCuJqYx7ecqPOFb+/GQnQH71XTWld2O6Hjm74hhTMfGagTpMjBllGkb4HEpZZN8tzJ1mZZSZgGTgA3ACbTDd8eEENOEEAOMi30LeAghotH2TqYa1z0GLAeOA78Bz0spswtr09jWl4AXsEsIcVAI8WZZ8ivQrlFNng1vxop9sfxx/JrecfRRuyU06Q6R8yG7CnesqOQS7mTy8o+HaFrblan91AjSZWHqOZ2PgI7lvXEp5TpgXb7n3sxzPw0YWsi604HpprRpfF7tC5vBP3v6sulkHK+tPEJI45rUqoqj64ZNgGWPQ9R6aP2w3mkUM3hrzVHiktJZ+VwnnB1Ub7WyMPXw2u9CiMFCjWSn5ONgZ8MnjwWScCeD11cfqZpTIPj2g+reajy2SurnQ5dZffAyk3u2IMC7ht5xrJ6pRedFtMNZ6UKIRCFEkhCiPHuyKVasdb3qvPCAL+uOXGXl/io4BYKtnTY0zrktEHdK7zRKObqakMa/Vx0hqGENngtXY6uVB1OLjjswFvivlLI62kgAD5grlGJ9nu7WjDCfWry55igxVXGm0eAxYOsAe7/RO4lSTgwGyZQVh8jMlswYFoSdrRpbrTyY+inOAu4DRhgfJ6GNSqAoANjaCGYMD8LWRvDPpQfIyKpiHQTdakObR+Hg95CmDgJUBgt3xbDtdDxvPOSnpiwoR6YWnQ5SyueBNAAp5S2gCp4xVorSoIYz7w8O4FBsAp/8EaV3nIoXNgEykuHwMr2TKGV09FIC/1t3kl6t6zAirGHxKygmM7XoZBoH05QAQojaQBX7U1YxRT//eowIa8hXW8+wo6oNCtogBOq30zoUVMUOFZVEcnoW//jhALVcHfhgSKCaCbScmVp0ZgKrgDpCiOnAduBds6VSrNobD/nR1NOVF5Yd5GZKht5xKo4Q2ujT8afg3Fa90yil9Oaao5y/kcKnw4Oq5iUAZmbqdNVLgFeA/wFXgEeklD+aM5hivVwc7Jg5oh23UzN5ZcWhqtWNuu2j4FwL9qru09bop32xrNx/ick9W3BfUzXqgDmY3B1DSnlSSjlLSvmFlLKKz+KlFKdNfXde7deKjSeuM29HjN5xKo69MwSPhpO/QkKs3mmUEjgbl8wba47SoUkt/nF/C73jVFqqD6BiNk929qFXay/+t+4E+87f0jtOxQl9SjunE6lmdLcW6VnZTPr+AI52Nnxq7IWpmIcqOorZCCH4eGgg9Wo4Men7/VXn/E7NxuDbF/YtgKx0vdMoJnjnl+Mcv5LIR0MDqefurHecSk0VHcWs3F3smT0yhBvJGfxr2UEMhipyfidsAqTGw/E1eidRirFyfyzf/XWBp7s1pWdrL73jVHqq6Chm5+/tzlsD/NgaFccXm6P1jlMxmvYAj+badNaKxTpxJZH/W3WE+5rWYkqfip/9tSpSRUepECPDGvFIUH1mbIxi++kqcP2OjY02107sXrh8QO80SgES7mTyzHf7cHe25/MRwWqYmwqiPmWlQgghmD7In+a13fjn0gNcvn1H70jmFzgC7F1hjxqPzdIYDJKXlh/i0q07zB4VTO1qjnpHqjJU0VEqjKujHXMeDyE9y8DExZGkZWbrHcm8nGtAwGNwdAWk3tQ7jZLHnC1n2HjiGv/u35qQxrX0jlOlqKKjVKjmddz4dFgQxy4nMvWnw5X/wtGwCZCVBgcW651EMdoSFcfHv59iQGB9xnby0TtOlaOKjlLhevl58WIvX1YfvMw3287pHce8vNpA487alAeGSr5nZwXOxCUz6fv9tKxbnfcG+6tx1XSgio6ii0n3N+dB/7r8b/0JtkbF6R3HvMImwO0LcPoPvZNUaSmZkvELI3GwteHrJ0JwcVAz2OtBFR1FF0IIPhwSiK9XNSZ9v79yT/zW6iGoVk91n9ZRVraB2QfTiL2VylejQ/Cu6aJ3pCpLFR1FN66Odnz9RCg2NoLxiyJJyayk53ds7SFkHJz5E26c0TtNlfTfX09w7IaB6Y/4E+qjOg7oSRUdRVcNa7kwZ1QI52+k8MWBtMo742jIWLCxV9NZ62Dpngss2BlD78Z2PNZeTcimN1V0FN11bObBe48GcOKmgX+vOlI5e7RV8wK/AXBgCWRU4kOJFmZrVByvrz5K1xaeDGup5saxBKroKBZhcIg3A5vZ8+O+WGZV1qFywiZCegIcXq53kirh+OVEnluyn+Z13Jg1KliNHG0hVNFRLMYjze0Z1K4BH/0exZqDl/SOU/4adgAvfzWddQW4fPsO4xbswc3Rjvnj2lPdyV7vSIqRKjqKxRBC8N5gf8Ka1GLKj4fZc66SXcUvhNZ9+voxuLBL7zSVVmJaJuPm7yU1PZsFT7ZXUxVYGFV0FIviaGfL3NEheNdy5qmFezlxJVHvSOXLfyg4uavu02aSkWXg2e/2cSYumS9Hh9CqbnW9Iyn56Fp0hBB9hRCnhBDRQoipBbzuKIRYZnx9txDCJ89rrxmfPyWE6FNcm0KIScbnpBDC09zvTSm9Gi4OLHoyDFcHO56Yt4cLN1L1jlR+HFyg3Wg48TMkXtE7TaWSbZC89OMhdkTf4P3BAXRurn7NLZFuRUcIYQvMAvoBfsAIIYRfvsWeAm5JKZsDM4D3jev6AcOBNkBfYLYQwraYNncAvYDzZn1jSrnwrunC4qfCyMw2MHrebq4npekdqfyEPgmGLG1mUaVcSCl5ffVRfj50mdf6tWJwiLfekZRC6LmnEwZESynPSikzgKXAwHzLDAQWGu+vAHoKbbCkgcBSKWW6lPIcEG1sr9A2pZQHpJQx5n5TSvlp4VWN+WPbE5eUzph5e0m4k6l3pPLh0QyaPwD75kNWFZnC28ze/+0UP+y5wHPhzXi6ezO94yhFEHpdEyGEGAL0lVKONz4eDXSQUk7Ks8xR4zKxxsdngA7Af4C/pJTfGZ//FlhvXK24NmOAUCllgTOJCSEmAhMBvLy8QpYuXVqq95ecnIybm1up1jUnS80FhWc7Gp/FjH3pNKthw0uhTjjaVmzXV3N8ZrVuRBJw5B2O+b1MXJ2uFpOrPFR0rl/OZrAiKpP7G9ox2s+h0EE81edVMmXJ1aNHj31SytCCXtNzxLuCfjLyV8DClins+YL23EpUVaWUc4G5AKGhoTI8PLwkq+eKiIigtOuak6XmgsKzhQM+vpeZ/MMBFp9z4ZsxoTjZ2+qeq0wM3SB2MW2Sd8Bjb1hOrnJQkbm+++s8K6KOMiCwPp8OC8KmiGtx1OdVMubKpefhtVgg75gU3sDlwpYRQtgB7sDNItY1pU3FCj0UUJ8PhwSy40w8Exfvs/4J4HKms76wC64e0TuNVVq29wKvrz7K/a3q8PFjgUUWHMVy6Fl09gIthBBNhBAOaB0D1uZbZi0wxnh/CLBJascD1wLDjb3bmgAtgD0mtqlYqcEh3rw/OICtUXE8+90+0rOsvPAEjQI7J+1iUaVElu29wKs/HaGbb21mjwrG3lZd/WEtdPufklJmAZOADcAJYLmU8pgQYpoQYoBxsW8BDyFENPAiMNW47jFgOXAc+A14XkqZXVibAEKIyUKIWLS9n8NCCDXyohV6LLQh/3vUn82n4nh+yX7rHiDUpZZ23c6RH+HOLb3TWI2le7SC0923NnNHh1TooVal7HSdxUhKuQ5Yl++5N/PcTwOGFrLudGC6KW0an58JzCxjZMUCjAhrRJZB8sbqozy3ZB9fjAy23i+esAnaVNYHv4eOz+udxuIt3XOBqSuPEN6yNl8+rgqONVL7pIpVGn1fY94Z2IaNJ67z1MK9pKRn6R2pdOoFamOy7f0GDFa811YBFv91XhWcSkAVHcVqje7ow0dDA9l15gajv91tvdfxtJ8AN8/CmU16J7FIUkq+2HSaN1YfpVfrOqrgWDlVdBSrNiTEm1kjgzlyKYERc//iRnK63pFKzm8guNaBvapDQX5SSqb/eoKPfo9iULsGzFEFx+qpoqNYvX7+9fj6iVDOxifz2Fe7iL1lZWO12TloM4tGbYCb5/ROYzGysg28suIw32w/x9hOPnw8NFD1UqsE1P+gUimEt6zDoic7cD0pnUGzd3L0UoLekUomdBwIG4j8Vu8kFuFORjbPLdnPj/ti+WfPFrz1sJ+6DqeSUEVHqTTCmtTip2c7YW8jeOyrXWw+dV3vSKarXh9aPwT7F0OGle2plbO4pHSGf/0Xf5y4xn8e9uOFB3wLHdpGsT6q6CiViq9XNVY93xkfD1fGL4xk6Z4LekcyXfsJkHYbjv6kdxLdnL6WxCOzdhB1NYmvHg9hbOcmekdSypkqOkql41XdieXPdKRzc0+mrjzC/9afINtgBdND+3SB2q21Cd6q4HTWO6LjeXTOTjKyDSx7+j56t6mrdyTFDFTRUSolN0c7vh0TysgOjfhqy1meWmgFUyMIAWHj4ephiN2rd5oKI6Vk4c4YxszbQz13J1Y914kA7xp6x1LMRBUdpdKyt7Xh3UH+TB/Ulu2n43lk1g6iryfpHatoAcPBsXqVGY8tLTObl348xFtrj9HdtzYrnu2Ed00XvWMpZqSKjlLpjerQmB8m3kdSWiaPzNrJH8ev6R2pcI5uEDgCjq2CZCvqCFEKl27fYciXO1m5/xL/6tWCr58IpbqTvd6xFDNTRUepEtr71GLtpC408XRlwqJIpv963HIHC20/HgyZsH9h8ctaqa1RcTz8+XbOx6fy7ZhQ/tXLV3WJriJU0VGqjPo1nPnxmY480bExX287x9CvdnHxpgV2T67tC017wN55kG2lY8oVIiPLwP/WneCJeXuo7ebImkmd6dnaS+9YSgVSRUepUpzsbZk2sC1zRgVzNi6ZB2duY/2RK3rHulfYBEi6DKd+1TtJuTl/I4WhX+7kq61nefy+RqyZ1JmmtS1vmmbFvFTRUaqkfv71WDe5K009XXl2yX5eXH7Qsnq3+fYF94aVokOBlJIfIy/Sf+Z2zsWn8OXjwfz3EX81hloVpYqOUmU1rOXCj890YvL9zVlz8DJ9ZmxlS1Sc3rE0NrYQ+iTEbIPrJ/ROU2pXE9J4csFepqw4jF/96qz/Vzf6tq2ndyxFR6roKFWag50NL/ZuyarnOuHmZMeYeXt4beVhy9jrCX4CbB21uXasjJSS5ZEXeWDGFv46e5P/POzH0gn30aCGs97RFJ2poqMoQIB3DX75Rxee7taUZXsv0vPjLaw5eAmp58gArp7Q9lE4eAAZJwAAFLhJREFUtBTSEvXLUUKXkw2M/nYPr6w4jF+96vz2r66M7dxE9U5TAFV0FCWXk70trz3YmjXPd6F+DSf+ufQgj3+7myvJOnatDpsAGcla4bFwKelZvLf+JG/suMPh2Nu8M7ANP0y4j8YernpHUyyInd4BFMXS+Hu7s+q5zny/+zwfbDjF7jNZnOE4k+5vTg0Xh4oN0yAE6gdrE7yFTdCGyrEwBoPklyNX+N+6E1xJSKNLAzs+HReOp5uj3tEUC6T2dBSlALY2gtEdfdj0Ujgd69vx7Y5zdPtgM3O3niEtM7tiw4RNhPgoOLelYrdrgu2n4xkwazuTfzhADRcHVjzTkfH+jqrgKIVSRUdRilC7miNP+Tuy/p9dCW5ck3fXnaTnx1tYuudCxY1o0GYQuHhYVPfpQxdvM/rb3Tz+7W5upWTyyWOB/PKPLoT61NI7mmLh1OE1RTFBq7rVWTAujB3R8bz/20mmrjzCzD9P80x4Mx4LbWjea07snbSebDs+g9sXoUZD822rCFJKdp29wezNZ9geHU9NF3te79+ax+9rrK65UUym9nQUpQQ6N/dkzfOdWTCuPfVqOPPmmmN0/WAzn/95mrikdPNtOPRJ7d/IeebbRiGysg2sP3KFR+fsZOTXuzl1LYnX+rVi26v3M75rU1VwlBJRezqKUkJCCMJb1qG7b23+OnuT2RHRfPxHFJ9viqZ/QD3GdPIh0Nu9fKdYrtEIfPtpg4B2f1Xb+zGz64lp/LDnIj/sucDVxDS8azrzziNtGRrirQqNUmqq6ChKKQkh6NjMg47NPDgTl8ziXedZsS+WVQcu4evlxiPtGvBIUAPql9cFkWETtLHYjq+GwOHl02Y+dzKy+fPkNVYfuEzEqetkGSTdfWvz/+3de7xVZZ3H8c8XDhwgbgeQqwIHOICaBnpAiy6ohZcp0FKhLC+Bjk6NM9M0ZS9nSi0nbXpNU9krsyytphSZV3ksk0ShNBVBxBtIHMELAhI35YAcbr/543kOLjZ7n7MP7L3XYZ/f+/XaL9Z+1rOe9dvP3pxnr7XX+j3fOPfdnDa2Px39Xht3mHzQca4ARh7VneumHs8XzxzDvUtf5zdLXudbD6zgv+au4JTqPpx5/EA+fOwAjulzGBOUjZgMfWvCdNYFHHQaGvfw6MqN/HHZeuY+v57tu/YyoGclM99fzScnDmV4P7/PxhVOqoOOpLOA7wIdgZ+Y2U0Z6yuBnwMnA5uA6Wb2clz3FWAmsBe42szmNtempGrgLqAPsAT4jJntKvZrdO1L98oKLjplGBedMoxXN+3gt0tfp+6ZtVx/3zKuv28Zowd057Sx/Tl1RF9qh1XRozWTlknhaOcPX4LXnzrkGPfs3ceL67excPVm5r+4gYWrN7F7r9GzSwUfe89gpo4bzCnVff2oxhVFaoOOpI7AD4CPAGuARZLqzGxZotpMYIuZjZI0A7gZmC7pOGAGcDwwGJgnaXTcJlebNwPfMbO7JN0a2/5h8V+pa6+G9u3G1WfUcPUZNby8cTvzlr/BQ8s3cPsjq/nRn1bRQXDc4J6cPLSKYwf15NhBPRk9oAddOzfze8l7ZsC86+HJn0DV9BZj2LvPeGXTdlas38aL67ex5NUtPP3qVhoawzw9I496F5dNqua0Mf2pHV5Fp45+bZErrjSPdCYC9Wa2CkDSXcA0IDnoTAOui8tzgFsUfp2dBtxlZo3Aakn1sT2ytSlpOXA68KlY587Yrg86riSG93sXsz4wglkfGMGOXXt4+tWtLFy9mSdXb+Kep9awY1e44bSDwmRzQ3p35eiqbgyp6kq/7p3p0aWCnl060aNLJ4aPPI9+z8/mtWOn8NQrm2lo3Mu2nbtp2LmHTdt3se7Nt1m7dSdrt77Ny5u2s3N3uJ9IgjEDenDe+CHUDq+idngfT8DpSi7NQWcI8Fri+RrglFx1zGyPpDeBvrH8iYxth8TlbG32Bbaa2Z4s9Z0rqW6dK5g0qh+TRvUDQhqZ17bsYPm6bSxf9xavbNrOmi1v89hLG1n/1k4yc47W6EQerPwlrz/9AP+x+OC0PL27dWJwr64cXdWVSaP6MWZgD8YO7EFN/xaOopwrgTQHnWwnjDNT+uaqk6s827mB5uofHJR0BXAFwIABA1iwYEG2ai1qaGg45G2Lqa3GBW03tlLF1QUY3wnGDwQGAnRkz75u7NgDO3YbO/YYb++GfTaSNauP56pd8+g++uNUdqqgW4XoUgHdO4nKChF+6tweHg0b2FwPC+uL/hIAfx9bq73FleagswZI3lp9NLA2R501kiqAXsDmFrbNVr4R6C2pIh7tZNsXAGZ2G3AbQG1trU2ePLnVLwxgwYIFHOq2xdRW44K2G1ubjGvZdph9MZ8/cS+MPTPtaA7QJvsLj6u1ihVXmr8aLgJqJFVL6ky4MKAuo04dcElcPh942MIEJ3XADEmV8aq0GuDJXG3GbebHNoht3lvE1+ZccY35Oxo79w2XTzt3BElt0IlHHJ8H5gLLgdlm9oKkGyRNjdVuB/rGCwW+AFwTt30BmE246OAB4HNmtjdXm7GtLwNfiG31jW07d2TqWMHawWfBqvmwcWXa0TiXt1Tv0zGz+4H7M8q+mljeCVyQY9sbgRvzaTOWr+KdK9ycO+KtHTyF6ldnh+msz7457XCcy4tflO/cEWp3595w/Lmw9FfQ2JB2OM7lxQcd545kEy6Hxrfg2bvTjsS5vPig49yR7JiJMPDEcIot84Ye59ogH3ScO5JJYTrrDcvglb+kHY1zLfJBx7kj3bs/AV16++XT7ojgg45zR7rO3eCkz8Dy38FbWe95dq7N8EHHuXJQOxNsHyz+WdqRONcsH3ScKwd9qqFmCjx1B+zxaaJc2+WDjnPlYuLlsH0DLM/MJuVc2+GDjnPlYuQZUFUNT/447Uicy8kHHefKRYcOMGEWvPYErHs27Wicy8oHHefKyfiLoKIrLPKjHdc2+aDjXDnpWgUnXgjP3gM7NqcdjXMH8UHHuXIz8XLY8zYs/d+0I3HuID7oOFduBp4AQ98b8rHt25d2NM4dwAcd58rRhFmw5WWon5d2JM4dwAcd58rRsVOh+wC/oMC1OT7oOFeOKjrDyZfCygdh86q0o3FuPx90nCtXJ18GHTrCotvTjsS5/XzQca5c9RwEYz8KT/8Cdu1IOxrnAB90nCtvE6+AnW/C83PSjsQ5wAcd58rbsPdB/+PDBG8+nbVrA3zQca6cSTBxFqx/Dl5bmHY0zvmg41zZO+FCqOzl2addm+CDjnPlrrI7jPsULLsXtr2RdjSunfNBx7n2YMIs2LcbltyZdiSunfNBx7n2oN8oGHk6LP4p7N2ddjSuHfNBx7n2YuIVsG0dvPj7tCNx7Vgqg46kPpIelLQy/luVo94lsc5KSZckyk+W9Jykeknfk6Tm2pU0VtLjkholfbE0r9K5NqZmCvQa6hcUuFSldaRzDfCQmdUAD8XnB5DUB/gacAowEfhaYnD6IXAFUBMfZ7XQ7mbgauDbRXk1zh0JOnSECTPhlUfhjWVpR+PaqbQGnWlA0y+adwLnZqlzJvCgmW02sy3Ag8BZkgYBPc3scTMz4OeJ7bO2a2YbzGwR4CezXft20sVQ0cWzT7vUVKS03wFmtg7AzNZJ6p+lzhDgtcTzNbFsSFzOLM+33WZJuoJwFAXQIGlFa9uI+gEbD3HbYmqrcUHbja0M4/qf+CiKMuyvoirHuIblWlG0QUfSPGBgllXX5ttEljJrprwgzOw24LbDbUfSYjOrLUBIBdVW44K2G5vH1ToeV+u0t7iKNuiY2YdzrZP0hqRB8WhkELAhS7U1wOTE86OBBbH86IzytXE5n3adc86lJK3fdOqApqvRLgHuzVJnLjBFUlW8gGAKMDeePtsm6dR41drFie3zadc551xK0vpN5yZgtqSZwKvABQCSaoErzWyWmW2W9HVgUdzmBjPbHJevAu4AugJ/iI/m2h0ILAZ6Avsk/TNwnJm9VcTXeNin6IqkrcYFbTc2j6t1PK7WaVdxyTzduXPOuRLxjATOOedKxgcd55xzJeODzmGQdIGkFyTti79H5ap3lqQVMW3PNYnyakkLY9qeuyV1LlBcLaYZknSapKWJx05J58Z1d0hanVg3rlRxxXp7E/uuS5Sn2V/jYiqlFyQ9K2l6Yl1B+yvX5yWxvjK+/vrYH8MT674Sy1dIOvNw4jiEuL4gaVnsn4ckDUusy/qeliiuSyX9LbH/WYl1WVNtlSiu7yRi+qukrYl1xeyvn0raIOn5HOulkF6sPr6XJyXWHX5/mZk/DvEBHAuMIVzKXZujTkfgJWAE0Bl4hnARA8BsYEZcvhW4qkBxfQu4Ji5fA9zcQv0+hFRB3eLzO4Dzi9BfecUFNOQoT62/gNFATVweDKwDehe6v5r7vCTq/ANwa1yeAdwdl4+L9SuB6thOxxLGdVriM3RVU1zNvacliutS4JYs2/YBVsV/q+JyVaniyqj/j8BPi91fse0PAicBz+dYfw7h4iwBpwILC9lffqRzGMxsuZm1lLFgIlBvZqvMbBdwFzBNkoDTgTmxXq50QIcinzRDSecDfzCzHQXafy6tjWu/tPvLzP5qZivj8lrCPWBHFWj/SVk/L83EOwc4I/bPNOAuM2s0s9VAfWyvJHGZ2fzEZ+gJDryfrljy6a9csqbaSimuTwK/LtC+m2VmfyZ8ycxlGvBzC54Aeivc91iQ/vJBp/hypfPpC2w1sz0Z5YVwQDogoKV0QDM4+AN/Yzy0/o6kyhLH1UXSYklPNJ3yow31l6SJhG+vLyWKC9VfuT4vWevE/niT0D/5bFvMuJJm8s6tDJD9PS1lXJ+I788cSce0cttixkU8DVkNPJwoLlZ/5aO5FGSH3V9p3adzxFAz6XzMLJ+bT4uSzqe5uPJtI7YzCDiBcDNuk68A6wl/WG8DvgzcUMK4hprZWkkjgIclPQdku6cqrf76BXCJme2LxYfcX9l2kaUs83WmkSIq77YlfRqoBT6UKD7oPTWzl7JtX4S47gN+bWaNkq4kHCWenue2xYyryQxgjpntTZQVq7/yUdTPlw86LbBm0vnkaQ1wTOJ5U9qejYTD1or4bTWZzuew4lJ+aYaaXAj8xsz2Z+Bu+tYPNEr6GZD3HESFiCuevsLMVklaAIwH/o+U+0tST+D3wL/H0w5NbR9yf2WR6/OSrc4aSRVAL8Lpkny2LWZcSPowYSD/kJk1NpXneE8L8Ue0xbjMbFPi6Y+BmxPbTs7YdkEBYsorroQZwOeSBUXsr3zkir0g/eWn14pvEVCjcOVVZ8IHrM7CL3PzCb+nQGHT9rQmHdBB55LjH96m31HOBbJe5VKMuBTSHlXG5X7AJGBZ2v0V37vfEM5135OxrpD9lfXz0ky85wMPx/6pA2YoXN1WTZhr6snDiKVVcUkaD/wImGpmGxLlWd/TEsY1KPF0KrA8LmdNtVWquGJsYwg/yj+eKCtmf+WjDrg4XsV2KvBm/GJVmP4q1hUS7eEBnEcY/RuBNwi54SBc3XR/ot45wF8J31SuTZSPIPxRqAfuASoLFFdfwiR2K+O/fWJ5LfCTRL3hwOtAh4ztHwaeI/zx/CXQvVRxAe+L+34m/juzLfQX8GnCfExLE49xxeivbJ8Xwum6qXG5S3z99bE/RiS2vTZutwI4u8Cf95bimhf/HzT1T11L72mJ4vom8ELc/3xgbGLbz8Z+rAcuK2Vc8fl1wE0Z2xW7v35NuPpyN+Hv10zgSkIKMgin0X4Q436OxJW5hegvT4PjnHOuZPz0mnPOuZLxQcc551zJ+KDjnHOuZHzQcc45VzI+6DjnnCsZH3Sci+J9CY9KOjtRdqGkBzLqNbSy3cmS3tfM+nMlfbX1Eee17+skfTEu3xBv3sxVd5ykcxLPpypLduQ893tUZr85B56RwLn9zMximpR7JM0nZAq+kcNPAjkZaAAey7H+S4SbFvOSyMrQKmbW0sA2jnBv0v2xfh1ZbmjMc19/k7RO0iQz+8uhtOHKkx/pOJdgZs8TcnV9GfgaIQPBQelHJN0o6ZmYkHFALPuYwvw2T0uaJ2mAwlw3VwL/ojA3ygcy2hkNNJrZxvj8Dkm3SnpEYY6Vj8bySyXdI+k+4I+x7N8kLVJIZHl9os1rFeZxmUeYeoNE2+fH5QmSHouv4UlJvQg3Lk6PcU6P+7wl1h+mMEdO01w5QxNtfi+2taqp/ei3wEWH/Ga4suRHOs4d7HpgCbCL8M0/07uAJ8zsWknfAi4HvgE8Cpwaj5hmAV8ys3+VdCthfpRvZ2lrUtxX0nBCssyRwHxJo2L5e4ETzWyzpCmENDcTCXeQ10n6ILCdkHJlPOH/9xLgqWTjMS3L3cB0M1ukkFNuB/BVwt3nn4/1Lk1sdgthAL5T0meB7/HOFBCDgPcDYwlHRk3TTyyO/eLcfj7oOJfBzLZLupswUDRmqbIL+F1cfgr4SFw+Grg75vrqDKzOY3eDgL9llM22kMF6paRVhD/mEOcyictT4uPp+Lw7YRDqQUjgugNA2WedHAOsM7NF8fW+Fes2F+d7gY/H5V8QJr5r8tsY77Kmo75oAyEllHP7+ek157LbFx/Z7LZ38kft5Z0vb98nzFB5AvD3hBxpLXk7S73M3FRNz7cnygR808zGxccoM7s9x/aZlEedliS3Tw7MyZGrC+H1ObefDzrOFU4vQgJVeCcLNMA2whFINsuBURllF0jqIGkkIclpttlp5wKfldQdQNIQSf2BPwPnSeoqqQfwsSzbvggMljQhbttDYYqE5uJ8jHDaDsLvNI/mqJc0msJlKHdlwgcd5wrnOsKVb48Q5ktqch9hIDjoQgLCIDFeB57bWgH8iTDz5pVmtjNzR2b2R+BXwOMKk9zNAXqY2RLC7zVLCXMQPZJl213AdOD7kp4hTDvchZCB+bimCwkyNrsauEzSs8BngH9qsTfgNML8Q87t51mmnUuZpO8C95nZPEl3AL8zszktbNbmSfozMM3MtqQdi2s7/EjHufT9J9At7SAKSdJRwH/7gOMy+ZGOc865kvEjHeeccyXjg45zzrmS8UHHOedcyfig45xzrmR80HHOOVcy/w/qz3CkD1lhMAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def cost(output, target, derivative=False):\n",
    "    output = np.array(output,dtype=float)\n",
    "    target = np.array(target, dtype=float)\n",
    "\n",
    "    if derivative:\n",
    "        return 2 * (target-output) / len(target)\n",
    "    return ((target - output) ** 2) / len(target)\n",
    "    \n",
    "\n",
    "j = np.arange(-1,1,0.001)\n",
    "#print(j)\n",
    "testO, testT = [-10,-7,-5,-2.5,-0.5,0.5, 2.5,5,7,10],[0,0,0,0,0,0,0,0,0,0]\n",
    "plt.plot(j, cost(j, np.zeros(len(j))))\n",
    "plt.grid()\n",
    "\n",
    "\n",
    "plt.plot(j,cost(j, np.zeros(len(j)), derivative=True))\n",
    "plt.legend([\"cost funciton\", \"Derivative of cost function\"])\n",
    "\n",
    "plt.title(\"Cost function with target output 0\")\n",
    "plt.xlabel(\"Y hat (prediction)\")\n",
    "plt.ylabel(\"error\")\n",
    "plt.ylim(-0.0001,0.0005)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Implementing the back propogation\n",
    "\n",
    "For backpropogation we need to find the relative increase in the cost function with respect to an increase of the weights. Therefore we need to find the derivative of the cost function w.r.t. the weights. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Chain rule\n",
    "As seen before the Cost function is the outer function which have several nested inner functions. In order to find: \n",
    "\n",
    "$$\\frac{\\partial C}{ \\partial W}$$\n",
    "\n",
    "\n",
    "We can apply the chain rule which says that the rate of change of a function of a function is the multiple of the derivatives of those functions:\n",
    "\n",
    "$$\\frac{\\partial}{ \\partial x}f \\big( g(x) \\big) = g'(x) * f'(x)$$\n",
    "\n",
    "\n",
    "And as the cost function, w.r.t. the weights, is the composition of the functions of the layers. Therefore the chain rule can be applied to find the derivative of the Cost function w.r.t. the weights.\n",
    "\n",
    "\n",
    "\n",
    "$$\\frac{\\partial}{ \\partial x}f \\big( g \\big( h \\big(i(j(x))\\big)\\big) \\big) = \\frac{\\partial j}{ \\partial x}\\frac{\\partial i}{ \\partial j}\\frac{\\partial h}{ \\partial i}\\frac{\\partial g}{ \\partial f}\\frac{\\partial f}{ \\partial g}$$\n",
    "\n",
    "***\n",
    "##  We use the chain rule to derive the change for the W2 (weight tensor between hidden layer and output)\n",
    "\n",
    "***The cost function (mean squared error) is a function of y hat (output of the network)***\n",
    "\n",
    "$$C(\\hat y)=\\big(\\hat y-y \\big) ^2 $$\n",
    "\n",
    "\n",
    "***y hat is a function of the z2 layer (fed into sigmoid in our case)***\n",
    "\n",
    "$$ \\hat y(z2)=\\frac {1}{1+e^-z2} $$\n",
    "\n",
    "\n",
    "\n",
    "***z2 is a function of w (it is the weighted sum with the activation of the hidden layer a2)***\n",
    "\n",
    "$$z2(W2)=\\big(a2 * W2 \\big) $$\n",
    "\n",
    "\n",
    "#### When applying the chain rule we get ####\n",
    "$$\\frac{\\partial C}{ \\partial W2} = \\frac{\\partial z2}{ \\partial W2}\\frac{\\partial \\hat y}{ \\partial z2} \\frac{\\partial C}{ \\partial \\hat y}$$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "### Note! this is only for the last weight matrix and bias and regularization is not in the derivation\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "### Sigmoid activation function and Squared Error used for backpropogation for W1\n",
    "\n",
    "To get the $\\frac{\\partial C}{ \\partial W1} $ we can reuse the beginning of the function defined above. The $\\frac{\\partial \\hat y}{ \\partial z2} *\\frac{\\partial C}{ \\partial \\hat y}$ usualy is denoted as $\\delta 2$. To derive $\\frac{\\partial C}{ \\partial W1}$ we get the following defintion: \n",
    "\n",
    "$$\\delta 2 * \\frac{\\partial z_{2}}{ \\partial a_{2}} \\frac{\\partial a_{2}}{ \\partial z_{1}}\\frac{\\partial z_{1}}{ \\partial W_{1}} $$\n",
    "\n",
    "\n",
    "where: $ \\frac{\\partial a_{2}}{ \\partial z_{1}} $ is the partial derivative of the activation of neurons in the hidden layer to the weighted sum feed into the activation function. i.e. the derivative of the activation function of the hidden layer w.r.t. the input. First we implement the sigmoid as the hidden layer activation function but then ReLU. Therefore we implemented the derivative of the ReLU above also."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4, 5. Set learning rate and update weight matrices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we get partial derivative of the cost function to the different weight matrices we know in what direction every specific weight needs to go in order to increase the cost. As we want to decrease the cost we update the weights by subtracting the $\\frac{\\partial C}{\\partial W} * scalar$. The scalar is called the learning rate as it determines how big steps we are taking towards the minimum of the function. If the steps are to big we will always overshoot the minimum and if the steps are too small we will never reach the minimum in a reasonable amount of computation time. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "****\n",
    "\n",
    "### 6. Evaluation metrics for out multiclass problem\n",
    "\n",
    "When picking performance metrics it is important to contemplate over the exact problem we are aiming to solve. Different preformance metrics could be relativley important.\n",
    "\n",
    "##### We will use accuracy, precision, recall as performance metrics. We will also use a confusion matrix to visualize the relative predictions/actual distrubtion. #####\n",
    "\n",
    "### Accuracy\n",
    "\n",
    "The accuracy is the total correct predictions / all predicitons made. It will tell us the overall performance of the model. However by adding precision and recall we can get more information on how the model is peforming\n",
    "\n",
    "****\n",
    "\n",
    "In multiclass problems the precision can be derived for each label. The precision is calculated where\n",
    "**i=column and j=row:**\n",
    "\n",
    "### Precision\n",
    "\n",
    "$$ precision_{i}  = \\frac {M_{ii}}{\\sum_{j} M_{ji}} $$\n",
    "\n",
    "**As the predictions of the confusion matrix is the columns the precision telling us: out of all predictions made of one class, how many was correct**\n",
    "\n",
    "****\n",
    "\n",
    "### Recall\n",
    "\n",
    "The recall on the other hand is dividing a correct predictions with the corresponding row for the label. i.e. the sum of all actual labels. The recall will then tell us out of all the outstanding instances of one label, how many of those could the model identify.\n",
    "\n",
    "$$ recall_{i}  = \\frac {M_{ii}}{\\sum_{j} M_{ij}} $$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "## Backpropogate\n",
    "Let us implement all the above in order to train our Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork(object):\n",
    "    def __init__(self):\n",
    "        self.inputLayerSize = 1024\n",
    "        self.hiddenLayerSize = 16\n",
    "        self.outputLayerSize = 10\n",
    "        self.learningRate = 0.01\n",
    "        self.bias = True\n",
    "        self.initilize_weights()\n",
    "        \n",
    "    \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "    \n",
    "           \n",
    "    def initilize_weights(self):\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0 # default self.bias is true\n",
    "       \n",
    "        rangeW1 = 1 / np.sqrt(self.inputLayerSize+bias_node) #Get the range to be as defined above \n",
    "        distrubutionW1 = truncated_normal(mean=0,sd=1, low=-rangeW1, upp=rangeW1) # Create a normal distrubtion trunctaed within the range\n",
    "        self.W1 = distrubutionW1.rvs((self.inputLayerSize+bias_node,self.hiddenLayerSize,)) #Randomly distribute the normal distrubtion with correct dimensions \n",
    "        \n",
    "        rangeW2 = 1 / np.sqrt(self.hiddenLayerSize)\n",
    "        distrubutionW2 = truncated_normal(mean=0, sd=1, low=-rangeW2, upp=rangeW2)\n",
    "        self.W2 = distrubutionW2.rvs(( self.hiddenLayerSize+bias_node,self.outputLayerSize))\n",
    "    \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "   \n",
    "            x = np.array(x, ndmin=2) # every row is an input\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(x))\n",
    "                x = np.c_[x, biases]  ##adding bias to the input layer # bias is an extra one\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            self.z1 = np.dot(x, self.W1)\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(self.z1))\n",
    "                self.z1 = np.c_[self.z1, biases]  ##Adding the bias to the hidden layer\n",
    "\n",
    "            self.a1 = sigmoid(self.z1) #sigmoid activation function\n",
    "\n",
    "\n",
    "            self.z2 = np.dot(self.a1, self.W2)\n",
    "            self.a2 = sigmoid(self.z2)\n",
    "\n",
    "            return self.a2\n",
    "        \n",
    "     \n",
    "    ##This is the implementatiion of the back-propogation\n",
    "    def backward(self, iput, output, target):\n",
    "        \n",
    "        #Calculate dcdw2 - how much the an arbritary change for each weiight in the W1 matrix affect the cost\n",
    "        dcdy = self.MSE_prime(output, target) #partial derivative of error w.r.t. y hat (prediction)\n",
    "        #print(\"shape pof dcdy\", dcdy.shape)\n",
    "        dyDz2 = sigmoid_derivative(self.z2) #Patial derivative of yhat with respect to z2,\n",
    "        #print(\"shape of dydz2\", dyDz2.shape)\n",
    "        delta2 = dcdy * dyDz2\n",
    "        \n",
    "       # print(\"shape of delta 2\", delta2.shape)\n",
    "        \n",
    "        \n",
    "        dz2dw2 = self.a1.T # partial derivative of z2 with respect to weights\n",
    "        \n",
    "        dcdw2 = np.dot( dz2dw2, delta2) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "       # print(dcdw2.shape)\n",
    "      \n",
    "        ##Calculate dcdw1 - how much the an arbritary change for each weiight in the W2 matrix affect the cost\n",
    "        \n",
    "        dz2da1 =  self.W2.T  # Equals to the weight # Hidden errors\n",
    "       \n",
    "        dcda1 = np.dot(delta2, dz2da1 )\n",
    "        #print(\"shape\",dcda1.shape)\n",
    "        da1dz1 = sigmoid_derivative(self.z1) #the derivative of the activation function for a1 - hidden layer\n",
    "      \n",
    "        \n",
    "        \n",
    "        delta1 = dcda1 * da1dz1\n",
    "        \n",
    "        iput = np.array(iput, ndmin=2) # every row is an input\n",
    "\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(iput))\n",
    "            iput = np.c_[iput, biases]  ##adding bias to the input layer\n",
    "            \n",
    "            \n",
    "        dz1dw1 = iput.T # The matrix product for input and weights - partial derivative of the product mutliplication w.r.t. the weights is simply the input then.\n",
    "       \n",
    "        dcdw1 = np.dot(dz1dw1, delta1)\n",
    "     \n",
    "        #print(dcdw1.shape)\n",
    "     \n",
    "        \n",
    "        return dcdw1, dcdw2\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    def train(self, training, target):\n",
    "        \n",
    "        network_output= self.feedForward(training)\n",
    "    \n",
    "        dcdw1, dcdw2 = self.backward(training, network_output,  target)\n",
    "    \n",
    "        ##Update weights\n",
    "        if self.bias:\n",
    "             self.W1 = self.W1 - (self.learningRate * dcdw1[:,:-1])\n",
    "        else:\n",
    "            self.W1 = self.W1 - (self.learningRate * dcdw1) \n",
    "        \n",
    "        self.W2 = self.W2 - (self.learningRate * dcdw2)\n",
    "        \n",
    "        return network_output, target\n",
    "\n",
    "        \n",
    "    \n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        print(length)\n",
    "        cm = np.zeros((width, length))\n",
    "        \n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        print(cm)\n",
    "        return cm\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer size : 1024\n",
      "\n",
      "Hidden layer size : 16\n",
      "\n",
      "Output layer size : 10\n",
      "\n",
      "Parameters to train in W1: 16400\n",
      "\n",
      "Parameters to train in W2: 170\n",
      "\n",
      "Total parameters:  16570\n"
     ]
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "NN.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have **16544** paramters to train and we have **73257 sample.** We have constructed the network so it is possible to feed in batches. It is possible because we take the dot product of the inputs to the weights. Every row will then become one sample. As seen when we make a single feedforward here on the 100 first samples in the training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.2935801 , 0.53181805, 0.56616242, 0.47996289, 0.46616009,\n",
       "        0.49446518, 0.51902744, 0.4075332 , 0.39451713, 0.53753475],\n",
       "       [0.29428719, 0.53195456, 0.56172436, 0.48247316, 0.46564794,\n",
       "        0.49432539, 0.51770928, 0.4078723 , 0.39845368, 0.53950564],\n",
       "       [0.29650362, 0.53834391, 0.56470179, 0.47724194, 0.45857032,\n",
       "        0.48999881, 0.51908384, 0.40301354, 0.40520054, 0.54989863],\n",
       "       [0.2929441 , 0.54213087, 0.55797135, 0.47592701, 0.45092797,\n",
       "        0.49360785, 0.52138971, 0.39173288, 0.39866074, 0.55695546],\n",
       "       [0.2977541 , 0.53415027, 0.56319634, 0.47873243, 0.461921  ,\n",
       "        0.49387453, 0.51941189, 0.40488977, 0.39826737, 0.54441349],\n",
       "       [0.29609571, 0.53403345, 0.56322704, 0.4809644 , 0.46217962,\n",
       "        0.49353208, 0.5182807 , 0.40692669, 0.39832772, 0.54235605],\n",
       "       [0.2980639 , 0.5339024 , 0.56241743, 0.47648037, 0.46179774,\n",
       "        0.49201119, 0.52079336, 0.40310416, 0.40204746, 0.54345106],\n",
       "       [0.29928037, 0.53233322, 0.56327993, 0.47935923, 0.46578965,\n",
       "        0.49326389, 0.51922768, 0.40619188, 0.40819702, 0.54250305],\n",
       "       [0.2927729 , 0.53093059, 0.56366996, 0.4811869 , 0.46568846,\n",
       "        0.49395247, 0.51904417, 0.40630443, 0.3974324 , 0.53985651],\n",
       "       [0.29473495, 0.53064758, 0.56303996, 0.47903772, 0.46628747,\n",
       "        0.4928922 , 0.52097591, 0.40444963, 0.40943942, 0.54301433],\n",
       "       [0.29544032, 0.53209186, 0.5646798 , 0.47984309, 0.46478024,\n",
       "        0.49290632, 0.51901099, 0.40662597, 0.39977734, 0.54055456],\n",
       "       [0.29698562, 0.53432089, 0.56270475, 0.47898823, 0.46227873,\n",
       "        0.49323975, 0.51803456, 0.40852635, 0.39515223, 0.54019615],\n",
       "       [0.29665481, 0.53652937, 0.56343365, 0.47891729, 0.46019113,\n",
       "        0.49368149, 0.51951546, 0.40556358, 0.39089151, 0.54143934],\n",
       "       [0.29914549, 0.53674269, 0.56221051, 0.48096827, 0.45909835,\n",
       "        0.4956244 , 0.5193659 , 0.40794694, 0.39084622, 0.54398621],\n",
       "       [0.29581209, 0.53650324, 0.56372315, 0.48063855, 0.45924057,\n",
       "        0.4943224 , 0.51877539, 0.40117646, 0.39652932, 0.54686643],\n",
       "       [0.29700923, 0.5387094 , 0.56591271, 0.47707783, 0.45779794,\n",
       "        0.49190205, 0.51837219, 0.4043918 , 0.39534382, 0.54834939],\n",
       "       [0.2992033 , 0.53566434, 0.56585916, 0.47638417, 0.46121976,\n",
       "        0.49359036, 0.51909221, 0.40483858, 0.40110622, 0.54684395],\n",
       "       [0.29656253, 0.53501186, 0.56214414, 0.48125832, 0.46084804,\n",
       "        0.49309443, 0.5178772 , 0.40263087, 0.39817397, 0.54421046],\n",
       "       [0.29764597, 0.53464907, 0.56241398, 0.48033809, 0.46017238,\n",
       "        0.49302376, 0.51786032, 0.40309248, 0.39848416, 0.54686222],\n",
       "       [0.29748699, 0.53559223, 0.56178613, 0.47910438, 0.46046138,\n",
       "        0.494541  , 0.52032512, 0.40351433, 0.4004744 , 0.54632351],\n",
       "       [0.2982081 , 0.53671279, 0.56015992, 0.47834489, 0.45889511,\n",
       "        0.49475255, 0.5224542 , 0.4007449 , 0.4003809 , 0.5444858 ],\n",
       "       [0.29694296, 0.53502958, 0.5668739 , 0.47553543, 0.46386146,\n",
       "        0.4928222 , 0.52003743, 0.40645307, 0.40765332, 0.54651691],\n",
       "       [0.29404824, 0.53091719, 0.56568152, 0.48065403, 0.46636933,\n",
       "        0.49291676, 0.51857297, 0.40728463, 0.40151299, 0.54178019],\n",
       "       [0.2981094 , 0.53597261, 0.56232442, 0.47946964, 0.4601995 ,\n",
       "        0.49323998, 0.51725648, 0.40989288, 0.39249084, 0.54079107],\n",
       "       [0.29219697, 0.53316573, 0.56264535, 0.47926175, 0.46235198,\n",
       "        0.49257161, 0.51995205, 0.40659606, 0.39796934, 0.54154935],\n",
       "       [0.2953756 , 0.53112676, 0.56280157, 0.47875625, 0.46438018,\n",
       "        0.492593  , 0.52005307, 0.40699826, 0.40080774, 0.54086852],\n",
       "       [0.29610746, 0.52914951, 0.56379995, 0.47797702, 0.46936262,\n",
       "        0.49298644, 0.51822415, 0.40951808, 0.40228512, 0.53517889],\n",
       "       [0.29284036, 0.52926346, 0.56131127, 0.48047651, 0.46819402,\n",
       "        0.49164902, 0.51962372, 0.40619835, 0.40862495, 0.53665965],\n",
       "       [0.29814107, 0.53342408, 0.56492023, 0.47653273, 0.46209628,\n",
       "        0.49220945, 0.51961423, 0.40365634, 0.40154381, 0.54647677],\n",
       "       [0.29659696, 0.53770678, 0.56220202, 0.48113869, 0.4590661 ,\n",
       "        0.49502402, 0.51937305, 0.40548178, 0.39218743, 0.54665038],\n",
       "       [0.29651881, 0.53330392, 0.56849012, 0.48050745, 0.46528291,\n",
       "        0.49215021, 0.5177011 , 0.40819711, 0.40425855, 0.54553821],\n",
       "       [0.29932548, 0.5392088 , 0.56391244, 0.47960309, 0.45724612,\n",
       "        0.49243024, 0.5189602 , 0.40913162, 0.38907801, 0.54506075],\n",
       "       [0.29868739, 0.5395349 , 0.56250525, 0.47859299, 0.4547106 ,\n",
       "        0.49601439, 0.5207312 , 0.39965686, 0.394344  , 0.55245931],\n",
       "       [0.29875724, 0.53701695, 0.56088255, 0.4799996 , 0.45647944,\n",
       "        0.49438099, 0.51862143, 0.39865844, 0.39788549, 0.5521465 ],\n",
       "       [0.29269933, 0.53445401, 0.56600996, 0.478524  , 0.46576529,\n",
       "        0.49071204, 0.51960405, 0.41051376, 0.40039451, 0.53725839],\n",
       "       [0.29299685, 0.52996325, 0.56359788, 0.48004326, 0.46840445,\n",
       "        0.49300792, 0.51892945, 0.40732435, 0.40452257, 0.53856213],\n",
       "       [0.30288579, 0.54284384, 0.55896099, 0.47955083, 0.4513035 ,\n",
       "        0.4976457 , 0.51991575, 0.40056937, 0.38692348, 0.55057808],\n",
       "       [0.29993759, 0.5402389 , 0.56084939, 0.47892393, 0.45377033,\n",
       "        0.49534287, 0.52005192, 0.3986895 , 0.39451013, 0.55416111],\n",
       "       [0.29851306, 0.54020558, 0.5612279 , 0.47802439, 0.45503403,\n",
       "        0.49471491, 0.52079948, 0.39542201, 0.39470516, 0.5513207 ],\n",
       "       [0.30194707, 0.53982805, 0.55770823, 0.48115716, 0.45523893,\n",
       "        0.49733404, 0.52040556, 0.39695821, 0.40162051, 0.55538611],\n",
       "       [0.30181867, 0.53661849, 0.55928391, 0.48040395, 0.459427  ,\n",
       "        0.49692564, 0.51956499, 0.40031025, 0.41009171, 0.55251635],\n",
       "       [0.29416249, 0.53333002, 0.56395224, 0.47960357, 0.46437303,\n",
       "        0.49226445, 0.51915491, 0.40707559, 0.39991006, 0.53921226],\n",
       "       [0.29623955, 0.53219634, 0.56371127, 0.47827397, 0.46584454,\n",
       "        0.49379675, 0.52101903, 0.40739122, 0.40246931, 0.53975598],\n",
       "       [0.28850912, 0.54066928, 0.56917315, 0.47704828, 0.45825605,\n",
       "        0.48967829, 0.51925613, 0.40123035, 0.39606538, 0.54755246],\n",
       "       [0.29639535, 0.53589041, 0.56245226, 0.48048886, 0.46020996,\n",
       "        0.49361207, 0.51963506, 0.40304209, 0.39396904, 0.54301998],\n",
       "       [0.2987578 , 0.53875778, 0.56127598, 0.47860259, 0.45654899,\n",
       "        0.494982  , 0.52014133, 0.4030521 , 0.39144139, 0.5483211 ],\n",
       "       [0.29727074, 0.53725304, 0.56362468, 0.47972352, 0.45821321,\n",
       "        0.49372799, 0.51871992, 0.40344618, 0.3937361 , 0.54736816],\n",
       "       [0.29275498, 0.53221068, 0.56613275, 0.47976712, 0.46637788,\n",
       "        0.48993737, 0.51707787, 0.41101411, 0.39892618, 0.53624843],\n",
       "       [0.29413291, 0.53119888, 0.56414029, 0.4806035 , 0.46575853,\n",
       "        0.49206135, 0.51622436, 0.40966162, 0.39578376, 0.53706431],\n",
       "       [0.30000605, 0.53242385, 0.56618315, 0.47577401, 0.4636666 ,\n",
       "        0.48988588, 0.51620743, 0.40840999, 0.39871168, 0.53797071],\n",
       "       [0.296852  , 0.52615832, 0.56445925, 0.47882351, 0.46845221,\n",
       "        0.4910824 , 0.51694843, 0.40710176, 0.40765015, 0.53937379],\n",
       "       [0.29538926, 0.53417268, 0.56623199, 0.48014456, 0.46386428,\n",
       "        0.49326321, 0.51890383, 0.40736013, 0.39861131, 0.54235522],\n",
       "       [0.29615933, 0.53589525, 0.56454577, 0.4790722 , 0.46146903,\n",
       "        0.49279024, 0.51938327, 0.40759657, 0.39539849, 0.54263577],\n",
       "       [0.29626342, 0.53671206, 0.56426084, 0.48025551, 0.46050343,\n",
       "        0.49420768, 0.51921474, 0.4080081 , 0.39252969, 0.54312213],\n",
       "       [0.29827869, 0.53652626, 0.56374616, 0.4806392 , 0.45990422,\n",
       "        0.49537921, 0.51812541, 0.40041205, 0.39821318, 0.54992012],\n",
       "       [0.29862773, 0.54051398, 0.56287364, 0.47838091, 0.45565391,\n",
       "        0.49397916, 0.52043851, 0.40151334, 0.393662  , 0.54997769],\n",
       "       [0.29635489, 0.52858389, 0.56763839, 0.47867852, 0.47066398,\n",
       "        0.49215653, 0.51755272, 0.4116949 , 0.40330424, 0.53613609],\n",
       "       [0.29564964, 0.53236872, 0.56497217, 0.48020913, 0.46598767,\n",
       "        0.49271904, 0.51734806, 0.41276637, 0.39436533, 0.53530613],\n",
       "       [0.29705965, 0.53892298, 0.55999907, 0.48080327, 0.45714296,\n",
       "        0.49511041, 0.52147985, 0.39977945, 0.39639542, 0.54905378],\n",
       "       [0.30055236, 0.53630085, 0.55877162, 0.48147828, 0.45769139,\n",
       "        0.49639399, 0.51872598, 0.40232925, 0.39956345, 0.54746564],\n",
       "       [0.29707991, 0.53969546, 0.57020192, 0.47348336, 0.45923846,\n",
       "        0.4893241 , 0.51638732, 0.40697029, 0.39674981, 0.54551867],\n",
       "       [0.29795512, 0.53994208, 0.5586997 , 0.47858543, 0.4570341 ,\n",
       "        0.49496872, 0.51743114, 0.39752193, 0.39730632, 0.54840514],\n",
       "       [0.29629715, 0.53384211, 0.56414907, 0.47684681, 0.46222897,\n",
       "        0.49144887, 0.52179631, 0.39921225, 0.40765091, 0.54725625],\n",
       "       [0.29474764, 0.53514056, 0.5630533 , 0.47918068, 0.4613794 ,\n",
       "        0.49259865, 0.51786177, 0.40934762, 0.38926204, 0.53818132],\n",
       "       [0.29276988, 0.53107252, 0.56646852, 0.47795043, 0.46762632,\n",
       "        0.49127445, 0.52008755, 0.40561799, 0.4047652 , 0.53917027],\n",
       "       [0.29572914, 0.54164984, 0.56213772, 0.47878296, 0.45482139,\n",
       "        0.49097814, 0.51772101, 0.40163773, 0.39001237, 0.54604801],\n",
       "       [0.29966205, 0.53466388, 0.5615266 , 0.47916587, 0.45995382,\n",
       "        0.49346615, 0.51781041, 0.40089399, 0.39663339, 0.54838915],\n",
       "       [0.29678075, 0.53525851, 0.56559432, 0.47784079, 0.46027845,\n",
       "        0.49263127, 0.51829272, 0.4037857 , 0.40194059, 0.54886627],\n",
       "       [0.29714895, 0.53434759, 0.56286043, 0.4777463 , 0.46042935,\n",
       "        0.49169373, 0.52049124, 0.40463309, 0.3958942 , 0.54555944],\n",
       "       [0.29901118, 0.53052583, 0.56418858, 0.48074971, 0.46638122,\n",
       "        0.49380729, 0.51726255, 0.40647314, 0.40076896, 0.53930669],\n",
       "       [0.29511768, 0.52875609, 0.56025773, 0.4813343 , 0.46592805,\n",
       "        0.49296675, 0.51951897, 0.40855537, 0.40557122, 0.53829773],\n",
       "       [0.29452924, 0.52822373, 0.55990058, 0.48261815, 0.46775509,\n",
       "        0.49377639, 0.52080981, 0.40590796, 0.41055452, 0.53712795],\n",
       "       [0.29227235, 0.53400544, 0.56493529, 0.48070863, 0.46264543,\n",
       "        0.49210865, 0.51858333, 0.40602384, 0.39596355, 0.54079581],\n",
       "       [0.2965822 , 0.53337929, 0.56521529, 0.47933704, 0.46456285,\n",
       "        0.49293847, 0.51720439, 0.40989833, 0.39921764, 0.54066214],\n",
       "       [0.29995014, 0.5377587 , 0.5607985 , 0.48040687, 0.45618407,\n",
       "        0.49446611, 0.5181051 , 0.40283885, 0.39541897, 0.54867437],\n",
       "       [0.29560977, 0.52711035, 0.56413833, 0.48061144, 0.46882254,\n",
       "        0.49076322, 0.51660906, 0.41050802, 0.40628609, 0.53771516],\n",
       "       [0.29621347, 0.52898542, 0.563031  , 0.48132682, 0.4674523 ,\n",
       "        0.49153144, 0.51518285, 0.41095441, 0.40144133, 0.5360604 ],\n",
       "       [0.29436146, 0.53379916, 0.56409415, 0.48074009, 0.46282445,\n",
       "        0.49352954, 0.51980377, 0.4050901 , 0.39965826, 0.54325545],\n",
       "       [0.29617657, 0.53293802, 0.56382028, 0.47952326, 0.46318151,\n",
       "        0.49283675, 0.51791936, 0.40730668, 0.40116944, 0.54250244],\n",
       "       [0.29264856, 0.5315881 , 0.56472501, 0.48117548, 0.46597069,\n",
       "        0.49397599, 0.51968221, 0.40872233, 0.39859478, 0.539184  ],\n",
       "       [0.29490542, 0.53197951, 0.56302274, 0.48073809, 0.46526931,\n",
       "        0.49361921, 0.51727662, 0.40952013, 0.39585191, 0.53654556],\n",
       "       [0.2975458 , 0.53671839, 0.56258432, 0.47791221, 0.4598672 ,\n",
       "        0.49306403, 0.51987276, 0.40432274, 0.3958015 , 0.54140696],\n",
       "       [0.29560722, 0.5347923 , 0.56524626, 0.47804358, 0.46264565,\n",
       "        0.49236283, 0.51990064, 0.40480533, 0.40376034, 0.54459799],\n",
       "       [0.29740515, 0.53442777, 0.55931106, 0.48133778, 0.46344865,\n",
       "        0.49427726, 0.51952647, 0.40465704, 0.40381541, 0.5398188 ],\n",
       "       [0.29705263, 0.53770896, 0.56144953, 0.48073701, 0.46095516,\n",
       "        0.49451182, 0.52076393, 0.40430232, 0.39770775, 0.54048992],\n",
       "       [0.29889472, 0.53884305, 0.56417943, 0.47732238, 0.45609251,\n",
       "        0.4927016 , 0.51838273, 0.39931714, 0.39918841, 0.55520682],\n",
       "       [0.29596086, 0.53862701, 0.56305423, 0.47964139, 0.45554608,\n",
       "        0.48967431, 0.51773631, 0.39880782, 0.40171568, 0.55351435],\n",
       "       [0.28609039, 0.53629858, 0.56581387, 0.48206401, 0.46292895,\n",
       "        0.4901494 , 0.51555355, 0.40750154, 0.39618446, 0.53710576],\n",
       "       [0.30242021, 0.53160184, 0.5634018 , 0.47815537, 0.46391093,\n",
       "        0.49476296, 0.52217584, 0.41211852, 0.40535591, 0.54758855],\n",
       "       [0.29488272, 0.5297219 , 0.5600215 , 0.48467608, 0.46602484,\n",
       "        0.49544471, 0.52136685, 0.40033274, 0.41228231, 0.54211989],\n",
       "       [0.29310862, 0.52881326, 0.56520517, 0.4796102 , 0.46399108,\n",
       "        0.48980872, 0.51882961, 0.4068995 , 0.40619684, 0.54427071],\n",
       "       [0.30055535, 0.53208438, 0.55750248, 0.48039763, 0.46089108,\n",
       "        0.49432134, 0.51762257, 0.40219522, 0.39669418, 0.54247524],\n",
       "       [0.30044563, 0.53776391, 0.56183765, 0.47937022, 0.45674696,\n",
       "        0.49567818, 0.52034174, 0.39883426, 0.40001891, 0.55318298],\n",
       "       [0.29843507, 0.5400432 , 0.56136227, 0.48137059, 0.45515339,\n",
       "        0.4948775 , 0.51789339, 0.40306221, 0.39401386, 0.54924587],\n",
       "       [0.30104076, 0.54110286, 0.56302137, 0.47725604, 0.45404588,\n",
       "        0.49295754, 0.51803877, 0.40409076, 0.39694433, 0.55208562],\n",
       "       [0.29611238, 0.53711433, 0.56241312, 0.47944846, 0.45897026,\n",
       "        0.49323933, 0.52093228, 0.40799703, 0.39361735, 0.54080614],\n",
       "       [0.30013622, 0.53597394, 0.56294354, 0.47784008, 0.46059466,\n",
       "        0.49444587, 0.51972371, 0.40454039, 0.39874679, 0.54436348],\n",
       "       [0.29877935, 0.5366306 , 0.5559224 , 0.48428586, 0.46036019,\n",
       "        0.4998073 , 0.52252629, 0.40545931, 0.40200367, 0.54299244],\n",
       "       [0.2931283 , 0.53965231, 0.56410952, 0.48191377, 0.4574312 ,\n",
       "        0.49442178, 0.52191357, 0.4100819 , 0.39333906, 0.54366105],\n",
       "       [0.29671001, 0.53681704, 0.56289706, 0.47908089, 0.45775894,\n",
       "        0.49236343, 0.5190462 , 0.4065988 , 0.39518492, 0.54621921]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN = NeuralNetwork()\n",
    "len(X_training_scaled)\n",
    "NN.feedForward(X_training_scaled[:100])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now it is time to train the network for the first time with sigmoid activation in both the hidden and the last activation layer. Since samples (73275) * trainable parameters(16544) = 1.212.201.600, one single epoch will need a lot of computations. We do not choose to feed in the whole network in case of stack overflow, as we need to save a lot of data, i.e. in the weight matrices. We start by feeding into online feeding and saving the loss and accuracy every 1000th sample. The online method is updating the weight for every single sample and therefore a constant O(n) is added to the complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################*#########################################################################"
     ]
    }
   ],
   "source": [
    "loss = []\n",
    "#\n",
    "count = 1\n",
    "acc = []\n",
    "for i in range(29):\n",
    "    print(\"*\", end=\"\")\n",
    "    for i in np.arange(1,(len(X_training_scaled)),1):    \n",
    "        output, target = NN.train(X_training_scaled[i][:, np.newaxis].T, y_training_one_hot[i])\n",
    "        if( i % 1000 == 0):\n",
    "            print(\"#\", end=\"\")\n",
    "            loss.append(NN.MSE(output,target))\n",
    "            pred = NN.feedForward(X_training_scaled) #Get predictions\n",
    "            pred = [np.argmax(x) for x in pred] #Get the value that the network has put the highst possibility on\n",
    "            pred = np.array(pred)\n",
    "            acc.append(NN.acc(y_training.flatten(), pred))\n",
    "      "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model to binary with the weights with Pickle\n",
    "As the online training takes such a long time it is a good idea to save the trained network, with the modified weights, if we wanted to make predictions from it later or futher the analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pickle\n",
    "with open(os.path.join(\".\",\"neural_network_basic_W1.pkl\"), \"bw\") as fh:\n",
    "    data = (NN.W1)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"neural_network_basic_W2.pkl\"), \"bw\") as fh:\n",
    "    data = (NN.W2)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"loss-basic_neural_network.pkl\"), \"bw\") as fh:\n",
    "    data = (loss)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"acc-basic_neural_network.pkl\"), \"bw\") as fh:\n",
    "    data = (acc)\n",
    "    pickle.dump(data, fh)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10\n",
      "[[1.024e+04 7.320e+02 7.350e+02 4.970e+02 1.447e+03 5.800e+01 8.100e+01\n",
      "  1.700e+01 3.600e+01 1.800e+01]\n",
      " [4.900e+02 8.311e+03 5.170e+02 2.530e+02 7.490e+02 7.000e+01 8.900e+01\n",
      "  2.700e+01 6.300e+01 1.600e+01]\n",
      " [6.960e+02 1.088e+03 2.936e+03 2.020e+02 3.242e+03 1.420e+02 1.020e+02\n",
      "  4.400e+01 2.700e+01 1.800e+01]\n",
      " [4.300e+02 3.580e+02 2.550e+02 5.600e+03 6.070e+02 1.250e+02 1.900e+01\n",
      "  2.600e+01 3.000e+01 8.000e+00]\n",
      " [3.590e+02 3.500e+02 9.560e+02 2.080e+02 4.785e+03 1.060e+02 4.400e+01\n",
      "  3.100e+01 3.300e+01 1.000e+01]\n",
      " [3.290e+02 3.230e+02 5.340e+02 5.990e+02 2.316e+03 1.446e+03 5.400e+01\n",
      "  8.400e+01 1.200e+01 3.000e+01]\n",
      " [6.480e+02 1.979e+03 4.350e+02 1.100e+02 7.330e+02 1.110e+02 1.532e+03\n",
      "  1.600e+01 2.600e+01 5.000e+00]\n",
      " [3.180e+02 3.810e+02 6.340e+02 2.670e+02 2.294e+03 1.510e+02 2.900e+01\n",
      "  8.770e+02 3.700e+01 5.700e+01]\n",
      " [3.850e+02 4.480e+02 7.420e+02 1.730e+02 1.736e+03 3.200e+01 2.800e+01\n",
      "  1.000e+01 1.009e+03 9.600e+01]\n",
      " [4.170e+02 4.800e+02 6.970e+02 1.900e+02 1.836e+03 1.420e+02 4.300e+01\n",
      "  5.800e+01 1.440e+02 9.410e+02]]\n",
      "Precision for label 0 is 0.72\n",
      "Recall for label 0 is 0.74\n",
      "Precision for label 1 is 0.58\n",
      "Recall for label 1 is 0.79\n",
      "Precision for label 2 is 0.35\n",
      "Recall for label 2 is 0.35\n",
      "Precision for label 3 is 0.69\n",
      "Recall for label 3 is 0.75\n",
      "Precision for label 4 is 0.24\n",
      "Recall for label 4 is 0.7\n",
      "Precision for label 5 is 0.61\n",
      "Recall for label 5 is 0.25\n",
      "Precision for label 6 is 0.76\n",
      "Recall for label 6 is 0.27\n",
      "Precision for label 7 is 0.74\n",
      "Recall for label 7 is 0.17\n",
      "Precision for label 8 is 0.71\n",
      "Recall for label 8 is 0.22\n",
      "Precision for label 9 is 0.78\n",
      "Recall for label 9 is 0.19\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x720 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"loss\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"iterations x1000\")\n",
    "plt.plot(loss)\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"iterations x1000\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(acc)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "##Accuracy score\n",
    "accuracy = NN.acc(y_training.flatten(), pred)\n",
    "\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot()\n",
    "## Confusion matrix\n",
    "cm = NN.confusion_matrix(y_training, pred)\n",
    "ax.set_ylabel(\"Actual label\")\n",
    "ax.set_xlabel(\"Predicted value\")\n",
    "ax.set_title(\"Accuracy score {} %\".format(round(accuracy*100),2))\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, square=True, cbar=False, fmt='g')\n",
    "ax.set_ylim(10,0) #maked heatmap showiung all squares\n",
    "\n",
    "for i in np.arange(len(np.unique(y_training))):\n",
    "    print(\"Precision for label {} is {}\".format(i, round(NN.precision(i, cm),2)))\n",
    "    print(\"Recall for label {} is {}\".format(i, round(NN.recall(i, cm),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ReLU implementation in hidden layer\n",
    "\n",
    "We change the weight intilization for the hidden layer because it is suggested to have the weights within the range below when using ReLU:\n",
    "\n",
    "$$ \\frac {-2}{\\sqrt n} , \\frac {2}{\\sqrt n}$$\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "@np.vectorize\n",
    "def ReLU(x):\n",
    "    return np.maximum(0.0, x)\n",
    "#derivation\n",
    "@np.vectorize\n",
    "def ReLU_derivation(x):\n",
    "    if x <= 0:\n",
    "        return 0\n",
    "    else:\n",
    "        return 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_relu(object):\n",
    "    \n",
    "    def __init__(self, bias, input_layer, hidden_layer, output_layer, learning_rate):\n",
    "        self.inputLayerSize = input_layer\n",
    "        self.hiddenLayerSize = hidden_layer\n",
    "        self.outputLayerSize = output_layer\n",
    "        self.learningRate = learning_rate\n",
    "        self.bias = bias       \n",
    "        self.initilize_weights()\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "    \n",
    "           \n",
    "    def initilize_weights(self):\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0 # default self.bias is true\n",
    "       \n",
    "        rangeW1 = 2 / np.sqrt(self.inputLayerSize+bias_node) #Get the range to be as defined above \n",
    "        distrubutionW1 = truncated_normal(mean=0,sd=1, low=-rangeW1, upp=rangeW1) # Create a normal distrubtion trunctaed within the range\n",
    "        self.W1 = distrubutionW1.rvs((self.inputLayerSize+bias_node,self.hiddenLayerSize,)) #Randomly distribute the normal distrubtion with correct dimensions \n",
    "        \n",
    "        rangeW2 = 1 / np.sqrt(self.hiddenLayerSize)\n",
    "        distrubutionW2 = truncated_normal(mean=0, sd=1, low=-rangeW2, upp=rangeW2)\n",
    "        self.W2 = distrubutionW2.rvs(( self.hiddenLayerSize+bias_node,self.outputLayerSize))\n",
    "    \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "   \n",
    "            x = np.array(x, ndmin=2) # every row is an input\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(x))\n",
    "                x = np.c_[x, biases]  ##adding bias to the input layer # bias is an extra one\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            self.z1 = np.dot(x, self.W1)\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(self.z1))\n",
    "                self.z1 = np.c_[self.z1, biases]  ##Adding the bias to the hidden layer\n",
    "\n",
    "            self.a1 = ReLU(self.z1) #Relu activation function\n",
    "\n",
    "\n",
    "            self.z2 = np.dot(self.a1, self.W2)\n",
    "            self.a2 = sigmoid(self.z2)\n",
    "\n",
    "            return self.a2\n",
    "        \n",
    "     \n",
    "    ##This is the implementatiion of the back-propogation\n",
    "    def backward(self, iput, output, target):\n",
    "        \n",
    "        #Calculate dcdw2 - how much the an arbritary change for each weiight in the W1 matrix affect the cost\n",
    "        dcdy = self.MSE_prime(output, target) #partial derivative of error w.r.t. y hat (prediction)\n",
    "        #print(\"shape pof dcdy\", dcdy.shape)\n",
    "        dyDz2 = sigmoid_derivative(self.z2) #Patial derivative of yhat with respect to z2,\n",
    "        #print(\"shape of dydz2\", dyDz2.shape)\n",
    "        delta2 = dcdy * dyDz2\n",
    "        \n",
    "       # print(\"shape of delta 2\", delta2.shape)\n",
    "        \n",
    "        \n",
    "        dz2dw2 = self.a1.T # partial derivative of z2 with respect to weights\n",
    "        \n",
    "        dcdw2 = np.dot( dz2dw2, delta2) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "       # print(dcdw2.shape)\n",
    "      \n",
    "        ##Calculate dcdw1 - how much the an arbritary change for each weiight in the W2 matrix affect the cost\n",
    "        \n",
    "        dz2da1 =  self.W2.T  # Equals to the weight # Hidden errors\n",
    "       \n",
    "        dcda1 = np.dot(delta2, dz2da1 )\n",
    "        #print(\"shape\",dcda1.shape)\n",
    "        da1dz1 = ReLU_derivation(self.z1) #the derivative of the activation function for a1 - hidden layer\n",
    "      \n",
    "        \n",
    "        \n",
    "        delta1 = dcda1 * da1dz1\n",
    "        \n",
    "        iput = np.array(iput, ndmin=2) # every row is an input\n",
    "\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(iput))\n",
    "            iput = np.c_[iput, biases]  ##adding bias to the input layer\n",
    "            \n",
    "            \n",
    "        dz1dw1 = iput.T # The matrix product for input and weights - partial derivative of the product mutliplication w.r.t. the weights is simply the input then.\n",
    "       \n",
    "        dcdw1 = np.dot(dz1dw1, delta1)\n",
    "     \n",
    "        #print(dcdw1.shape)\n",
    "     \n",
    "        \n",
    "        return dcdw1, dcdw2\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    def train_single(self, training, target):\n",
    "        \n",
    "        network_output= self.feedForward(training)\n",
    "    \n",
    "        dcdw1, dcdw2 = self.backward(training, network_output,  target)\n",
    "    \n",
    "        ##Update weights\n",
    "        if self.bias:\n",
    "             self.W1 = self.W1 - (self.learningRate * dcdw1[:,:-1])\n",
    "        else:\n",
    "            self.W1 = self.W1 - (self.learningRate * dcdw1) \n",
    "        \n",
    "        self.W2 = self.W2 - (self.learningRate * dcdw2)\n",
    "        \n",
    "        return network_output, target\n",
    "    \n",
    "    \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              batch_size,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        \n",
    "        intermediate_weights = []\n",
    "        \n",
    "        \n",
    "        loss_list = []\n",
    "        iterations = []\n",
    "        accuracy_list = []\n",
    "                        \n",
    "        iteration_count = 1\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"Epoch {}\".format(str(epoch+1)), end=\"\")\n",
    "        \n",
    "            for iteration in np.arange(0,len(data_array+1), batch_size): #Move index a batch size for every run\n",
    "                #print(iteration)\n",
    "                start_index = iteration\n",
    "                end_index = iteration+batch_size-1\n",
    "               \n",
    "                features = data_array[start_index : end_index]\n",
    "                targets = labels_one_hot_array[start_index : end_index]\n",
    "                \n",
    "                self.train_single(features, targets) #Train the batch size\n",
    "                                \n",
    "               ##For intermediate evaluation\n",
    "                if ((iteration_count % 120 ) == 0 ): #We pick an iteration number to save the loss abnd accuracy\n",
    "                \n",
    "                    predicted = self.feedForward(X_training_scaled) # get network puput\n",
    "                    \n",
    "                    predicted = [np.argmax(x) for x in predicted] \n",
    "                    loss = self.MSE(predicted, y_training.flatten())\n",
    "                    loss_list.append(loss)    \n",
    "                    \n",
    "                    acc = self.acc( y_training.flatten(), predicted)\n",
    "                    accuracy_list.append(acc)\n",
    "                    \n",
    "                   \n",
    "                    \n",
    "                    np.set_printoptions(precision=2)\n",
    "                    print(\"Iteration {0} -  loss: {1:.2f}, accuracy: {2:.2f}\".format(iteration_count, loss,acc, ))\n",
    "                    print(\"predicted: \", predicted[1:20])   \n",
    "                # print(\"predicted : {}, y_target:{}\".format(predicted,y))\n",
    "\n",
    "                    iterations.append(iteration_count)                                \n",
    "\n",
    "                \n",
    "                iteration_count += 1\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.W1.copy(), \n",
    "                                                 self.W2.copy()))\n",
    "                \n",
    "            \n",
    "                    \n",
    "                \n",
    "            \n",
    "        return intermediate_weights, loss_list, accuracy_list,iterations\n",
    "    \n",
    "\n",
    "        \n",
    "    \n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        cm = np.zeros((width, length))\n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        return cm\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer size : 1024\n",
      "\n",
      "Hidden layer size : 16\n",
      "\n",
      "Output layer size : 10\n",
      "\n",
      "Parameters to train in W1: 16400\n",
      "\n",
      "Parameters to train in W2: 170\n",
      "\n",
      "Total parameters:  16570\n"
     ]
    }
   ],
   "source": [
    "NN_relu = NeuralNetwork_relu(bias=True, input_layer=X_training_scaled.shape[1], hidden_layer=16, output_layer=10, learning_rate=0.002)\n",
    "NN_relu.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch size, Epoch, and iterations\n",
    "\n",
    " As seen with the Sigmoid implementation we used an online training technique and we wanted 29 epochs (all training samples have been trainined 29 times) we got an total iteration of 73275(samples) * 29(epochs) =  2.124.975 iterations.\n",
    "\n",
    "\n",
    "Every iteration is training a total of 16570 parameters. So if we assume one parameter training is denoted as one computation there are astonishing 2.124.975 * 16570 = 35.210.835.750 compuations.\n",
    "\n",
    "Therefore we will introduce a batch size that will make the iteration amount smaller and therefore the total computation smaller.\n",
    "\n",
    "\n",
    "##### Note!  larger batch size means that there will be larger matrix multiplciations between weights and inputs. However, it is more efficient to make batch operations than single. More importantly, the extra updates that was carried out with the large amount of iterations will go away when increasing the batch size."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the weights loss and accuracy\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-974724619dc0>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintermediate_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_relu\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-1d8bd7263aa6>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_array, labels_one_hot_array, batch_size, epochs, intermediate_results)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m                     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpredicted\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 170\u001b[0;31m                     \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpredicted\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    171\u001b[0m                     \u001b[0mloss_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    172\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-1d8bd7263aa6>\u001b[0m in \u001b[0;36mMSE\u001b[0;34m(self, yHat, y)\u001b[0m\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    113\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mMSE\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myHat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m##Cost function Mean squared error\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 114\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0myHat\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    115\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    116\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mMSE_prime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0myHat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m# Derivative of the cost fucnction\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "\n",
    "intermediate_weights, loss_list, accuracy_list, iteration_list = NN_relu.train(X_training_scaled, y_training_one_hot,batch_size=20, epochs=29, intermediate_results=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-0bbad8e5fad7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mylabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Error\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxlabel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Iterations\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mplot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfigure\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtitle\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Accuracy\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_list' is not defined"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.title(\"loss\")\n",
    "plt.ylabel(\"Error\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.plot(loss_list)\n",
    "plt.figure()\n",
    "plt.title(\"Accuracy\")\n",
    "plt.xlabel(\"Iterations\")\n",
    "plt.ylabel(\"accuracy\")\n",
    "plt.plot(accuracy_list)\n",
    "\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "##Accuracy score\n",
    "accuracy = NN_relu.acc(y_training.flatten(), pred)\n",
    "pred = NN_relu.feedForward(X_training_scaled)\n",
    "pred = [np.argmax(x) for x in pred]\n",
    "\n",
    "plt.figure(figsize=(10,10))\n",
    "ax = plt.subplot()\n",
    "## Confusion matrix\n",
    "cm = NN.confusion_matrix(y_training, pred)\n",
    "ax.set_ylabel(\"Actual label\")\n",
    "ax.set_xlabel(\"Predicted value\")\n",
    "ax.set_title(\"Accuracy score {} %\".format(round(accuracy*100),2))\n",
    "\n",
    "ax = sns.heatmap(cm, annot=True, square=True, cbar=False, fmt='g')\n",
    "ax.set_ylim(10,0) #maked heatmap showiung all squares\n",
    "\n",
    "for i in np.arange(len(np.unique(y_training))):\n",
    "    print(\"Precision for label {} is {}\".format(i, round(NN_relu.precision(i, cm),2)))\n",
    "    print(\"Recall for label {} is {}\".format(i, round(NN_relu.recall(i, cm),2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save trained model to binary files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'loss_list' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-36-6a37c470124e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"loss-relu_NN.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bw\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mloss_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     11\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"acc-relu_NN.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bw\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'loss_list' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "with open(os.path.join(\".\",\"NN_ReLU_W1.pkl\"), \"bw\") as fh:\n",
    "    data = (NN_relu.W1)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"NN_ReLU_W2.pkl\"), \"bw\") as fh:\n",
    "    data = (NN_relu.W2)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"loss-relu_NN.pkl\"), \"bw\") as fh:\n",
    "    data = (loss_list)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"acc-relu_NN.pkl\"), \"bw\") as fh:\n",
    "    data = (accuracy_list)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"iteration_list_ReLU.pkl\"), \"bw\") as fh:\n",
    "    data = (iteration_list)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"intermediate_weights_relu.pkl\"), \"bw\") as fh:\n",
    "    data = (intermediate_weights)\n",
    "    pickle.dump(data, fh)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test accuracy :  0.1952980946527351\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'intermediate_weights' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-37-4993f241e587>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mweights\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mintermediate_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0mtestAcc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'intermediate_weights' is not defined"
     ]
    }
   ],
   "source": [
    "predictions = NN_relu.feedForward(X_test_scaled)\n",
    "predictions = [np.argmax(x) for x in predictions]\n",
    "testAcc = NN_relu.acc(y_test.flatten(), predictions)\n",
    "print(\"Test accuracy : \", testAcc)\n",
    "\n",
    "\n",
    "weights = np.array(intermediate_weights)\n",
    "\n",
    "testAcc = []\n",
    "for i in range(len (intermediate_weights)):\n",
    "    NN_relu.W1 = intermediate_weights[i][0]\n",
    "    NN_relu.W2 = intermediate_weights[i][1]\n",
    "    predictions = NN_relu.feedForward(X_test_scaled)\n",
    "    predictions = [np.argmax(x) for x in predictions]\n",
    "    testAcc.append( NN_relu.acc(y_test.flatten(), predictions))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(testAcc)\n",
    "plt.xlabel(\"Epochs\")\n",
    "plt.ylabel(\"Accuracy\")\n",
    "plt.title(\"Test accuracy for ReLU implementations\", fontsize=(15))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual labels: [ 5  2  1 10  6  1  9  1  1  8]\n"
     ]
    }
   ],
   "source": [
    "fig, ax = plt.subplots(1,10, figsize=(20,10))\n",
    "for i in np.arange(10):\n",
    "    predicted = (predictions[i]) +1\n",
    "    ax[i].set_title(\"Predicted:{}\".format(predicted))\n",
    "    #ax[i].imshow(X_training[i].reshape(32,32))\n",
    "   \n",
    "    ax[i].imshow(X_test[i].reshape(32,32))\n",
    "plt.show()\n",
    "\n",
    "print(\"actual labels:\",  y_test[:10].flatten()+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*******\n",
    "## Task 3: implementing softmax classifer\n",
    "The softmax activation functions is about the probability. The sigmoid function, that we have used as the activation function so far has been working as a probability. However, the output for our ten classes' sum has not added up to 1,therefore, it is not a probability by definition. However, the softmax activation function is assigning each output a probability, which is what we are looking for when classifying. \n",
    "\n",
    "To illustrate the shortcomings of the sigmoid function we assume that we have 6 output neurons with the last weighted sum vector being [1,2,3,4,5,6]. **If it is put into the sigmoid function we get [0.5, 0.73,0.88,0.95,0.98,0.99]**. The distribution of the probabilities does not add up to 1. On the oth\n",
    "\n",
    "\n",
    "$$f_{i}(\\overrightarrow a)=\\frac {e^{a_{i}}}{\\sum _{k}e^{a_k} }$$\n",
    "\n",
    "\n",
    "Where a is the input vector (weighted sum from last layer). As the formula says for each label the output will be $e^{weighted sum}$ divided with the sum of all the output neurons $e ^ {weighted sum}$. The distrubtion will therefore be dependent on each other, and the sum will be 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.88079708 0.26894142 0.26894142 0.04742587]\n",
      " [0.11920292 0.73105858 0.73105858 0.95257413]]\n"
     ]
    }
   ],
   "source": [
    "def softmax(a):\n",
    "    a = np.array(a)\n",
    "    return np.exp(a) / np.sum(np.exp(a), axis=0)\n",
    "\n",
    "\n",
    "test_input = [[3.0,1.0,2.0,1.0],[1,2,3,4]]\n",
    "\n",
    "print(softmax(test_input))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualize softmax vs sigmoid output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "z2 =  [1, 2, 3, 4, 1, 2, 3]\n",
      "Sigmoid activation =  [0.73105858 0.88079708 0.95257413 0.98201379 0.73105858 0.88079708\n",
      " 0.95257413]\n",
      "Sofmax =  [0.02364054 0.06426166 0.1746813  0.474833   0.02364054 0.06426166\n",
      " 0.1746813 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<BarContainer object of 7 artists>"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1440x360 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "test_z2 = [1,2,3,4,1,2,3]\n",
    "\n",
    "sigmoid_activations_output = sigmoid(test_z2)\n",
    "softmax_output = softmax(test_z2)\n",
    "\n",
    "print(\"z2 = \", test_z2)\n",
    "print(\"Sigmoid activation = \", sigmoid_activations_output)\n",
    "print(\"Sofmax = \", softmax_output)\n",
    "\n",
    "\n",
    "fig,ax = plt.subplots(1,2, figsize=(20,5))\n",
    "ax[0].set_title(\"Sigmoid\", fontsize=20)\n",
    "ax[0].set_xlabel(\"Output neurons/labels\")\n",
    "ax[0].set_ylabel(\"ouput value\")\n",
    "ax[0].bar(x=np.arange(len(softmax_output)), height=sigmoid_activations_output )\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "ax[1].set_title(\"Softmax\")\n",
    "ax[1].set_xlabel(\"Output neurons/labels\")\n",
    "ax[1].set_ylabel(\"ouput value\")\n",
    "ax[1].bar(x=np.arange(len(softmax_output)), height=softmax_output )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Derivative of softmax - (used in back propogation)\n",
    "\n",
    "In order to take the derivative of the softmax function we can use the quotient rule of calculus. It says if:\n",
    "$$ f(x) = \\frac{g(x)}{h(x)} $$\n",
    "\n",
    "**Then:** \n",
    "\n",
    "$$ f(x)' = \\frac {g'(x)h(x)-h'(x)g(x)}{h(x)}$$\n",
    "\n",
    "\n",
    "The  in our case this holds : \n",
    "\n",
    "$$g _ i =  e^{a_i} $$\n",
    "\n",
    "$$h_i = \\sum e^{a_k} $$\n",
    "\n",
    "**********\n",
    "We take the partial derivative w.r.t. the weighted sum because we will derive the partial derivative of the cost function w.r.t. the weights by using the chain rule. So in order to get the partial derivative of the softmax w.r.t. the weighted sum we get the following notation. \n",
    "\n",
    "$$\\frac {\\partial a_{i}}{\\partial z_{j}} =\\frac {\\partial}{\\partial z_j} \\big ( \\frac {e^{z_i}} {\\sum_{k} e^{z_k} } \\big)$$\n",
    "\n",
    "\n",
    "\n",
    "*********\n",
    "### Then $g'(x)$ is : ###\n",
    "\n",
    "\n",
    "\n",
    "$$\\frac {\\partial } {\\partial z _j} (e^{z_i})=  \\left\\{ \\begin{array}{lr}e^{z_i}, i = j \\\\ 0,  i \\neq  j \\end{array}\\right. $$\n",
    "\n",
    "*************\n",
    "### Then $h'(x)$ is : ###\n",
    "\n",
    "\n",
    "$$\\frac {\\partial } {\\partial z _j} (\\sum_{k} e^{z_k})= e^{z_j}$$\n",
    "\n",
    "**********\n",
    "\n",
    "### Putting it al togheter yields two results, \n",
    "When **$i = j$** the result look much like the one we have for sigmoid :\n",
    "\n",
    "$$\\frac {\\partial a_i } {\\partial z _j} = a_i(i-a_i)$$\n",
    "\n",
    "When $i \\neq j$ we get the following:\n",
    "\n",
    "\n",
    "$$\\frac {\\partial a_i } {\\partial z _j} = -a_i{a_j}$$\n",
    "\n",
    "[http://www.adeveloperdiary.com/data-science/deep-learning/neural-network-with-softmax-in-python/]\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The softmax function's partial derivative with respect to the weighted sum is \n",
    "\n",
    "#$$\\frac {\\partial \\sigma (\\overrightarrow a)}{\\partial  a_{j}} = \\sigma _{i}(\\overrightarrow a)\\big( \\delta _{ij} - \\sigma _{j}(\\overrightarrow a) \\big ) $$\n",
    "\n",
    "#No graph can represent the derivative for the softmax function. It is becuase it takes the whole vector **a** instead of each element inside the vectors, like for example the sigmoid does. We have illustrated it by annotating the input conventionally with an arrow above the a: indicating it is a vector.  The delta is the kronecker delta."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "def softmax_grad(z):\n",
    "    # Reshape the 1-d softmax to 2-d so that np.dot will do the matrix multiplication\n",
    "    ##Vectorized version that will hold the i = j clause\n",
    "    # s i the softmax of the x\n",
    "    z = softmax(z)\n",
    "    s = z.reshape(-1,1)\n",
    "    return np.diagflat(s) - np.dot(s, s.T) # this simple line of code is obeying the i = j difference of output\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.08780359 0.64878564 0.08780359 0.08780359 0.08780359]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[ 0.14362012, -0.05295834, -0.03022059, -0.03022059, -0.03022059],\n",
       "       [-0.05295834,  0.21183336, -0.05295834, -0.05295834, -0.05295834],\n",
       "       [-0.03022059, -0.05295834,  0.14362012, -0.03022059, -0.03022059],\n",
       "       [-0.03022059, -0.05295834, -0.03022059,  0.14362012, -0.03022059],\n",
       "       [-0.03022059, -0.05295834, -0.03022059, -0.03022059,  0.14362012]])"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_output = softmax([1,3,1,1,1])\n",
    "\n",
    "print(test_output)\n",
    "\n",
    "softmax_grad(test_output)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical cross entropy cost function \n",
    "We will need to use the cross entropy as cost function. The entropy is based on information theory that tells how many questions you have to ask to know what symbol e.g. a machine will produce, if you already know the probability distribution of the symbols. As we will get a probability distribution from softmax this is applicable. So if the entropy drops we can ask fewer questions, which means we will need to minimize the entropy.\n",
    "\n",
    "$$ H(y,a) = - \\sum y_{i} loga_{i}$$\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the output from the softmax: [[0.5        0.88079708 0.11920292 0.04742587 0.01798621]\n",
      " [0.5        0.11920292 0.88079708 0.95257413 0.98201379]]\n",
      "Test-target, [[0, 1, 0, 0, 0], [0, 0, 0, 1, 0]]\n",
      "loss [[-0.         -0.12692801 -0.         -0.         -0.        ]\n",
      " [-0.         -0.         -0.         -0.04858735 -0.        ]]\n",
      "0.17551536261671466\n"
     ]
    }
   ],
   "source": [
    "test_output = softmax([[1,4,1,1,1],[1,2,3,4,5]])\n",
    "\n",
    "print(\"the output from the softmax:\", test_output)\n",
    "\n",
    "test_target = [[0,1,0,0,0],[0,0,0,1,0]]\n",
    "\n",
    "print(\"Test-target,\", test_target)\n",
    "\n",
    "\n",
    "def cross_entropy(output, target):\n",
    "    loss =  target * np.log(output)\n",
    "    print(\"loss\", loss)\n",
    "    return -np.sum(loss)\n",
    "\n",
    "loss = cross_entropy(test_output, test_target)\n",
    "print(loss)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### When using the cross entropy with softmax (as conventional) the partial derivative of the Loss w.r.t. z has an elegant solution.\n",
    "\n",
    "\n",
    "$$\\frac {\\partial C}{\\partial z_i} = \\hat y - y$$\n",
    "\n",
    "Before we took the partial derivative of the cost function to the activation and by chain rule we took the multiplication with the partial derivative of the activation to the weighted sum to get the partial derivative of the cost function to the weighted sum (delta2). Now we can omit those steps and directly get delta2 directyl by the defintion above. An elegant and simple solution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Rescale\n",
    "When using the cross entropy we want to rescale our target to be either 0 or 1, instead of being 0.01 and 0.99. It is because the 0's is canceling out the cross entropy for the wrong classes. We end up with minimizing the cross entropy of only the target class\n",
    "\n",
    "\n",
    "## Finaly, let us train the model with the softmax + crossentropy\n",
    "\n",
    "We have changed the feedforward last layer activation function to our implementation of softmax. In the training we are calculating the delta2 directly before preceding with the backpropogation. We are implementing a cross_entropy function inside the network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def softmax(X):\n",
    "    X = np.array(X)\n",
    "    biggest = X.max(axis=1)\n",
    "\n",
    "    temp = X - biggest[:,np.newaxis]\n",
    "    return np.exp(temp)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork_softmax(object):\n",
    "    \n",
    "    def __init__(self, bias, input_layer, hidden_layer, output_layer, learning_rate):\n",
    "        self.inputLayerSize = input_layer\n",
    "        self.hiddenLayerSize = hidden_layer\n",
    "        self.outputLayerSize = output_layer\n",
    "        self.learningRate = learning_rate\n",
    "        self.bias = bias       \n",
    "        self.initilize_weights()\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "    \n",
    "           \n",
    "    def initilize_weights(self):\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0 # default self.bias is true\n",
    "       \n",
    "        rangeW1 = 2 / np.sqrt(self.inputLayerSize+bias_node) #Get the range to be as defined above \n",
    "        distrubutionW1 = truncated_normal(mean=0,sd=1, low=-rangeW1, upp=rangeW1) # Create a normal distrubtion trunctaed within the range\n",
    "        self.W1 = distrubutionW1.rvs((self.inputLayerSize+bias_node,self.hiddenLayerSize,)) #Randomly distribute the normal distrubtion with correct dimensions \n",
    "        \n",
    "        rangeW2 = 1 / np.sqrt(self.hiddenLayerSize)\n",
    "        distrubutionW2 = truncated_normal(mean=0, sd=1, low=-rangeW2, upp=rangeW2)\n",
    "        self.W2 = distrubutionW2.rvs(( self.hiddenLayerSize+bias_node,self.outputLayerSize))\n",
    "    \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "   \n",
    "            x = np.array(x, ndmin=2) # every row is an input\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(x))\n",
    "                x = np.c_[x, biases]  ##adding bias to the input layer # bias is an extra one\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            self.z1 = np.dot(x, self.W1)\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(self.z1))\n",
    "                self.z1 = np.c_[self.z1, biases]  ##Adding the bias to the hidden layer\n",
    "\n",
    "            self.a1 = ReLU(self.z1) #Relu activation function\n",
    "\n",
    "\n",
    "            self.z2 = np.dot(self.a1, self.W2)\n",
    "            self.a2 = softmax(self.z2)\n",
    "\n",
    "            return self.a2\n",
    "        \n",
    "     \n",
    "    ##This is the implementatiion of the back-propogation\n",
    "    def backward(self, iput, output, target):\n",
    "        \n",
    "        #Calculate dcdw2 - how much the an arbritary change for each weiight in the W1 matrix affect the cost\n",
    "        #dcdy = self.MSE_prime(output, target) #partial derivative of error w.r.t. y hat (prediction)\n",
    "        #print(\"shape pof dcdy\", dcdy.shape)\n",
    "        #dyDz2 = sigmoid_derivative(self.z2) #Patial derivative of yhat with respect to z2,\n",
    "        #print(\"shape of dydz2\", dyDz2.shape)\n",
    "        #delta2 = dcdy * dyDz2\n",
    "        \n",
    "        #SOFTMAX - simple and elegant\n",
    "        delta2 = output - target\n",
    "        \n",
    "       # print(\"shape of delta 2\", delta2.shape)\n",
    "        \n",
    "        \n",
    "        dz2dw2 = self.a1.T # partial derivative of z2 with respect to weights\n",
    "        \n",
    "        dcdw2 = np.dot( dz2dw2, delta2) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "       # print(dcdw2.shape)\n",
    "      \n",
    "        ##Calculate dcdw1 - how much the an arbritary change for each weiight in the W2 matrix affect the cost\n",
    "        \n",
    "        dz2da1 =  self.W2.T  # Equals to the weight # Hidden errors\n",
    "       \n",
    "        dcda1 = np.dot(delta2, dz2da1 )\n",
    "        #print(\"shape\",dcda1.shape)\n",
    "        da1dz1 = ReLU_derivation(self.z1) #the derivative of the activation function for a1 - hidden layer\n",
    "      \n",
    "        \n",
    "        \n",
    "        delta1 = dcda1 * da1dz1\n",
    "        \n",
    "        iput = np.array(iput, ndmin=2) # every row is an input\n",
    "\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(iput))\n",
    "            iput = np.c_[iput, biases]  ##adding bias to the input layer\n",
    "            \n",
    "            \n",
    "        dz1dw1 = iput.T # The matrix product for input and weights - partial derivative of the product mutliplication w.r.t. the weights is simply the input then.\n",
    "       \n",
    "        dcdw1 = np.dot(dz1dw1, delta1)\n",
    "     \n",
    "        #print(dcdw1.shape)\n",
    "     \n",
    "        \n",
    "        return dcdw1, dcdw2\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def cross_entropy(self,output, target):\n",
    "        loss =  target * np.log(output)\n",
    "        return -np.sum(loss)\n",
    "    \n",
    "    \n",
    "    def train_single(self, training, target):\n",
    "        \n",
    "        network_output= self.feedForward(training)\n",
    "    \n",
    "        dcdw1, dcdw2 = self.backward(training, network_output,  target)\n",
    "    \n",
    "        ##Update weights\n",
    "        if self.bias:\n",
    "             self.W1 = self.W1 - (self.learningRate * dcdw1[:,:-1])\n",
    "        else:\n",
    "            self.W1 = self.W1 - (self.learningRate * dcdw1) \n",
    "        \n",
    "        self.W2 = self.W2 - (self.learningRate * dcdw2)\n",
    "        \n",
    "        return network_output, target\n",
    "    \n",
    "    \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              batch_size,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        \n",
    "        intermediate_weights = []\n",
    "        \n",
    "        \n",
    "        loss_list = []\n",
    "        iterations = []\n",
    "        accuracy_list = []\n",
    "                        \n",
    "        iteration_count = 1\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"Epoch {}\".format(str(epoch+1)), end=\"\")\n",
    "        \n",
    "            for iteration in np.arange(0,len(data_array+1), batch_size): #Move index a batch size for every run\n",
    "                #print(iteration)\n",
    "                start_index = iteration\n",
    "                end_index = iteration+batch_size-1\n",
    "               \n",
    "                features = data_array[start_index : end_index]\n",
    "                targets = labels_one_hot_array[start_index : end_index]\n",
    "                \n",
    "                self.train_single(features, targets) #Train the batch size\n",
    "                                \n",
    "               ##For intermediate evaluation\n",
    "                if ((iteration_count % 120 ) == 0 ): #We pick an iteration number to save the loss abnd accuracy\n",
    "                \n",
    "                    predicted = self.feedForward(X_training_scaled) # get network ouput\n",
    "                  \n",
    "                    \n",
    "                    predicted_encoded = [np.argmax(x) for x in predicted] \n",
    "                    loss = self.cross_entropy(predicted,y_training_one_hot) # Changed from MSE\n",
    "                    loss_list.append(loss)    \n",
    "                    #print(loss)\n",
    "                    acc = self.acc( y_training.flatten(), predicted_encoded)\n",
    "                    accuracy_list.append(acc)\n",
    "              \n",
    "                   \n",
    "                    \n",
    "                    np.set_printoptions(precision=2)\n",
    "                    print(\"Predicted\", predicted[:1])\n",
    "                    print(\"Iteration {0} -  loss: {1:.2f}, accuracy: {2:.2f}\".format(iteration_count, loss,acc, ))\n",
    "            \n",
    "\n",
    "                    iterations.append(iteration_count)                                \n",
    "                \n",
    "                iteration_count += 1\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.W1.copy(), \n",
    "                                                 self.W2.copy()))                \n",
    "            \n",
    "        return intermediate_weights, loss_list, accuracy_list,iterations\n",
    "\n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        cm = np.zeros((width, length))\n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        return cm\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer size : 1024\n",
      "\n",
      "Hidden layer size : 16\n",
      "\n",
      "Output layer size : 10\n",
      "\n",
      "Parameters to train in W1: 16400\n",
      "\n",
      "Parameters to train in W2: 170\n",
      "\n",
      "Total parameters:  16570\n"
     ]
    }
   ],
   "source": [
    "NN_softmax = NeuralNetwork_softmax(bias=True, input_layer=X_training_scaled.shape[1], hidden_layer=16, output_layer=10, learning_rate=0.001)\n",
    "NN_softmax.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'ReLU_derivation' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-64-07e1f388aec4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintermediate_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_softmax\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#NN.feedForward(X_training_scaled[0:10])\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-531f103defef>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_array, labels_one_hot_array, batch_size, epochs, intermediate_results)\u001b[0m\n\u001b[1;32m    179\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_one_hot_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    180\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 181\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Train the batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    182\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    183\u001b[0m                \u001b[0;31m##For intermediate evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-531f103defef>\u001b[0m in \u001b[0;36mtrain_single\u001b[0;34m(self, training, target)\u001b[0m\n\u001b[1;32m    141\u001b[0m         \u001b[0mnetwork_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 143\u001b[0;31m         \u001b[0mdcdw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcdw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    144\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    145\u001b[0m         \u001b[0;31m##Update weights\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-61-531f103defef>\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, iput, output, target)\u001b[0m\n\u001b[1;32m    101\u001b[0m         \u001b[0mdcda1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdelta2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdz2da1\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m         \u001b[0;31m#print(\"shape\",dcda1.shape)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0mda1dz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLU_derivation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz1\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#the derivative of the activation function for a1 - hidden layer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'ReLU_derivation' is not defined"
     ]
    }
   ],
   "source": [
    "\n",
    "intermediate_weights, loss_list, accuracy_list, iteration_list = NN_softmax.train(X_training_scaled, y_training_one_hot,batch_size=10, epochs=29, intermediate_results=True)\n",
    "\n",
    "#NN.feedForward(X_training_scaled[0:10])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Underflow and overflow of softmax\n",
    "The softmax function is producing 'nan' values after some training. It can happen when the softmax function is experiencing underflow or underflow. The function above could be unstable as we can get a NaN error in python due to oversize of the floating point. It is suggested to multiply both the denominator and the nominator with a constant $ C $ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    X = np.array(X)\n",
    "    biggest = X.max(axis=1)\n",
    "    #print(\"X\", X)\n",
    "    #print(\"Biggest\", biggest)\n",
    "    #print(X - biggest[:,np.newaxis])\n",
    "    temp = X - biggest[:,np.newaxis]\n",
    "    #print(np.exp(temp))\n",
    "    exps =np.exp(temp)\n",
    "    sumExps = np.sum(exps, axis=1)\n",
    "   # print(\"sum exps\", sumExps)\n",
    "    returnStatement = exps / sumExps[:,np.newaxis]\n",
    "    return(returnStatement)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "class NeuralNetwork_softmax_stabilized(object):\n",
    "    \n",
    "    def __init__(self, bias, input_layer, hidden_layer, output_layer, learning_rate):\n",
    "        self.inputLayerSize = input_layer\n",
    "        self.hiddenLayerSize = hidden_layer\n",
    "        self.outputLayerSize = output_layer\n",
    "        self.learningRate = learning_rate\n",
    "        self.bias = bias       \n",
    "        self.initilize_weights()\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "        print(\"Learning rate: \" + str( self.learningRate) +\"\\n\")\n",
    "    \n",
    "           \n",
    "    def initilize_weights(self):\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        \n",
    "        bias_node = 1 if self.bias else 0 # default self.bias is true\n",
    "       \n",
    "        rangeW1 = 2 / np.sqrt(self.inputLayerSize+bias_node) #Get the range to be as defined above \n",
    "        distrubutionW1 = truncated_normal(mean=0,sd=1, low=-rangeW1, upp=rangeW1) # Create a normal distrubtion trunctaed within the range\n",
    "        self.W1 = distrubutionW1.rvs((self.inputLayerSize+bias_node,self.hiddenLayerSize,)) #Randomly distribute the normal distrubtion with correct dimensions \n",
    "        \n",
    "        rangeW2 = 1 / np.sqrt(self.hiddenLayerSize)\n",
    "        distrubutionW2 = truncated_normal(mean=0, sd=1, low=-rangeW2, upp=rangeW2)\n",
    "        self.W2 = distrubutionW2.rvs(( self.hiddenLayerSize+bias_node,self.outputLayerSize))\n",
    "    \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "   \n",
    "            x = np.array(x, ndmin=2) # every row is an input\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(x))\n",
    "                x = np.c_[x, biases]  ##adding bias to the input layer # bias is an extra one\n",
    "\n",
    "    \n",
    "\n",
    "\n",
    "            self.z1 = np.dot(x, self.W1)\n",
    "\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(self.z1))\n",
    "                self.z1 = np.c_[self.z1, biases]  ##Adding the bias to the hidden layer\n",
    "\n",
    "            self.a1 = ReLU(self.z1) #Relu activation function\n",
    "\n",
    "\n",
    "            self.z2 = np.dot(self.a1, self.W2)\n",
    "            self.a2 = stable_softmax(self.z2)\n",
    "\n",
    "            return self.a2\n",
    "        \n",
    "     \n",
    "    ##This is the implementatiion of the back-propogation\n",
    "    def backward(self, iput, output, target):\n",
    "        \n",
    "        #Calculate dcdw2 - how much the an arbritary change for each weiight in the W1 matrix affect the cost\n",
    "        #dcdy = self.MSE_prime(output, target) #partial derivative of error w.r.t. y hat (prediction)\n",
    "        #print(\"shape pof dcdy\", dcdy.shape)\n",
    "        #dyDz2 = sigmoid_derivative(self.z2) #Patial derivative of yhat with respect to z2,\n",
    "        #print(\"shape of dydz2\", dyDz2.shape)\n",
    "        #delta2 = dcdy * dyDz2\n",
    "        \n",
    "        #SOFTMAX - simple and elegant\n",
    "        delta2 = output - target\n",
    "        \n",
    "       # print(\"shape of delta 2\", delta2.shape)\n",
    "        \n",
    "        \n",
    "        dz2dw2 = self.a1.T # partial derivative of z2 with respect to weights\n",
    "        \n",
    "        dcdw2 = np.dot( dz2dw2, delta2) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "       # print(dcdw2.shape)\n",
    "      \n",
    "        ##Calculate dcdw1 - how much the an arbritary change for each weiight in the W2 matrix affect the cost\n",
    "        \n",
    "        dz2da1 =  self.W2.T  # Equals to the weight # Hidden errors\n",
    "       \n",
    "        dcda1 = np.dot(delta2, dz2da1 )\n",
    "        #print(\"shape\",dcda1.shape)\n",
    "        da1dz1 = ReLU_derivation(self.z1) #the derivative of the activation function for a1 - hidden layer\n",
    "      \n",
    "        \n",
    "        \n",
    "        delta1 = dcda1 * da1dz1\n",
    "        \n",
    "        iput = np.array(iput, ndmin=2) # every row is an input\n",
    "\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(iput))\n",
    "            iput = np.c_[iput, biases]  ##adding bias to the input layer\n",
    "            \n",
    "            \n",
    "        dz1dw1 = iput.T # The matrix product for input and weights - partial derivative of the product mutliplication w.r.t. the weights is simply the input then.\n",
    "       \n",
    "        dcdw1 = np.dot(dz1dw1, delta1)\n",
    "     \n",
    "        #print(dcdw1.shape)\n",
    "     \n",
    "        \n",
    "        return dcdw1, dcdw2\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def cross_entropy(self,output, target):\n",
    "        loss =  target * np.log(output)\n",
    "        return -np.sum(loss)\n",
    "    \n",
    "    \n",
    "    def train_single(self, training, target):\n",
    "        \n",
    "        network_output= self.feedForward(training)\n",
    "    \n",
    "        dcdw1, dcdw2 = self.backward(training, network_output,  target)\n",
    "    \n",
    "        ##Update weights\n",
    "        if self.bias:\n",
    "             self.W1 = self.W1 - (self.learningRate * dcdw1[:,:-1])\n",
    "        else:\n",
    "            self.W1 = self.W1 - (self.learningRate * dcdw1) \n",
    "        \n",
    "        self.W2 = self.W2 - (self.learningRate * dcdw2)\n",
    "        \n",
    "        return network_output, target\n",
    "    \n",
    "    \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              batch_size,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        \n",
    "        intermediate_weights = []\n",
    "        \n",
    "        \n",
    "        loss_list = []\n",
    "        iterations = []\n",
    "        accuracy_list = []\n",
    "                        \n",
    "        iteration_count = 1\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"Epoch {}\".format(str(epoch+1)), end=\"\")\n",
    "        \n",
    "            for iteration in np.arange(0,len(data_array+1), batch_size): #Move index a batch size for every run\n",
    "                #print(iteration)\n",
    "                start_index = iteration\n",
    "                end_index = iteration+batch_size-1\n",
    "               \n",
    "                features = data_array[start_index : end_index]\n",
    "                targets = labels_one_hot_array[start_index : end_index]\n",
    "                \n",
    "                self.train_single(features, targets) #Train the batch size\n",
    "                                \n",
    "               ##For intermediate evaluation\n",
    "                if ((iteration_count % 120 ) == 0 ): #We pick an iteration number to save the loss abnd accuracy\n",
    "                \n",
    "                    predicted = self.feedForward(X_training_scaled) # get network ouput\n",
    "                  \n",
    "                    \n",
    "                    predicted_encoded = [np.argmax(x) for x in predicted] \n",
    "                    loss = self.cross_entropy(predicted,y_training_one_hot_unscaled) # Changed from MSE\n",
    "                    #loss = self.MSE(predicted_encoded, y_training.flatten())\n",
    "                    loss_list.append(loss)    \n",
    "                    #print(loss)\n",
    "                    acc = self.acc( y_training.flatten(), predicted_encoded)\n",
    "                    accuracy_list.append(acc)\n",
    "              \n",
    "                   \n",
    "                    \n",
    "                    np.set_printoptions(precision=2)\n",
    "                    print(\"Predicted\", predicted[:1])\n",
    "                    print(\"Iteration {0} -  loss: {1:.2f}, accuracy: {2:.2f}\".format(iteration_count, loss,acc, ))\n",
    "            \n",
    "\n",
    "                    iterations.append(iteration_count)                                \n",
    "                \n",
    "                iteration_count += 1\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append((self.W1.copy(), \n",
    "                                                 self.W2.copy()))                \n",
    "            \n",
    "        return intermediate_weights, loss_list, accuracy_list,iterations\n",
    "\n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        cm = np.zeros((width, length))\n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        return cm7\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input layer size : 1024\n",
      "\n",
      "Hidden layer size : 16\n",
      "\n",
      "Output layer size : 10\n",
      "\n",
      "Parameters to train in W1: 16400\n",
      "\n",
      "Parameters to train in W2: 170\n",
      "\n",
      "Total parameters:  16570\n",
      "Learning rate: 0.02\n",
      "\n"
     ]
    }
   ],
   "source": [
    "NN_softmax_stable = NeuralNetwork_softmax_stabilized(bias=True, input_layer=X_training_scaled.shape[1], hidden_layer=16, output_layer=10, learning_rate=0.02)\n",
    "NN_softmax_stable.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "crossEnttropyu 176460.1303568979\n"
     ]
    }
   ],
   "source": [
    "output = NN_softmax_stable.feedForward(X_training_scaled)\n",
    "cross_entropy = NN_softmax_stable.cross_entropy(output, y_training_one_hot_unscaled)\n",
    "\n",
    "#print(\"Sum of 1 row\", np.sum(output, axis=1))\n",
    "print(\"crossEnttropyu\", cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1Predicted [[0.17 0.11 0.1  0.09 0.1  0.08 0.08 0.09 0.09 0.09]]\n",
      "Iteration 120 -  loss: 165296.04, accuracy: 0.19\n",
      "Predicted [[0.21 0.12 0.12 0.1  0.09 0.07 0.07 0.08 0.07 0.08]]\n",
      "Iteration 240 -  loss: 164371.32, accuracy: 0.19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-c3acda486eda>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mintermediate_weights\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maccuracy_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miteration_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mNN_softmax_stable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training_one_hot_unscaled\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m29\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-32-96a08939ccdf>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_array, labels_one_hot_array, batch_size, epochs, intermediate_results)\u001b[0m\n\u001b[1;32m    188\u001b[0m                 \u001b[0mtargets\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlabels_one_hot_array\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mstart_index\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mend_index\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    189\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 190\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfeatures\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtargets\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#Train the batch size\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    191\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    192\u001b[0m                \u001b[0;31m##For intermediate evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-96a08939ccdf>\u001b[0m in \u001b[0;36mtrain_single\u001b[0;34m(self, training, target)\u001b[0m\n\u001b[1;32m    148\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mtrain_single\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    149\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 150\u001b[0;31m         \u001b[0mnetwork_output\u001b[0m\u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    151\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    152\u001b[0m         \u001b[0mdcdw1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdcdw2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnetwork_output\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mtarget\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-32-96a08939ccdf>\u001b[0m in \u001b[0;36mfeedForward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mz1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "intermediate_weights, loss_list, accuracy_list, iteration_list = NN_softmax_stable.train(X_training_scaled, y_training_one_hot_unscaled,batch_size=5, epochs=29, intermediate_results=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save the softmax+cross entropy model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'NN_softmax_stable' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-40337539bdc7>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mpickle\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NN_softmax_W1.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bw\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mNN_softmax_stable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mW1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mpickle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdump\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mwith\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\".\"\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\"NN_softmax_W2.pkl\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"bw\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfh\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'NN_softmax_stable' is not defined"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pickle\n",
    "with open(os.path.join(\".\",\"NN_softmax_W1.pkl\"), \"bw\") as fh:\n",
    "    data = (NN_softmax_stable.W1)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"NN_softmax_W2.pkl\"), \"bw\") as fh:\n",
    "    data = (NN_softmax_stable.W2)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"NN_softmax_network.pkl\"), \"bw\") as fh:\n",
    "    data = (loss_list)\n",
    "    pickle.dump(data, fh)\n",
    "with open(os.path.join(\".\",\"acc-NN_softmax.pkl\"), \"bw\") as fh:\n",
    "    data = (accuracy_list)\n",
    "    pickle.dump(data, fh)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate the softmax + Cross Entropy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "************\n",
    "\n",
    "## Task 4: implementing fully connected NN\n",
    "\n",
    "We will implement a Neural Network with multiple hidden layers, that can be specified at initlization\n",
    "\n",
    "## Multiple hidden layers\n",
    "\n",
    "We define a new parameter called network structure where we specify amount of layers and nodes. We have to redefine the:\n",
    "\n",
    "        1. weight initilization, \n",
    "        2. feed forward\n",
    "        3. backpropogation. \n",
    "        \n",
    "We specify the 'network structure' parameter as a list with the form  **[input_nodes, hidden1_nodes, ... , hidden_n_nodes, output_nodes]**\n",
    "\n",
    "\n",
    "### Weight initlization\n",
    "We loop over the amount of layer and put the corresponding weight vectors inside a weight matrix. We also change the weight shape to be more intutive. The shape will be (out_nodes, in_nodes + bias). That means that each row is the input neurons corresponding weight. When we take the dot product of the transpose of the weight matrix with the input we get the each get the weighted sum of all input neurons with their corresponding weights. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NeuralNetwork_weights(object):\n",
    "    def __init__(self, network_structure):\n",
    "        self.structure = network_structure\n",
    "        self.initilize_weights()\n",
    "        \n",
    "    \n",
    "    def initilize_weights(self):\n",
    "        bias_node = 1 \n",
    "        self.weights_matrices = []\n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        \n",
    "        while layer_index < no_of_layers:\n",
    "          \n",
    "\n",
    "            nodes_in = self.structure[layer_index-1] # get layer 0 first run and then incremented\n",
    "            nodes_out = self.structure[layer_index] # Gets the next layer\n",
    "            \n",
    "            rangeWeightLayer =  1 / np.sqrt(nodes_in)\n",
    "            distrubutionWeightLayer = truncated_normal(mean=2, sd=1, low=-rangeWeightLayer, upp=rangeWeightLayer)\n",
    "            weightLayer = distrubutionWeightLayer.rvs(( nodes_out, nodes_in + bias_node))\n",
    "            self.weights_matrices.append(weightLayer)\n",
    "            layer_index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Network structure =  [24, 16, 16, 4]\n",
      "Shape of W1 =  (16, 25)\n",
      "Shape of W2 =  (16, 17)\n",
      "Shape of W3 =  (4, 17)\n"
     ]
    }
   ],
   "source": [
    "test_weights_nn = NeuralNetwork_weights(network_structure=[24,16,16,4])\n",
    "\n",
    "print(\"Network structure = \", test_weights_nn.structure)\n",
    "print(\"Shape of W1 = \", test_weights_nn.weights_matrices[0].shape)\n",
    "print(\"Shape of W2 = \", test_weights_nn.weights_matrices[1].shape)\n",
    "print(\"Shape of W3 = \", test_weights_nn.weights_matrices[2].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Each weight layer has one extra row for the bias.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed forward"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NN_test_feed_forward(object):\n",
    "    def __init__(self, bias, network_structure):\n",
    "        self.structure = network_structure\n",
    "        self.bias = bias\n",
    "        self.initilize_weights()\n",
    "        \n",
    "    \n",
    "    def initilize_weights(self):\n",
    "        bias_node = 1 \n",
    "        self.weights_matrices = []\n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        \n",
    "        while layer_index < no_of_layers:\n",
    "          \n",
    "\n",
    "            nodes_in = self.structure[layer_index-1] # get layer 0 first run and then incremented\n",
    "            nodes_out = self.structure[layer_index] # Gets the next layer\n",
    "            \n",
    "            rangeWeightLayer =  1 / np.sqrt(nodes_in)\n",
    "            distrubutionWeightLayer = truncated_normal(mean=2, sd=1, low=-rangeWeightLayer, upp=rangeWeightLayer)\n",
    "            weightLayer = distrubutionWeightLayer.rvs((nodes_in + bias_node, nodes_out))\n",
    "            self.weights_matrices.append(weightLayer)\n",
    "            layer_index += 1\n",
    "\n",
    "\n",
    "    def feedForward(self, x):       \n",
    "\n",
    "            no_of_layers = len(self.structure)\n",
    "            x = np.array(x, ndmin=2) # every row is an input\n",
    "            \n",
    "            if self.bias:\n",
    "                biases = np.ones(len(x))\n",
    "                x = np.c_[x, biases]  ##adding bias to the input layer\n",
    "\n",
    "\n",
    "            layer_index = 1\n",
    "            # The input vectors to the various layers\n",
    "\n",
    "            in_vector = x\n",
    "\n",
    "            while layer_index < no_of_layers-1:\n",
    "\n",
    "                z = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "\n",
    "                a = ReLU(z) #sigmoid activation function\n",
    "\n",
    "\n",
    "                in_vector = a\n",
    "                #input vector for next layer\n",
    "                if self.bias:\n",
    "                    biases = np.ones(len(in_vector))\n",
    "                    in_vector = np.c_[in_vector, biases]  ##Adding the bias to the hidden layer\n",
    "\n",
    "                layer_index += 1\n",
    "\n",
    "            #Last layer softmax or sigmoid\n",
    "            lastZ = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "            output_network = sigmoid(lastZ)\n",
    "\n",
    "\n",
    "            return output_network\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.53, 0.58, 0.43, 0.59, 0.66, 0.66, 0.55, 0.61, 0.6 , 0.62],\n",
       "       [0.56, 0.59, 0.41, 0.6 , 0.64, 0.7 , 0.59, 0.61, 0.63, 0.63],\n",
       "       [0.57, 0.59, 0.4 , 0.63, 0.68, 0.7 , 0.58, 0.62, 0.64, 0.59],\n",
       "       [0.55, 0.58, 0.41, 0.61, 0.66, 0.68, 0.56, 0.61, 0.62, 0.61]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "NN_test_feed = NN_test_feed_forward(bias=True,  network_structure=[1024, 16,3,10])\n",
    "\n",
    "NN_test_feed.feedForward(X_training_scaled[1:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backpropogation\n",
    "We have caluculated the gradient for the hidden layer step by step. If we want to add more hidden layers in intilization we need to make a procedure for calculating the gradients for the hidden layers. We will construct a general computation for each layer from the chain rule:\n",
    "\n",
    "$$\\frac {\\partial p(a)} {\\partial a} = \\sum \\frac {\\partial p(a)}{\\partial q_i (a)}\\frac {\\partial q_i (a)}{\\partial (a)}$$\n",
    "\n",
    "\n",
    "$a$ = unit layer\n",
    "$q_i$ = pre activation in the layer above\n",
    "$p(a)$ = loss function\n",
    "\n",
    "\n",
    "\n",
    "The last weight matrix is going to be the same but we are increasing the hidden weight matrices. The backpropogation for the hidden layers can be generlized with the function:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We perform a feedforward in the backward function where we save the intermediate output from each layer: in the loop we perform three operations\n",
    " \n",
    "     1. ass bias to input vector, often denoted  a\n",
    "     2. weighted sum often denoted z\n",
    "     3. The activation of the weighted sum (next layer input). often denoted a+1\n",
    "     \n",
    "When we take the derivative to the hidden weights from the hidden layers there is a slightly different computation as described in earlier sections. We take the derivative across our synapses. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    X = np.array(X)\n",
    "    biggest = X.max(axis=1)\n",
    "    #print(\"X\", X)\n",
    "    #print(\"Biggest\", biggest)\n",
    "    #print(X - biggest[:,np.newaxis])\n",
    "    temp = X - biggest[:,np.newaxis]\n",
    "    #print(np.exp(temp))\n",
    "    exps =np.exp(temp)\n",
    "    sumExps = np.sum(exps, axis=1)\n",
    "   # print(\"sum exps\", sumExps)\n",
    "    returnStatement = exps / sumExps[:,np.newaxis]\n",
    "    return(returnStatement)\n",
    "\n",
    "\n",
    "class full_connected_NN(object):\n",
    "    \n",
    "    def __init__(self, bias, network_structure, learning_rate):\n",
    "        self.structure = network_structure\n",
    "        self.learningRate = learning_rate\n",
    "        self.bias = bias       \n",
    "        self.initilize_weights()\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "        print(\"Learning rate: \" + str( self.learningRate) +\"\\n\")\n",
    "    \n",
    "           \n",
    "    def initilize_weights(self):\n",
    "        print(\"inside init weghts\")\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []\n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        \n",
    "        while layer_index < no_of_layers:\n",
    "            print(\"inside init weghts\")\n",
    "\n",
    "            nodes_in = self.structure[layer_index-1] # get layer 0 first run and then incremented\n",
    "            nodes_out = self.structure[layer_index] # Gets the next layer\n",
    "            \n",
    "            rangeWeightLayer =  1 / np.sqrt(nodes_in)\n",
    "            distrubutionWeightLayer = truncated_normal(mean=2, sd=1, low=-rangeWeightLayer, upp=rangeWeightLayer)\n",
    "            weightLayer = distrubutionWeightLayer.rvs(( nodes_in + bias_node, nodes_out))\n",
    "            self.weights_matrices.append(weightLayer)\n",
    "            layer_index += 1\n",
    "            \n",
    "            \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "        no_of_layers = len(self.structure)\n",
    "        x = np.array(x, ndmin=2) # every row is an input\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(x))\n",
    "            x = np.c_[x, biases]  ##adding bias to the input layer\n",
    "        \n",
    "        \n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        \n",
    "        in_vector = x\n",
    "        \n",
    "        while layer_index < no_of_layers-1:\n",
    "            \n",
    "            \n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "    \n",
    "            a = ReLU(z) #sigmoid activation function\n",
    "            \n",
    "            in_vector = a\n",
    "            #input vector for next layer\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(in_vector))\n",
    "                in_vector = np.c_[in_vector, biases]  ##Adding the bias to the hidden layer\n",
    "            \n",
    "            layer_index += 1\n",
    "            \n",
    "        #Last layer softmax or sigmoid\n",
    "        lastZ = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "        output_network = stable_softmax(lastZ)\n",
    "        \n",
    "        \n",
    "        return output_network\n",
    "        \n",
    "     \n",
    "    def backward(self, iput, target):\n",
    "        \n",
    "        ##################GET the output and input vectors for the feedforward###########\n",
    "    \n",
    "        no_of_layers = len(self.structure)        \n",
    "        input_vector = np.array(iput, ndmin=2)\n",
    "        layer_index = 0\n",
    "        # The output/input vectors of the hidden layers layers:\n",
    "       \n",
    "        res_vectors = [input_vector]          \n",
    "        while layer_index < no_of_layers - 1: #\n",
    "            in_vector = res_vectors[-1] # Get the output from last layer\n",
    "           \n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                \n",
    "                biases = np.ones((len(in_vector),1))\n",
    "                in_vector = np.concatenate((in_vector, biases), axis=1) ##adding bias to the input layer for every layer\n",
    "             \n",
    "          \n",
    "            res_vectors[-1] = in_vector # Save the input vector with added bias\n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index]) # The weighted sum  - often denoted z\n",
    "            res_vectors.append(z)\n",
    "            if(layer_index == no_of_layers-2):\n",
    "                out_vector = stable_softmax(z)\n",
    "                \n",
    "               \n",
    "            else:\n",
    "                out_vector = ReLU(z)\n",
    "            res_vectors.append(out_vector)   \n",
    "            layer_index += 1\n",
    "        \n",
    "    \n",
    "        #############  LAST LAYER WEIGHTS UPDATE ########################\n",
    "        weight_gradients = []\n",
    "          \n",
    "        deltaLast = res_vectors[-1] - target ##Sofmax impementation\n",
    "       \n",
    "        dz2dw2 = res_vectors[-3].T # partial derivative of z2 with respect to weights\n",
    "\n",
    "        #### UPDATE WEIGHTS OF LAST LAYER\n",
    "        dcdw2 = np.dot( dz2dw2, deltaLast) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "        weight_gradients.append(dcdw2) # Transpose so each row is the the weight from each node, not each column\n",
    "        \n",
    "    \n",
    "        \n",
    "       ####HIDDEN LAYERS\n",
    "        \n",
    "        index_vecor = len(res_vectors) - 4\n",
    "        \n",
    "        layer_index = no_of_layers - 1\n",
    "       \n",
    "        while layer_index > 1:\n",
    "            dzda = self.weights_matrices[layer_index-1].T #Weight between layers\n",
    "            dcda = np.dot(deltaLast, dzda)\n",
    "            dadz = ReLU_derivation(res_vectors[index_vecor])\n",
    "            delta = dcda[:,:-1] * dadz #Take away bias as input to get delta\n",
    "            deltaLast = delta\n",
    "            dcdw = np.dot(res_vectors[index_vecor-1].T,delta)\n",
    "            weight_gradients.append(dcdw)            \n",
    "            layer_index -= 1\n",
    "            index_vecor -= 2\n",
    "            \n",
    "        \n",
    "        return weight_gradients\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def cross_entropy(self,output, target):\n",
    "        loss =  target * np.log(output)\n",
    "        return -np.sum(loss)\n",
    "    \n",
    "    \n",
    "    def train_single(self, training, target):\n",
    "        \n",
    "        gradients = self.backward(training, target)\n",
    "       \n",
    "        weight_index = len(self.weights_matrices) -1\n",
    "        for i in range(len(gradients)):\n",
    "            self.weights_matrices[weight_index] = self.weights_matrices[weight_index] - (self.learningRate * gradients[i])\n",
    "            weight_index -= 1\n",
    "    \n",
    "    \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              batch_size,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        \n",
    "        intermediate_weights = []\n",
    "        \n",
    "        \n",
    "        loss_list = []\n",
    "        iterations = []\n",
    "        accuracy_list = []\n",
    "                        \n",
    "        iteration_count = 1\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"Epoch {}\".format(str(epoch+1)), end=\"\")\n",
    "        \n",
    "            for iteration in np.arange(0,len(data_array+1), batch_size): #Move index a batch size for every run\n",
    "                #print(iteration)\n",
    "                start_index = iteration\n",
    "                end_index = iteration+batch_size-1\n",
    "               \n",
    "                features = data_array[start_index : end_index]\n",
    "                targets = labels_one_hot_array[start_index : end_index]\n",
    "                \n",
    "                self.train_single(features, targets) #Train the batch size\n",
    "                                \n",
    "               ##For intermediate evaluation\n",
    "                if ((iteration_count % 120 ) == 0 ): #We pick an iteration number to save the loss abnd accuracy\n",
    "                \n",
    "                    predicted = self.feedForward(X_training_scaled) # get network ouput\n",
    "                  \n",
    "                    \n",
    "                    predicted_encoded = [np.argmax(x) for x in predicted] \n",
    "                    loss = self.cross_entropy(predicted,y_training_one_hot_unscaled) # Changed from MSE\n",
    "                    #loss = self.MSE(predicted_encoded, y_training.flatten())\n",
    "                    loss_list.append(loss)    \n",
    "                    #print(loss)\n",
    "                    acc = self.acc( y_training.flatten(), predicted_encoded)\n",
    "                    accuracy_list.append(acc)\n",
    "              \n",
    "                   \n",
    "                    \n",
    "                    np.set_printoptions(precision=2)\n",
    "                    print(\"Predicted\", predicted[:1])\n",
    "                    print(\"Iteration {0} -  loss: {1:.2f}, accuracy: {2:.2f}\".format(iteration_count, loss,acc, ))\n",
    "            \n",
    "\n",
    "                    iterations.append(iteration_count)                                \n",
    "                \n",
    "                iteration_count += 1\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append(self.weights_matrices)                \n",
    "            \n",
    "        return intermediate_weights, loss_list, accuracy_list,iterations\n",
    "\n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        cm = np.zeros((width, length))\n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        return cm7\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameters used\n",
    "learning rate = 0.2\n",
    "network structur = 1024, 16 , 16, 10\n",
    "update rule = \n",
    "epochs = 29\n",
    "batch size = 50\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "full_connected_NN = full_connected_NN(bias=True,  network_structure=[1024,16,16,16, 10], learning_rate=0.0002)\n",
    "full_connected_NN.train(X_training_scaled, y_training_one_hot,batch_size=300, epochs=300, intermediate_results=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task 2: Regularization\n",
    "\n",
    "## Dropout\n",
    "\n",
    "Dropout is usually implemented to prevent overfitting, as our model has not overfitted yet it might not be needed yet. However, it is a good idea to implement to use it.\n",
    "\n",
    "We set a random probabillity for each node if it should be passed. \n",
    "\n",
    "We create a dropout vector we call $d^{layer}$,(with the same shape as the corresponding layer) which we will initlize with random numbers. We will then compare the values of the layer to a choosen number to determine if the node should be droped or not.\n",
    "\n",
    "$$d^3 = np.random.rand(a^3.shape[0], a^3.shape[1] ) < keepProb$$\n",
    "\n",
    "If we set keepProb to 0.8, it will dropout 20% on average of the layer as random.rand is generating random numbers between 0 and 1.\n",
    "\n",
    "\n",
    "For each activation layer we take\n",
    "\n",
    "$$a_i = np.multiply(a_i,d_i)$$\n",
    "\n",
    "\n",
    "#### Inverted dropout\n",
    "\n",
    "We will use inverted dropout which is the most common one. It is based upon scaling up the reamining nodes.\n",
    "\n",
    "As the final step we will scale the remaining nodes by dividing it with the keepProb scalar we have choosen. We do so because we do not want to change the expexted value of the activation.\n",
    "\n",
    "$$a_i = \\frac {a_i} { keepProb}$$\n",
    "\n",
    "\n",
    "***We will only implement the forward pass in the backward (which is using for training) as the reason for inverted dropout scale is to account for all active nodes in the testing.***\n",
    "\n",
    "We define a function in the Neural Network class called reset_weights, which we can call in the training.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    X = np.array(X)\n",
    "    biggest = X.max(axis=1)\n",
    "    #print(\"X\", X)\n",
    "    #print(\"Biggest\", biggest)\n",
    "    #print(X - biggest[:,np.newaxis])\n",
    "    temp = X - biggest[:,np.newaxis]\n",
    "    #print(np.exp(temp))\n",
    "    exps =np.exp(temp)\n",
    "    sumExps = np.sum(exps, axis=1)\n",
    "   # print(\"sum exps\", sumExps)\n",
    "    returnStatement = exps / sumExps[:,np.newaxis]\n",
    "    return(returnStatement)\n",
    "\n",
    "import random\n",
    "\n",
    "class full_connected_NN_dropout(object):\n",
    "    \n",
    "    def __init__(self, bias, network_structure, learning_rate, dropout_in_pecentage=0.9, dropout_hidden=True,dropout_in=True, dropout_hidden_percentage=0.9):\n",
    "        self.structure = network_structure\n",
    "        self.dropout_in = dropout_in\n",
    "        self.dropout_hidden = dropout_hidden\n",
    "        self.dropout_percentage_in = dropout_in_pecentage\n",
    "        self.dropout_percentage_hidden = dropout_hidden_percentage\n",
    "        self.learningRate = learning_rate\n",
    "        self.bias = bias       \n",
    "        self.initilize_weights()\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "        print(\"Learning rate: \" + str( self.learningRate) +\"\\n\")\n",
    "    \n",
    "           \n",
    "    def initilize_weights(self):\n",
    "        print(\"inside init weghts\")\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []\n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        \n",
    "        while layer_index < no_of_layers:\n",
    "            print(\"inside init weghts\")\n",
    "\n",
    "            nodes_in = self.structure[layer_index-1] # get layer 0 first run and then incremented\n",
    "            nodes_out = self.structure[layer_index] # Gets the next layer\n",
    "            \n",
    "            rangeWeightLayer =  1 / np.sqrt(nodes_in)\n",
    "            distrubutionWeightLayer = truncated_normal(mean=2, sd=1, low=-rangeWeightLayer, upp=rangeWeightLayer)\n",
    "            weightLayer = distrubutionWeightLayer.rvs(( nodes_in + bias_node, nodes_out))\n",
    "            self.weights_matrices.append(weightLayer)\n",
    "            layer_index += 1\n",
    "            \n",
    "            \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "        no_of_layers = len(self.structure)\n",
    "        x = np.array(x, ndmin=2) # every row is an input\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(x))\n",
    "            x = np.c_[x, biases]  ##adding bias to the input layer\n",
    "        \n",
    "        \n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        \n",
    "        in_vector = x\n",
    "        \n",
    "        while layer_index < no_of_layers-1:\n",
    "            \n",
    "            \n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "    \n",
    "            a = ReLU(z) #sigmoid activation function\n",
    "            \n",
    "            in_vector = a\n",
    "            #input vector for next layer\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(in_vector))\n",
    "                in_vector = np.c_[in_vector, biases]  ##Adding the bias to the hidden layer\n",
    "            \n",
    "            layer_index += 1\n",
    "            \n",
    "        #Last layer softmax or sigmoid\n",
    "        lastZ = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "        output_network = stable_softmax(lastZ)\n",
    "        \n",
    "        \n",
    "        return output_network\n",
    "    \n",
    "    \n",
    "    \n",
    "    def dropout(self):\n",
    "        ##Steps\n",
    "        weight_matrix = np.array(self.weights_matrices.copy())\n",
    "        dropout_prob_in = self.dropout_percentage_in\n",
    "        dropout_prop_hidden = self.dropout_percentage_hidden\n",
    "        #1 copy the weights to a self.weights_original\n",
    "        self.weights_matrices_original =weight_matrix\n",
    "        #2. calculate the active nodes indices\n",
    "        inputShape = []\n",
    "        for x in np.arange(len(weight_matrix)):\n",
    "            inputShape.append(weight_matrix[x].shape[0])\n",
    "        #3. calcualte the indices for the nodes\n",
    "        \n",
    "        \n",
    "        inputShape = np.array(inputShape)\n",
    "        active_nodes = inputShape * dropout_prob_in # to round to decimla active nodes in first layer\n",
    "        active_nodes = [int(x) for x in active_nodes]\n",
    "        #4. Pick what nodes to drop\n",
    "        dropoutIndices = []\n",
    "        for x in range(len(inputShape)):\n",
    "            indices  = sorted(random.sample(range(0, inputShape[x]), active_nodes[x]))\n",
    "            dropoutIndices.append(indices)\n",
    "        \n",
    "        return dropoutIndices\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "    def resetWeights(self):\n",
    "        self.weights_matrices = self.weights_matrices_original.copy()\n",
    "            \n",
    "        \n",
    "     \n",
    "    def backward(self, iput, target):\n",
    "        \n",
    "        ##################GET the output and input vectors for the feedforward###########\n",
    "        \n",
    "        ####DROPOUT NEW##################\n",
    "        \n",
    "        dropoutIndices = self.dropout()\n",
    "        self.dropoutIndices = dropoutIndices.copy()\n",
    "\n",
    "        \n",
    "        ##dropout from first layer\n",
    "        weights = self.weights_matrices[0].copy()\n",
    "        new_weights_in = weights[dropoutIndices[0], :]\n",
    "        \n",
    "        if self.dropout_in:\n",
    "            self.weights_matrices[0] = new_weights_in\n",
    "        \n",
    "        #############\n",
    "        \n",
    "        \n",
    "        \n",
    "    \n",
    "        no_of_layers = len(self.structure)        \n",
    "        input_vector = np.array(iput, ndmin=2)\n",
    "        layer_index = 0\n",
    "        # The output/input vectors of the hidden layers layers:\n",
    "       \n",
    "        res_vectors = [input_vector]          \n",
    "        while layer_index < no_of_layers - 1: #\n",
    "            in_vector = res_vectors[-1] # Get the output from last layer\n",
    "           \n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                \n",
    "                biases = np.ones((len(in_vector),1))\n",
    "                in_vector = np.concatenate((in_vector, biases), axis=1) ##adding bias to the input layer for every layer\n",
    "                if self.dropout_in and layer_index == 0: ##For first layer dropout\n",
    "                    \n",
    "                    in_vector = in_vector[:,dropoutIndices[0]]\n",
    "                    in_vector = in_vector / self.dropout_percentage_in ##Rescale as the inverted dropout says\n",
    "                                 \n",
    "            \n",
    "            res_vectors[-1] = in_vector # Save the input vector with added bias\n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index]) # The weighted sum  - often denoted z\n",
    "            res_vectors.append(z)\n",
    "            if(layer_index == no_of_layers-2):\n",
    "                out_vector = stable_softmax(z)\n",
    "                \n",
    "               \n",
    "            else:\n",
    "                out_vector = ReLU(z)\n",
    "            res_vectors.append(out_vector)   \n",
    "            layer_index += 1\n",
    "        \n",
    "    \n",
    "        #############  LAST LAYER WEIGHTS UPDATE ########################\n",
    "        weight_gradients = []\n",
    "          \n",
    "        deltaLast = res_vectors[-1] - target ##Sofmax impementation\n",
    "       \n",
    "        dz2dw2 = res_vectors[-3].T # partial derivative of z2 with respect to weights\n",
    "\n",
    "        #### UPDATE WEIGHTS OF LAST LAYER\n",
    "        dcdw2 = np.dot( dz2dw2, deltaLast) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "        weight_gradients.append(dcdw2) # Transpose so each row is the the weight from each node, not each column\n",
    "        \n",
    "    \n",
    "        \n",
    "       ####HIDDEN LAYERS\n",
    "        \n",
    "        index_vecor = len(res_vectors) - 4\n",
    "        \n",
    "        layer_index = no_of_layers - 1\n",
    "       \n",
    "        while layer_index > 1:\n",
    "            dzda = self.weights_matrices[layer_index-1].T #Weight between layers\n",
    "            dcda = np.dot(deltaLast, dzda)\n",
    "            dadz = ReLU_derivation(res_vectors[index_vecor])\n",
    "            delta = dcda[:,:-1] * dadz #Take away bias as input to get delta\n",
    "            deltaLast = delta\n",
    "            dcdw = np.dot(res_vectors[index_vecor-1].T,delta)\n",
    "            weight_gradients.append(dcdw)            \n",
    "            layer_index -= 1\n",
    "            index_vecor -= 2\n",
    "            \n",
    "     \n",
    "        return weight_gradients\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def cross_entropy(self,output, target):\n",
    "        loss =  target * np.log(output)\n",
    "        return -np.sum(loss)\n",
    "    \n",
    "    \n",
    "    def train_single(self, training, target):\n",
    "        \n",
    "        gradients = self.backward(training, target)\n",
    "        dropped = [x for x in range(len(self.weights_matrices_original[0])) if x not in self.dropoutIndices[0]]\n",
    "      \n",
    "       \n",
    "        weight_index = len(self.weights_matrices) -1\n",
    "        for i in range(len(gradients)):\n",
    "            self.weights_matrices[weight_index] = self.weights_matrices[weight_index] - (self.learningRate * gradients[i])\n",
    "            weight_index -= 1\n",
    "            \n",
    "        if self.dropout_in:\n",
    "            self.weights_matrices_original[0][self.dropoutIndices[0], :] = self.weights_matrices[0]\n",
    "            self.weights_matrices[0] = self.weights_matrices_original[0]  \n",
    "    \n",
    "    \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              batch_size,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        \n",
    "        intermediate_weights = []\n",
    "        \n",
    "        \n",
    "        loss_list = []\n",
    "        iterations = []\n",
    "        accuracy_list = []\n",
    "                        \n",
    "        iteration_count = 1\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"Epoch {}\".format(str(epoch+1)), end=\"\")\n",
    "        \n",
    "            for iteration in np.arange(0,len(data_array+1), batch_size): #Move index a batch size for every run\n",
    "                #print(iteration)\n",
    "                start_index = iteration\n",
    "                end_index = iteration+batch_size-1\n",
    "               \n",
    "                features = data_array[start_index : end_index]\n",
    "                targets = labels_one_hot_array[start_index : end_index]\n",
    "                \n",
    "                self.train_single(features, targets) #Train the batch size\n",
    "                                \n",
    "               ##For intermediate evaluation\n",
    "                if ((iteration_count % 120 ) == 0 ): #We pick an iteration number to save the loss abnd accuracy\n",
    "                \n",
    "                    predicted = self.feedForward(X_training_scaled) # get network ouput\n",
    "                  \n",
    "                    \n",
    "                    predicted_encoded = [np.argmax(x) for x in predicted] \n",
    "                    loss = self.cross_entropy(predicted,y_training_one_hot_unscaled) # Changed from MSE\n",
    "                    #loss = self.MSE(predicted_encoded, y_training.flatten())\n",
    "                    loss_list.append(loss)    \n",
    "                    #print(loss)\n",
    "                    acc = self.acc( y_training.flatten(), predicted_encoded)\n",
    "                    accuracy_list.append(acc)\n",
    "              \n",
    "                   \n",
    "                    \n",
    "                    np.set_printoptions(precision=2)\n",
    "                    print(\"Predicted\", predicted[:1])\n",
    "                    print(\"Iteration {0} -  loss: {1:.2f}, accuracy: {2:.2f}\".format(iteration_count, loss,acc, ))\n",
    "            \n",
    "\n",
    "                    iterations.append(iteration_count)                                \n",
    "                \n",
    "                iteration_count += 1\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append(self.weights_matrices)                \n",
    "            \n",
    "        return intermediate_weights, loss_list, accuracy_list,iterations\n",
    "\n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        cm = np.zeros((width, length))\n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        return cm\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Let us see how the network will handle a dropout of 10 % in first layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'full_connected_NN_dropout' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-2a2c9de18c13>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_connected_NN_dropout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_connected_NN_dropout\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0mnetwork_structure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mfull_connected_NN_dropout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'full_connected_NN_dropout' is not defined"
     ]
    }
   ],
   "source": [
    "full_connected_NN_dropout = full_connected_NN_dropout(bias=True,  network_structure=[1024,16,16,10], learning_rate=0.2)\n",
    "full_connected_NN_dropout.train(X_training_scaled, y_training_one_hot,batch_size=5, epochs=50, intermediate_results=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing l2\n",
    "Ass a weight penalty to penalize large weights. We implement a weight decay which is specified in intilization as lambda. We add this to a NN that uses Relu and Mean Squared Error as it has gotten the best results so far."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    X = np.array(X)\n",
    "    biggest = X.max(axis=1)\n",
    "    #print(\"X\", X)\n",
    "    #print(\"Biggest\", biggest)\n",
    "    #print(X - biggest[:,np.newaxis])\n",
    "    temp = X - biggest[:,np.newaxis]\n",
    "    #print(np.exp(temp))\n",
    "    exps =np.exp(temp)\n",
    "    sumExps = np.sum(exps, axis=1)\n",
    "   # print(\"sum exps\", sumExps)\n",
    "    returnStatement = exps / sumExps[:,np.newaxis]\n",
    "    return(returnStatement)\n",
    "\n",
    "\n",
    "class full_connected_NN_L2(object):\n",
    "    \n",
    "    def __init__(self, bias, network_structure, learning_rate, l2Lambda=0.2, useL2=True):\n",
    "        self.structure = network_structure\n",
    "        self.useL2 = useL2\n",
    "        self.l2Lambda = l2Lambda\n",
    "        self.learningRate = learning_rate\n",
    "        self.bias = bias       \n",
    "        self.initilize_weights()\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "        print(\"Learning rate: \" + str( self.learningRate) +\"\\n\")\n",
    "    \n",
    "           \n",
    "    def initilize_weights(self):\n",
    "        print(\"inside init weghts\")\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []\n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        \n",
    "        while layer_index < no_of_layers:\n",
    "            print(\"inside init weghts\")\n",
    "\n",
    "            nodes_in = self.structure[layer_index-1] # get layer 0 first run and then incremented\n",
    "            nodes_out = self.structure[layer_index] # Gets the next layer\n",
    "            \n",
    "            rangeWeightLayer =  1 / np.sqrt(nodes_in)\n",
    "            distrubutionWeightLayer = truncated_normal(mean=2, sd=1, low=-rangeWeightLayer, upp=rangeWeightLayer)\n",
    "            weightLayer = distrubutionWeightLayer.rvs(( nodes_in + bias_node, nodes_out))\n",
    "            self.weights_matrices.append(weightLayer)\n",
    "            layer_index += 1\n",
    "            \n",
    "            \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "        no_of_layers = len(self.structure)\n",
    "        x = np.array(x, ndmin=2) # every row is an input\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(x))\n",
    "            x = np.c_[x, biases]  ##adding bias to the input layer\n",
    "        \n",
    "        \n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        \n",
    "        in_vector = x\n",
    "        \n",
    "        while layer_index < no_of_layers-1:\n",
    "            \n",
    "            \n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "    \n",
    "            a = ReLU(z) #sigmoid activation function\n",
    "            \n",
    "            in_vector = a\n",
    "            #input vector for next layer\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(in_vector))\n",
    "                in_vector = np.c_[in_vector, biases]  ##Adding the bias to the hidden layer\n",
    "            \n",
    "            layer_index += 1\n",
    "            \n",
    "        #Last layer softmax or sigmoid\n",
    "        lastZ = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "        output_network = stable_softmax(lastZ)\n",
    "        \n",
    "        \n",
    "        return output_network\n",
    "        \n",
    "     \n",
    "    def backward(self, iput, target):\n",
    "        \n",
    "        ##################GET the output and input vectors for the feedforward###########\n",
    "    \n",
    "        no_of_layers = len(self.structure)        \n",
    "        input_vector = np.array(iput, ndmin=2)\n",
    "        layer_index = 0\n",
    "        # The output/input vectors of the hidden layers layers:\n",
    "       \n",
    "        res_vectors = [input_vector]          \n",
    "        while layer_index < no_of_layers - 1: #\n",
    "            in_vector = res_vectors[-1] # Get the output from last layer\n",
    "           \n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                \n",
    "                biases = np.ones((len(in_vector),1))\n",
    "                in_vector = np.concatenate((in_vector, biases), axis=1) ##adding bias to the input layer for every layer\n",
    "             \n",
    "          \n",
    "            res_vectors[-1] = in_vector # Save the input vector with added bias\n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index]) # The weighted sum  - often denoted z\n",
    "            res_vectors.append(z)\n",
    "            if(layer_index == no_of_layers-2):\n",
    "                out_vector = stable_softmax(z)\n",
    "                \n",
    "               \n",
    "            else:\n",
    "                out_vector = ReLU(z)\n",
    "            res_vectors.append(out_vector)   \n",
    "            layer_index += 1\n",
    "        \n",
    "    \n",
    "        #############  LAST LAYER WEIGHTS UPDATE ########################\n",
    "        weight_gradients = []\n",
    "          \n",
    "        deltaLast = res_vectors[-1] - target ##Sofmax impementation\n",
    "       \n",
    "        dz2dw2 = res_vectors[-3].T # partial derivative of z2 with respect to weights\n",
    "\n",
    "        #### UPDATE WEIGHTS OF LAST LAYER\n",
    "        dcdw2 = np.dot( dz2dw2, deltaLast) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "        weight_gradients.append(dcdw2) # Transpose so each row is the the weight from each node, not each column\n",
    "        \n",
    "    \n",
    "        \n",
    "       ####HIDDEN LAYERS\n",
    "        \n",
    "        index_vecor = len(res_vectors) - 4\n",
    "        \n",
    "        layer_index = no_of_layers - 1\n",
    "       \n",
    "        while layer_index > 1:\n",
    "            dzda = self.weights_matrices[layer_index-1].T #Weight between layers\n",
    "            dcda = np.dot(deltaLast, dzda)\n",
    "            dadz = ReLU_derivation(res_vectors[index_vecor])\n",
    "            delta = dcda[:,:-1] * dadz #Take away bias as input to get delta\n",
    "            deltaLast = delta\n",
    "            dcdw = np.dot(res_vectors[index_vecor-1].T,delta)\n",
    "            weight_gradients.append(dcdw)            \n",
    "            layer_index -= 1\n",
    "            index_vecor -= 2\n",
    "            \n",
    "        \n",
    "        return weight_gradients\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def cross_entropy(self,output, target):\n",
    "        loss =  target * np.log(output)\n",
    "        return -np.sum(loss)\n",
    "    \n",
    "    \n",
    "    def train_single(self, training, target):\n",
    "        \n",
    "        gradients = self.backward(training, target)\n",
    "       \n",
    "        weight_index = len(self.weights_matrices) -1\n",
    "        for i in range(len(gradients)):\n",
    "            if self.useL2:\n",
    "                self.weights_matrices[weight_index]  = self.weights_matrices[weight_index] * (1-self.l2Lambda)\n",
    "            self.weights_matrices[weight_index] = self.weights_matrices[weight_index] - (self.learningRate * gradients[i])\n",
    "            weight_index -= 1\n",
    "    \n",
    "    \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              batch_size,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        \n",
    "        intermediate_weights = []\n",
    "        \n",
    "        \n",
    "        loss_list = []\n",
    "        iterations = []\n",
    "        accuracy_list = []\n",
    "                        \n",
    "        iteration_count = 1\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"Epoch {}\".format(str(epoch+1)), end=\"\")\n",
    "        \n",
    "            for iteration in np.arange(0,len(data_array+1), batch_size): #Move index a batch size for every run\n",
    "                #print(iteration)\n",
    "                start_index = iteration\n",
    "                end_index = iteration+batch_size-1\n",
    "               \n",
    "                features = data_array[start_index : end_index]\n",
    "                targets = labels_one_hot_array[start_index : end_index]\n",
    "                \n",
    "                self.train_single(features, targets) #Train the batch size\n",
    "                                \n",
    "               ##For intermediate evaluation\n",
    "                if ((iteration_count % 120 ) == 0 ): #We pick an iteration number to save the loss abnd accuracy\n",
    "                \n",
    "                    predicted = self.feedForward(X_training_scaled) # get network ouput\n",
    "                  \n",
    "                    \n",
    "                    predicted_encoded = [np.argmax(x) for x in predicted] \n",
    "                    loss = self.cross_entropy(predicted,y_training_one_hot_unscaled) # Changed from MSE\n",
    "                    #loss = self.MSE(predicted_encoded, y_training.flatten())\n",
    "                    loss_list.append(loss)    \n",
    "                    #print(loss)\n",
    "                    acc = self.acc( y_training.flatten(), predicted_encoded)\n",
    "                    accuracy_list.append(acc)\n",
    "              \n",
    "                   \n",
    "                    \n",
    "                    np.set_printoptions(precision=2)\n",
    "                    print(\"Predicted\", predicted[:1])\n",
    "                    print(\"Iteration {0} -  loss: {1:.2f}, accuracy: {2:.2f}\".format(iteration_count, loss,acc, ))\n",
    "            \n",
    "\n",
    "                    iterations.append(iteration_count)                                \n",
    "                \n",
    "                iteration_count += 1\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append(self.weights_matrices)                \n",
    "            \n",
    "        return intermediate_weights, loss_list, accuracy_list,iterations\n",
    "\n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        cm = np.zeros((width, length))\n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        return cm7\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weight decay of 1 %"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside init weghts\n",
      "inside init weghts\n",
      "inside init weghts\n",
      "Epoch 1Predicted [[0.19 0.1  0.08 0.06 0.11 0.13 0.08 0.07 0.09 0.08]]\n",
      "Iteration 120 -  loss: 166693.45, accuracy: 0.19\n",
      "Predicted [[0.3  0.1  0.12 0.15 0.06 0.05 0.06 0.05 0.04 0.09]]\n",
      "Iteration 240 -  loss: 169368.25, accuracy: 0.19\n",
      "Predicted [[0.16 0.11 0.13 0.08 0.12 0.09 0.09 0.07 0.07 0.07]]\n",
      "Iteration 360 -  loss: 165024.25, accuracy: 0.19\n",
      "Predicted [[0.16 0.11 0.12 0.06 0.13 0.09 0.1  0.07 0.09 0.06]]\n",
      "Iteration 480 -  loss: 166223.79, accuracy: 0.19\n",
      "Predicted [[0.24 0.11 0.18 0.1  0.07 0.05 0.05 0.08 0.04 0.08]]\n",
      "Iteration 600 -  loss: 167294.36, accuracy: 0.19\n",
      "Predicted [[0.17 0.16 0.07 0.15 0.08 0.06 0.13 0.06 0.06 0.06]]\n",
      "Iteration 720 -  loss: 166718.16, accuracy: 0.19\n",
      "Predicted [[0.2  0.13 0.07 0.11 0.07 0.08 0.08 0.07 0.11 0.08]]\n",
      "Iteration 840 -  loss: 166035.79, accuracy: 0.19\n",
      "Predicted [[0.18 0.11 0.1  0.11 0.13 0.07 0.07 0.07 0.08 0.08]]\n",
      "Iteration 960 -  loss: 164951.82, accuracy: 0.19\n",
      "Predicted [[0.17 0.13 0.1  0.08 0.16 0.08 0.07 0.07 0.05 0.08]]\n",
      "Iteration 1080 -  loss: 165826.61, accuracy: 0.19\n",
      "Predicted [[0.21 0.2  0.07 0.1  0.09 0.1  0.08 0.03 0.05 0.06]]\n",
      "Iteration 1200 -  loss: 167339.64, accuracy: 0.19\n",
      "Predicted [[0.15 0.15 0.11 0.09 0.1  0.09 0.07 0.06 0.07 0.11]]\n",
      "Iteration 1320 -  loss: 165152.18, accuracy: 0.14\n",
      "Predicted [[0.15 0.18 0.09 0.13 0.1  0.1  0.08 0.05 0.04 0.08]]\n",
      "Iteration 1440 -  loss: 165784.72, accuracy: 0.14\n",
      "Predicted [[0.14 0.16 0.09 0.08 0.11 0.09 0.12 0.05 0.08 0.08]]\n",
      "Iteration 1560 -  loss: 166177.68, accuracy: 0.14\n",
      "Predicted [[0.08 0.29 0.12 0.07 0.09 0.05 0.1  0.05 0.08 0.05]]\n",
      "Iteration 1680 -  loss: 172527.34, accuracy: 0.14\n",
      "Predicted [[0.24 0.17 0.06 0.09 0.08 0.09 0.12 0.05 0.07 0.04]]\n",
      "Iteration 1800 -  loss: 167700.15, accuracy: 0.19\n",
      "Predicted [[0.13 0.17 0.1  0.12 0.07 0.07 0.12 0.08 0.07 0.07]]\n",
      "Iteration 1920 -  loss: 166245.70, accuracy: 0.14\n",
      "Predicted [[0.14 0.12 0.09 0.12 0.09 0.11 0.08 0.06 0.12 0.06]]\n",
      "Iteration 2040 -  loss: 166220.92, accuracy: 0.19\n",
      "Predicted [[0.23 0.11 0.16 0.1  0.06 0.05 0.09 0.06 0.07 0.06]]\n",
      "Iteration 2160 -  loss: 165953.04, accuracy: 0.19\n",
      "Predicted [[0.13 0.17 0.1  0.06 0.11 0.05 0.14 0.07 0.07 0.11]]\n",
      "Iteration 2280 -  loss: 168368.96, accuracy: 0.14\n",
      "Predicted [[0.17 0.11 0.12 0.1  0.11 0.06 0.06 0.09 0.1  0.08]]\n",
      "Iteration 2400 -  loss: 165317.33, accuracy: 0.19\n",
      "Predicted [[0.22 0.14 0.1  0.14 0.06 0.09 0.05 0.05 0.09 0.06]]\n",
      "Iteration 2520 -  loss: 166181.18, accuracy: 0.19\n",
      "Predicted [[0.26 0.09 0.08 0.07 0.11 0.08 0.07 0.07 0.08 0.08]]\n",
      "Iteration 2640 -  loss: 166723.99, accuracy: 0.19\n",
      "Predicted [[0.24 0.1  0.07 0.09 0.16 0.06 0.07 0.08 0.05 0.08]]\n",
      "Iteration 2760 -  loss: 167316.92, accuracy: 0.19\n",
      "Predicted [[0.24 0.15 0.08 0.06 0.07 0.05 0.07 0.11 0.09 0.08]]\n",
      "Iteration 2880 -  loss: 167623.62, accuracy: 0.19\n",
      "Predicted [[0.11 0.14 0.16 0.09 0.08 0.07 0.1  0.07 0.13 0.05]]\n",
      "Iteration 3000 -  loss: 167919.05, accuracy: 0.12\n",
      "Predicted [[0.19 0.14 0.1  0.14 0.06 0.09 0.04 0.06 0.1  0.07]]\n",
      "Iteration 3120 -  loss: 166534.27, accuracy: 0.19\n",
      "Predicted [[0.22 0.12 0.06 0.08 0.08 0.08 0.17 0.06 0.06 0.06]]\n",
      "Iteration 3240 -  loss: 168333.60, accuracy: 0.19\n",
      "Predicted [[0.28 0.09 0.07 0.1  0.12 0.05 0.06 0.09 0.07 0.07]]\n",
      "Iteration 3360 -  loss: 167985.49, accuracy: 0.19\n",
      "Predicted [[0.26 0.16 0.1  0.07 0.11 0.05 0.08 0.06 0.05 0.06]]\n",
      "Iteration 3480 -  loss: 165962.32, accuracy: 0.19\n",
      "Predicted [[0.12 0.1  0.16 0.11 0.1  0.09 0.09 0.06 0.1  0.07]]\n",
      "Iteration 3600 -  loss: 166998.95, accuracy: 0.12\n",
      "Predicted [[0.18 0.09 0.2  0.11 0.08 0.05 0.07 0.07 0.07 0.08]]\n",
      "Iteration 3720 -  loss: 167044.06, accuracy: 0.12\n",
      "Predicted [[0.23 0.1  0.11 0.08 0.09 0.07 0.11 0.05 0.07 0.08]]\n",
      "Iteration 3840 -  loss: 165815.34, accuracy: 0.19\n",
      "Predicted [[0.09 0.19 0.19 0.09 0.08 0.06 0.07 0.08 0.08 0.08]]\n",
      "Iteration 3960 -  loss: 169244.95, accuracy: 0.12\n",
      "Predicted [[0.19 0.17 0.12 0.07 0.06 0.12 0.09 0.09 0.05 0.05]]\n",
      "Iteration 4080 -  loss: 166519.39, accuracy: 0.19\n",
      "Predicted [[0.1  0.13 0.16 0.1  0.15 0.05 0.07 0.06 0.12 0.06]]\n",
      "Iteration 4200 -  loss: 168957.10, accuracy: 0.12\n",
      "Predicted [[0.13 0.13 0.07 0.13 0.18 0.1  0.07 0.06 0.07 0.06]]\n",
      "Iteration 4320 -  loss: 167632.12, accuracy: 0.09\n",
      "Predicted [[0.21 0.12 0.11 0.11 0.06 0.08 0.14 0.05 0.06 0.07]]\n",
      "Iteration 4440 -  loss: 166181.83, accuracy: 0.19\n",
      "Predicted [[0.18 0.1  0.09 0.09 0.2  0.08 0.06 0.07 0.07 0.06]]\n",
      "Iteration 4560 -  loss: 167522.50, accuracy: 0.09\n",
      "Predicted [[0.14 0.23 0.13 0.07 0.1  0.05 0.06 0.05 0.07 0.09]]\n",
      "Iteration 4680 -  loss: 167230.79, accuracy: 0.14\n",
      "Predicted [[0.21 0.13 0.07 0.12 0.12 0.08 0.07 0.11 0.04 0.05]]\n",
      "Iteration 4800 -  loss: 166593.15, accuracy: 0.19\n",
      "Predicted [[0.16 0.12 0.08 0.09 0.14 0.1  0.05 0.08 0.09 0.08]]\n",
      "Iteration 4920 -  loss: 166595.77, accuracy: 0.19\n",
      "Predicted [[0.14 0.18 0.09 0.19 0.07 0.08 0.06 0.06 0.06 0.07]]\n",
      "Iteration 5040 -  loss: 167418.88, accuracy: 0.10\n",
      "Predicted [[0.12 0.2  0.08 0.12 0.07 0.11 0.1  0.06 0.09 0.07]]\n",
      "Iteration 5160 -  loss: 167568.48, accuracy: 0.14\n",
      "Predicted [[0.21 0.11 0.15 0.1  0.05 0.09 0.07 0.06 0.06 0.09]]\n",
      "Iteration 5280 -  loss: 166191.35, accuracy: 0.19\n",
      "Predicted [[0.15 0.16 0.15 0.07 0.08 0.1  0.05 0.07 0.08 0.09]]\n",
      "Iteration 5400 -  loss: 166010.90, accuracy: 0.14\n",
      "Predicted [[0.14 0.16 0.17 0.08 0.06 0.09 0.11 0.05 0.09 0.06]]\n",
      "Iteration 5520 -  loss: 166991.49, accuracy: 0.12\n",
      "Predicted [[0.12 0.21 0.12 0.06 0.1  0.05 0.08 0.06 0.07 0.12]]\n",
      "Iteration 5640 -  loss: 168171.39, accuracy: 0.14\n",
      "Predicted [[0.17 0.19 0.06 0.07 0.09 0.13 0.07 0.06 0.05 0.09]]\n",
      "Iteration 5760 -  loss: 167713.05, accuracy: 0.14\n",
      "Predicted [[0.14 0.17 0.12 0.09 0.11 0.05 0.09 0.08 0.11 0.05]]\n",
      "Iteration 5880 -  loss: 166404.63, accuracy: 0.14\n",
      "Predicted [[0.17 0.13 0.12 0.09 0.12 0.08 0.05 0.07 0.09 0.07]]\n",
      "Iteration 6000 -  loss: 164926.76, accuracy: 0.19\n",
      "Predicted [[0.16 0.1  0.12 0.12 0.1  0.09 0.07 0.06 0.09 0.08]]\n",
      "Iteration 6120 -  loss: 165286.06, accuracy: 0.19\n",
      "Predicted [[0.17 0.19 0.14 0.09 0.06 0.11 0.07 0.08 0.05 0.05]]\n",
      "Iteration 6240 -  loss: 165867.74, accuracy: 0.14\n",
      "Predicted [[0.1  0.16 0.07 0.16 0.09 0.09 0.13 0.06 0.09 0.07]]\n",
      "Iteration 6360 -  loss: 169314.85, accuracy: 0.10\n",
      "Predicted [[0.2  0.13 0.1  0.06 0.2  0.06 0.09 0.06 0.05 0.06]]\n",
      "Iteration 6480 -  loss: 167704.85, accuracy: 0.09\n",
      "Predicted [[0.14 0.12 0.12 0.1  0.08 0.1  0.11 0.09 0.06 0.07]]\n",
      "Iteration 6600 -  loss: 165392.33, accuracy: 0.19\n",
      "Predicted [[0.24 0.09 0.11 0.09 0.07 0.13 0.09 0.08 0.04 0.05]]\n",
      "Iteration 6720 -  loss: 167142.00, accuracy: 0.19\n",
      "Predicted [[0.22 0.17 0.07 0.09 0.1  0.07 0.06 0.06 0.08 0.07]]\n",
      "Iteration 6840 -  loss: 165583.19, accuracy: 0.19\n",
      "Predicted [[0.15 0.17 0.08 0.09 0.09 0.14 0.05 0.07 0.05 0.12]]\n",
      "Iteration 6960 -  loss: 167790.36, accuracy: 0.14\n",
      "Predicted [[0.15 0.14 0.18 0.07 0.08 0.07 0.07 0.09 0.08 0.07]]\n",
      "Iteration 7080 -  loss: 166246.25, accuracy: 0.12\n",
      "Predicted [[0.16 0.1  0.14 0.12 0.09 0.06 0.06 0.07 0.12 0.06]]\n",
      "Iteration 7200 -  loss: 166485.01, accuracy: 0.19\n",
      "Predicted [[0.17 0.14 0.11 0.12 0.07 0.09 0.1  0.08 0.07 0.05]]\n",
      "Iteration 7320 -  loss: 165044.13, accuracy: 0.19\n",
      "Predicted [[0.2  0.18 0.08 0.11 0.06 0.06 0.1  0.04 0.07 0.1 ]]\n",
      "Iteration 7440 -  loss: 166544.31, accuracy: 0.19\n",
      "Predicted [[0.24 0.1  0.1  0.07 0.07 0.13 0.06 0.07 0.06 0.09]]\n",
      "Iteration 7560 -  loss: 166661.25, accuracy: 0.19\n",
      "Predicted [[0.19 0.14 0.09 0.15 0.07 0.08 0.07 0.06 0.1  0.05]]\n",
      "Iteration 7680 -  loss: 165772.75, accuracy: 0.19\n",
      "Predicted [[0.28 0.13 0.11 0.06 0.1  0.06 0.06 0.07 0.08 0.06]]\n",
      "Iteration 7800 -  loss: 166690.50, accuracy: 0.19\n",
      "Predicted [[0.15 0.11 0.09 0.09 0.11 0.16 0.08 0.09 0.05 0.06]]\n",
      "Iteration 7920 -  loss: 167176.47, accuracy: 0.08\n",
      "Predicted [[0.15 0.18 0.14 0.08 0.08 0.12 0.08 0.07 0.05 0.04]]\n",
      "Iteration 8040 -  loss: 166345.20, accuracy: 0.14\n",
      "Predicted [[0.18 0.09 0.13 0.08 0.09 0.1  0.09 0.09 0.05 0.09]]\n",
      "Iteration 8160 -  loss: 165875.59, accuracy: 0.19\n",
      "Predicted [[0.16 0.08 0.11 0.14 0.08 0.14 0.07 0.04 0.11 0.08]]\n",
      "Iteration 8280 -  loss: 168986.92, accuracy: 0.19\n",
      "Predicted [[0.17 0.15 0.1  0.11 0.09 0.12 0.07 0.05 0.07 0.06]]\n",
      "Iteration 8400 -  loss: 164868.85, accuracy: 0.19\n",
      "Predicted [[0.11 0.17 0.16 0.07 0.12 0.06 0.06 0.06 0.08 0.12]]\n",
      "Iteration 8520 -  loss: 168644.86, accuracy: 0.14\n",
      "Predicted [[0.17 0.23 0.09 0.09 0.08 0.11 0.05 0.07 0.06 0.05]]\n",
      "Iteration 8640 -  loss: 166577.83, accuracy: 0.14\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted [[0.14 0.21 0.14 0.11 0.08 0.09 0.06 0.08 0.04 0.05]]\n",
      "Iteration 8760 -  loss: 166288.50, accuracy: 0.14\n",
      "Predicted [[0.29 0.1  0.08 0.1  0.1  0.07 0.07 0.05 0.06 0.09]]\n",
      "Iteration 8880 -  loss: 167000.01, accuracy: 0.19\n",
      "Predicted [[0.13 0.11 0.14 0.11 0.1  0.07 0.1  0.1  0.08 0.06]]\n",
      "Iteration 9000 -  loss: 166131.71, accuracy: 0.12\n",
      "Predicted [[0.36 0.13 0.08 0.09 0.06 0.07 0.04 0.05 0.04 0.07]]\n",
      "Iteration 9120 -  loss: 169878.33, accuracy: 0.19\n",
      "Predicted [[0.2  0.17 0.1  0.14 0.07 0.07 0.08 0.06 0.09 0.04]]\n",
      "Iteration 9240 -  loss: 165557.36, accuracy: 0.19\n",
      "Predicted [[0.23 0.11 0.16 0.09 0.09 0.07 0.05 0.1  0.04 0.05]]\n",
      "Iteration 9360 -  loss: 166340.10, accuracy: 0.19\n",
      "Predicted [[0.2  0.14 0.07 0.12 0.09 0.07 0.1  0.1  0.07 0.05]]\n",
      "Iteration 9480 -  loss: 165607.06, accuracy: 0.19\n",
      "Predicted [[0.09 0.2  0.09 0.09 0.07 0.12 0.09 0.09 0.07 0.08]]\n",
      "Iteration 9600 -  loss: 168728.43, accuracy: 0.14\n",
      "Predicted [[0.14 0.16 0.16 0.1  0.08 0.06 0.05 0.06 0.11 0.07]]\n",
      "Iteration 9720 -  loss: 166558.29, accuracy: 0.12\n",
      "Predicted [[0.15 0.16 0.09 0.1  0.1  0.08 0.07 0.08 0.06 0.11]]\n",
      "Iteration 9840 -  loss: 164985.75, accuracy: 0.14\n",
      "Predicted [[0.17 0.13 0.13 0.09 0.1  0.08 0.11 0.09 0.05 0.07]]\n",
      "Iteration 9960 -  loss: 164705.53, accuracy: 0.19\n",
      "Predicted [[0.12 0.18 0.13 0.1  0.09 0.07 0.15 0.06 0.05 0.06]]\n",
      "Iteration 10080 -  loss: 167259.49, accuracy: 0.14\n",
      "Predicted [[0.26 0.13 0.11 0.09 0.06 0.06 0.09 0.05 0.09 0.07]]\n",
      "Iteration 10200 -  loss: 166174.92, accuracy: 0.19\n",
      "Predicted [[0.16 0.19 0.06 0.11 0.09 0.06 0.11 0.09 0.07 0.06]]\n",
      "Iteration 10320 -  loss: 166751.97, accuracy: 0.14\n",
      "Predicted [[0.28 0.1  0.06 0.05 0.1  0.09 0.1  0.08 0.08 0.04]]\n",
      "Iteration 10440 -  loss: 169336.62, accuracy: 0.19\n",
      "Predicted [[0.21 0.18 0.07 0.09 0.12 0.09 0.07 0.05 0.05 0.07]]\n",
      "Iteration 10560 -  loss: 165700.08, accuracy: 0.19\n",
      "Predicted [[0.2  0.15 0.14 0.1  0.08 0.11 0.07 0.06 0.07 0.04]]\n",
      "Iteration 10680 -  loss: 165568.33, accuracy: 0.19\n",
      "Predicted [[0.22 0.1  0.07 0.14 0.1  0.06 0.07 0.07 0.1  0.08]]\n",
      "Iteration 10800 -  loss: 166975.60, accuracy: 0.19\n",
      "Predicted [[0.27 0.1  0.08 0.15 0.1  0.08 0.07 0.07 0.04 0.04]]\n",
      "Iteration 10920 -  loss: 167760.29, accuracy: 0.19\n",
      "Predicted [[0.2  0.12 0.09 0.14 0.08 0.13 0.07 0.06 0.06 0.05]]\n",
      "Iteration 11040 -  loss: 166145.85, accuracy: 0.19\n",
      "Predicted [[0.11 0.1  0.24 0.06 0.11 0.08 0.1  0.1  0.04 0.06]]\n",
      "Iteration 11160 -  loss: 171317.91, accuracy: 0.12\n",
      "Predicted [[0.22 0.12 0.11 0.08 0.09 0.07 0.09 0.09 0.06 0.08]]\n",
      "Iteration 11280 -  loss: 164725.16, accuracy: 0.19\n",
      "Predicted [[0.21 0.07 0.14 0.11 0.08 0.07 0.09 0.09 0.05 0.1 ]]\n",
      "Iteration 11400 -  loss: 167555.36, accuracy: 0.19\n",
      "Predicted [[0.21 0.12 0.13 0.1  0.07 0.11 0.07 0.05 0.06 0.07]]\n",
      "Iteration 11520 -  loss: 164915.11, accuracy: 0.19\n",
      "Predicted [[0.31 0.15 0.08 0.08 0.07 0.08 0.07 0.04 0.06 0.08]]\n",
      "Iteration 11640 -  loss: 167717.40, accuracy: 0.19\n",
      "Predicted [[0.26 0.13 0.11 0.04 0.12 0.08 0.07 0.06 0.04 0.08]]\n",
      "Iteration 11760 -  loss: 167670.29, accuracy: 0.19\n",
      "Predicted [[0.17 0.14 0.13 0.1  0.08 0.17 0.05 0.07 0.05 0.06]]\n",
      "Iteration 11880 -  loss: 166825.50, accuracy: 0.19\n",
      "Predicted [[0.18 0.08 0.15 0.16 0.08 0.07 0.08 0.05 0.04 0.11]]\n",
      "Iteration 12000 -  loss: 167879.52, accuracy: 0.19\n",
      "Predicted [[0.18 0.14 0.07 0.12 0.15 0.09 0.05 0.06 0.05 0.09]]\n",
      "Iteration 12120 -  loss: 166493.23, accuracy: 0.19\n",
      "Predicted [[0.13 0.25 0.13 0.07 0.08 0.05 0.1  0.06 0.07 0.06]]\n",
      "Iteration 12240 -  loss: 168027.19, accuracy: 0.14\n",
      "Predicted [[0.22 0.11 0.09 0.1  0.11 0.11 0.07 0.06 0.07 0.07]]\n",
      "Iteration 12360 -  loss: 165281.63, accuracy: 0.19\n",
      "Predicted [[0.21 0.09 0.12 0.16 0.08 0.05 0.07 0.1  0.06 0.06]]\n",
      "Iteration 12480 -  loss: 166832.49, accuracy: 0.19\n",
      "Predicted [[0.21 0.17 0.11 0.05 0.1  0.06 0.08 0.08 0.07 0.06]]\n",
      "Iteration 12600 -  loss: 165978.84, accuracy: 0.19\n",
      "Predicted [[0.15 0.15 0.11 0.07 0.15 0.07 0.08 0.07 0.05 0.09]]\n",
      "Iteration 12720 -  loss: 165926.29, accuracy: 0.19\n",
      "Predicted [[0.16 0.18 0.12 0.09 0.07 0.08 0.04 0.06 0.1  0.1 ]]\n",
      "Iteration 12840 -  loss: 166224.16, accuracy: 0.14\n",
      "Predicted [[0.16 0.23 0.05 0.08 0.13 0.06 0.1  0.06 0.08 0.05]]\n",
      "Iteration 12960 -  loss: 168775.02, accuracy: 0.14\n",
      "Predicted [[0.11 0.17 0.11 0.06 0.13 0.17 0.06 0.1  0.04 0.06]]\n",
      "Iteration 13080 -  loss: 170512.59, accuracy: 0.14\n",
      "Predicted [[0.23 0.12 0.14 0.1  0.09 0.05 0.08 0.08 0.04 0.07]]\n",
      "Iteration 13200 -  loss: 165470.22, accuracy: 0.19\n",
      "Predicted [[0.14 0.15 0.12 0.06 0.13 0.07 0.06 0.06 0.09 0.12]]\n",
      "Iteration 13320 -  loss: 166792.83, accuracy: 0.14\n",
      "Predicted [[0.18 0.12 0.1  0.11 0.08 0.06 0.1  0.1  0.07 0.07]]\n",
      "Iteration 13440 -  loss: 164914.21, accuracy: 0.19\n",
      "Predicted [[0.13 0.13 0.14 0.13 0.08 0.04 0.1  0.08 0.08 0.07]]\n",
      "Iteration 13560 -  loss: 166413.98, accuracy: 0.12\n",
      "Predicted [[0.17 0.16 0.1  0.05 0.21 0.07 0.07 0.03 0.09 0.04]]\n",
      "Iteration 13680 -  loss: 170396.47, accuracy: 0.09\n",
      "Predicted [[0.12 0.18 0.12 0.06 0.06 0.08 0.11 0.1  0.08 0.09]]\n",
      "Iteration 13800 -  loss: 167976.54, accuracy: 0.14\n",
      "Predicted [[0.13 0.08 0.21 0.13 0.09 0.07 0.1  0.07 0.07 0.07]]\n",
      "Iteration 13920 -  loss: 168930.23, accuracy: 0.12\n",
      "Predicted [[0.14 0.16 0.1  0.12 0.07 0.06 0.1  0.06 0.13 0.05]]\n",
      "Iteration 14040 -  loss: 167109.22, accuracy: 0.14\n",
      "Predicted [[0.28 0.13 0.09 0.09 0.07 0.08 0.07 0.06 0.08 0.06]]\n",
      "Iteration 14160 -  loss: 165962.12, accuracy: 0.19\n",
      "Predicted [[0.16 0.11 0.16 0.1  0.13 0.12 0.06 0.07 0.05 0.05]]\n",
      "Iteration 14280 -  loss: 166394.15, accuracy: 0.12\n",
      "Predicted [[0.14 0.1  0.1  0.06 0.16 0.09 0.09 0.08 0.07 0.1 ]]\n",
      "Iteration 14400 -  loss: 168170.43, accuracy: 0.09\n",
      "Predicted [[0.14 0.13 0.1  0.12 0.08 0.07 0.07 0.11 0.12 0.07]]\n",
      "Iteration 14520 -  loss: 166343.48, accuracy: 0.19\n",
      "Predicted [[0.15 0.13 0.1  0.1  0.09 0.07 0.11 0.06 0.09 0.11]]\n",
      "Iteration 14640 -  loss: 165951.11, accuracy: 0.19\n",
      "Epoch 2Predicted [[0.2  0.12 0.12 0.08 0.1  0.06 0.07 0.09 0.07 0.09]]\n",
      "Iteration 14760 -  loss: 164804.40, accuracy: 0.19\n",
      "Predicted [[0.26 0.13 0.11 0.12 0.06 0.07 0.05 0.07 0.04 0.09]]\n",
      "Iteration 14880 -  loss: 166411.19, accuracy: 0.19\n",
      "Predicted [[0.16 0.11 0.11 0.1  0.18 0.07 0.08 0.08 0.07 0.04]]\n",
      "Iteration 15000 -  loss: 166575.86, accuracy: 0.09\n",
      "Predicted [[0.14 0.08 0.09 0.08 0.07 0.07 0.17 0.08 0.1  0.12]]\n",
      "Iteration 15120 -  loss: 170612.38, accuracy: 0.08\n",
      "Predicted [[0.18 0.19 0.13 0.09 0.08 0.08 0.06 0.08 0.05 0.05]]\n",
      "Iteration 15240 -  loss: 164954.41, accuracy: 0.14\n",
      "Predicted [[0.15 0.27 0.09 0.06 0.07 0.08 0.08 0.07 0.07 0.06]]\n",
      "Iteration 15360 -  loss: 168127.87, accuracy: 0.14\n",
      "Predicted [[0.2  0.16 0.1  0.07 0.06 0.1  0.1  0.08 0.08 0.06]]\n",
      "Iteration 15480 -  loss: 165642.29, accuracy: 0.19\n",
      "Predicted [[0.22 0.09 0.16 0.08 0.1  0.06 0.07 0.05 0.08 0.08]]\n",
      "Iteration 15600 -  loss: 166205.67, accuracy: 0.19\n",
      "Predicted [[0.15 0.18 0.18 0.1  0.08 0.06 0.09 0.05 0.05 0.07]]\n",
      "Iteration 15720 -  loss: 165952.54, accuracy: 0.12\n",
      "Predicted [[0.16 0.16 0.1  0.13 0.08 0.08 0.1  0.04 0.07 0.08]]\n",
      "Iteration 15840 -  loss: 165458.95, accuracy: 0.14\n",
      "Predicted [[0.11 0.1  0.14 0.23 0.09 0.07 0.1  0.04 0.07 0.06]]\n",
      "Iteration 15960 -  loss: 170708.57, accuracy: 0.10\n",
      "Predicted [[0.17 0.09 0.12 0.07 0.11 0.14 0.12 0.05 0.07 0.06]]\n",
      "Iteration 16080 -  loss: 167448.78, accuracy: 0.19\n",
      "Predicted [[0.15 0.11 0.23 0.07 0.07 0.11 0.07 0.05 0.06 0.08]]\n",
      "Iteration 16200 -  loss: 168320.02, accuracy: 0.12\n",
      "Predicted [[0.17 0.14 0.12 0.08 0.13 0.05 0.1  0.08 0.08 0.04]]\n",
      "Iteration 16320 -  loss: 166000.37, accuracy: 0.19\n",
      "Predicted [[0.18 0.14 0.11 0.1  0.07 0.09 0.11 0.07 0.07 0.05]]\n",
      "Iteration 16440 -  loss: 164973.40, accuracy: 0.19\n",
      "Predicted [[0.15 0.12 0.16 0.14 0.09 0.06 0.06 0.07 0.07 0.1 ]]\n",
      "Iteration 16560 -  loss: 166117.05, accuracy: 0.12\n",
      "Predicted [[0.23 0.17 0.1  0.09 0.07 0.07 0.09 0.05 0.06 0.07]]\n",
      "Iteration 16680 -  loss: 165317.31, accuracy: 0.19\n",
      "Predicted [[0.14 0.1  0.1  0.13 0.09 0.09 0.09 0.06 0.13 0.06]]\n",
      "Iteration 16800 -  loss: 167312.27, accuracy: 0.19\n",
      "Predicted [[0.16 0.17 0.1  0.08 0.1  0.08 0.08 0.07 0.08 0.08]]\n",
      "Iteration 16920 -  loss: 164652.07, accuracy: 0.14\n",
      "Predicted [[0.18 0.17 0.11 0.09 0.17 0.06 0.08 0.04 0.07 0.04]]\n",
      "Iteration 17040 -  loss: 166662.52, accuracy: 0.19\n",
      "Predicted [[0.1  0.23 0.1  0.09 0.08 0.14 0.09 0.06 0.04 0.07]]\n",
      "Iteration 17160 -  loss: 169777.69, accuracy: 0.14\n",
      "Predicted [[0.18 0.14 0.11 0.08 0.11 0.07 0.09 0.08 0.1  0.06]]\n",
      "Iteration 17280 -  loss: 164832.04, accuracy: 0.19\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted [[0.21 0.08 0.13 0.09 0.15 0.06 0.06 0.07 0.06 0.08]]\n",
      "Iteration 17400 -  loss: 166960.45, accuracy: 0.19\n",
      "Predicted [[0.22 0.2  0.11 0.06 0.04 0.07 0.07 0.05 0.08 0.1 ]]\n",
      "Iteration 17520 -  loss: 168541.12, accuracy: 0.19\n",
      "Predicted [[0.13 0.1  0.1  0.09 0.18 0.07 0.08 0.07 0.09 0.08]]\n",
      "Iteration 17640 -  loss: 167539.07, accuracy: 0.09\n",
      "Predicted [[0.2  0.14 0.12 0.12 0.06 0.06 0.07 0.07 0.09 0.07]]\n",
      "Iteration 17760 -  loss: 165237.49, accuracy: 0.19\n",
      "Predicted [[0.22 0.14 0.1  0.06 0.09 0.08 0.08 0.08 0.06 0.08]]\n",
      "Iteration 17880 -  loss: 164963.21, accuracy: 0.19\n",
      "Predicted [[0.14 0.17 0.06 0.11 0.11 0.05 0.14 0.06 0.07 0.08]]\n",
      "Iteration 18000 -  loss: 167997.18, accuracy: 0.14\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-68-f6eab9ca14b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mfull_connected_NN_L2\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfull_connected_NN_L2\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbias\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0ml2Lambda\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.01\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mnetwork_structure\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1024\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mfull_connected_NN_L2\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-67-6489cf54fcf7>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_array, labels_one_hot_array, batch_size, epochs, intermediate_results)\u001b[0m\n\u001b[1;32m    220\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m120\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#We pick an iteration number to save the loss abnd accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    221\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 222\u001b[0;31m                     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get network ouput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    223\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    224\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-67-6489cf54fcf7>\u001b[0m in \u001b[0;36mfeedForward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     78\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     79\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 80\u001b[0;31m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_matrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sigmoid activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_connected_NN_L2 = full_connected_NN_L2(bias=True,  l2Lambda=0.01,network_structure=[1024,16, 10], learning_rate=0.2)\n",
    "full_connected_NN_L2.train(X_training_scaled, y_training_one_hot,batch_size=5, epochs=50, intermediate_results=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As both the dropout and the L2 could not converge to the training data, there is no point in testing the trained models to the training set."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implementing SGD + momentum\n",
    "Momentum is added to the gradients to take into consideration the previous deltachanges. So it can get escape get over local optima (small hills). Plan is to calculate the exponential weighted average of our gradient. \n",
    "\n",
    "### SGD vs Gradient descent\n",
    "Stochastich gradient descent is taking small steps towards minmum compared to gradient descent. We have already used stochastich gradient descent in som sence thorughout the implementation. However, the problem with stochastic gradient descent is that is not taking the straight way towards the minimum. Also it can get stuck in local maximum and minimum. There are many different techniques to achive this. One is momentum.\n",
    "\n",
    "\n",
    "### Momentum\n",
    "We have to calculate the exponential moving average.\n",
    "The moving average is simply \n",
    "$$grad^{i}=\\gamma * grad^{i-1}+grad^{i}$$\n",
    "gamma is the momentum constant. We also have to specify a period of how many sequences we are calculating moving average for."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stable_softmax(X):\n",
    "    X = np.array(X)\n",
    "    biggest = X.max(axis=1)\n",
    "    #print(\"X\", X)\n",
    "    #print(\"Biggest\", biggest)\n",
    "    #print(X - biggest[:,np.newaxis])\n",
    "    temp = X - biggest[:,np.newaxis]\n",
    "    #print(np.exp(temp))\n",
    "    exps =np.exp(temp)\n",
    "    sumExps = np.sum(exps, axis=1)\n",
    "   # print(\"sum exps\", sumExps)\n",
    "    returnStatement = exps / sumExps[:,np.newaxis]\n",
    "    return(returnStatement)\n",
    "\n",
    "\n",
    "class full_connected_NN_Momentum(object):\n",
    "    \n",
    "    def __init__(self, bias, network_structure, learning_rate, l2Lambda=0.2, useL2=False, momentum=True):\n",
    "        self.structure = network_structure\n",
    "        self.useL2 = useL2\n",
    "        self.gamma = 0.09\n",
    "        self.previousGradients = 0\n",
    "        self.l2Lambda = l2Lambda\n",
    "        self.learningRate = learning_rate\n",
    "        self.bias = bias       \n",
    "        self.initilize_weights()\n",
    "        \n",
    "    def summary(self):\n",
    "        print(\"Input layer size : \" + str(self.inputLayerSize) + \"\\n\")\n",
    "        print(\"Hidden layer size : \" +str(self.hiddenLayerSize) + \"\\n\")\n",
    "        print(\"Output layer size : \" + str(self.outputLayerSize) + \"\\n\")\n",
    "        \n",
    "        ##Parameters\n",
    "        parametersInFirstLayer = np.multiply(self.W1.shape[0], self.W1.shape[1])\n",
    "        parametersInHiddenLayer = np.multiply(self.W2.shape[0], self.W2.shape[1])\n",
    "        print(\"Parameters to train in W1: \" + str(parametersInFirstLayer) +\"\\n\")\n",
    "        print(\"Parameters to train in W2: \" + str(parametersInHiddenLayer) +\"\\n\")\n",
    "\n",
    "        print(\"Total parameters: \", str(parametersInFirstLayer + parametersInHiddenLayer))\n",
    "        print(\"Learning rate: \" + str( self.learningRate) +\"\\n\")\n",
    "    \n",
    "           \n",
    "     \n",
    "    def initlize_momentum(self, iput, target):\n",
    "        self.previousGradients = self.backward(iput, target)\n",
    "        \n",
    "        \n",
    "    def initilize_weights(self):\n",
    "        print(\"inside init weghts\")\n",
    "        #self.W1 = np.random.rand(self.inputLayerSize, self.hiddenLayerSize) # (1024x16) !16384 parameters! weights from input nodes to hidden layer (1024x16)\n",
    "        #self.W2 = np.random.rand(self.hiddenLayerSize, self.outputLayerSize) #(16x2) 32parameters weights from hidden layers to output\n",
    "        bias_node = 1 if self.bias else 0\n",
    "        self.weights_matrices = []\n",
    "        layer_index = 1\n",
    "        no_of_layers = len(self.structure)\n",
    "        \n",
    "        while layer_index < no_of_layers:\n",
    "            print(\"inside init weghts\")\n",
    "\n",
    "            nodes_in = self.structure[layer_index-1] # get layer 0 first run and then incremented\n",
    "            nodes_out = self.structure[layer_index] # Gets the next layer\n",
    "            \n",
    "            rangeWeightLayer =  1 / np.sqrt(nodes_in)\n",
    "            distrubutionWeightLayer = truncated_normal(mean=2, sd=1, low=-rangeWeightLayer, upp=rangeWeightLayer)\n",
    "            weightLayer = distrubutionWeightLayer.rvs(( nodes_in + bias_node, nodes_out))\n",
    "            self.weights_matrices.append(weightLayer)\n",
    "            layer_index += 1\n",
    "            \n",
    "            \n",
    "    def feedForward(self, x):       \n",
    "       \n",
    "        no_of_layers = len(self.structure)\n",
    "        x = np.array(x, ndmin=2) # every row is an input\n",
    "        if self.bias:\n",
    "            biases = np.ones(len(x))\n",
    "            x = np.c_[x, biases]  ##adding bias to the input layer\n",
    "        \n",
    "        \n",
    "        layer_index = 1\n",
    "        # The input vectors to the various layers\n",
    "        \n",
    "        in_vector = x\n",
    "        \n",
    "        while layer_index < no_of_layers-1:\n",
    "            \n",
    "            \n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "    \n",
    "            a = ReLU(z) #sigmoid activation function\n",
    "            \n",
    "            in_vector = a\n",
    "            #input vector for next layer\n",
    "            if self.bias:\n",
    "                biases = np.ones(len(in_vector))\n",
    "                in_vector = np.c_[in_vector, biases]  ##Adding the bias to the hidden layer\n",
    "            \n",
    "            layer_index += 1\n",
    "            \n",
    "        #Last layer softmax or sigmoid\n",
    "        lastZ = np.dot(in_vector, self.weights_matrices[layer_index-1])\n",
    "        output_network = stable_softmax(lastZ)\n",
    "        \n",
    "        \n",
    "        return output_network\n",
    "        \n",
    "     \n",
    "    def backward(self, iput, target):\n",
    "        \n",
    "        ##################GET the output and input vectors for the feedforward###########\n",
    "    \n",
    "        no_of_layers = len(self.structure)        \n",
    "        input_vector = np.array(iput, ndmin=2)\n",
    "        layer_index = 0\n",
    "        # The output/input vectors of the hidden layers layers:\n",
    "       \n",
    "        res_vectors = [input_vector]          \n",
    "        while layer_index < no_of_layers - 1: #\n",
    "            in_vector = res_vectors[-1] # Get the output from last layer\n",
    "           \n",
    "            if self.bias:\n",
    "                # adding bias node to the end of the 'input'_vector\n",
    "                \n",
    "                biases = np.ones((len(in_vector),1))\n",
    "                in_vector = np.concatenate((in_vector, biases), axis=1) ##adding bias to the input layer for every layer\n",
    "             \n",
    "          \n",
    "            res_vectors[-1] = in_vector # Save the input vector with added bias\n",
    "            z = np.dot(in_vector, self.weights_matrices[layer_index]) # The weighted sum  - often denoted z\n",
    "            res_vectors.append(z)\n",
    "            if(layer_index == no_of_layers-2):\n",
    "                out_vector = stable_softmax(z)\n",
    "                \n",
    "               \n",
    "            else:\n",
    "                out_vector = ReLU(z)\n",
    "            res_vectors.append(out_vector)   \n",
    "            layer_index += 1\n",
    "        \n",
    "    \n",
    "        #############  LAST LAYER WEIGHTS UPDATE ########################\n",
    "        weight_gradients = []\n",
    "          \n",
    "        deltaLast = res_vectors[-1] - target ##Sofmax impementation\n",
    "       \n",
    "        dz2dw2 = res_vectors[-3].T # partial derivative of z2 with respect to weights\n",
    "\n",
    "        #### UPDATE WEIGHTS OF LAST LAYER\n",
    "        dcdw2 = np.dot( dz2dw2, deltaLast) # chain rule applied to get derivative of the cost w.r.t. the weights\n",
    "        weight_gradients.append(dcdw2) # Transpose so each row is the the weight from each node, not each column\n",
    "        \n",
    "    \n",
    "        \n",
    "       ####HIDDEN LAYERS\n",
    "        \n",
    "        index_vecor = len(res_vectors) - 4\n",
    "        \n",
    "        layer_index = no_of_layers - 1\n",
    "       \n",
    "        while layer_index > 1:\n",
    "            dzda = self.weights_matrices[layer_index-1].T #Weight between layers\n",
    "            dcda = np.dot(deltaLast, dzda)\n",
    "            dadz = ReLU_derivation(res_vectors[index_vecor])\n",
    "            delta = dcda[:,:-1] * dadz #Take away bias as input to get delta\n",
    "            deltaLast = delta\n",
    "            dcdw = np.dot(res_vectors[index_vecor-1].T,delta)\n",
    "            weight_gradients.append(dcdw)            \n",
    "            layer_index -= 1\n",
    "            index_vecor -= 2\n",
    "            \n",
    "        \n",
    "        return weight_gradients\n",
    "\n",
    "\n",
    "    def MSE(self,yHat, y): ##Cost function Mean squared error\n",
    "        return np.sum((yHat - y)**2) / y.size\n",
    "    \n",
    "    def MSE_prime(self,yHat, y): # Derivative of the cost fucnction\n",
    "        return yHat - y\n",
    "    \n",
    "    \n",
    "    \n",
    "    def cross_entropy(self,output, target):\n",
    "        loss =  target * np.log(output)\n",
    "        return -np.sum(loss)\n",
    "    \n",
    "    \n",
    "    def train_single(self, training, target):\n",
    "        \n",
    "        gradients = self.backward(training, target)\n",
    "        \n",
    "       \n",
    "        weight_index = len(self.weights_matrices) -1\n",
    "        for i in range(len(gradients)):\n",
    "            if self.useL2:\n",
    "                self.weights_matrices[weight_index]  = self.weights_matrices[weight_index] * (1-self.l2Lambda)\n",
    "            \n",
    "            v = (self.previousGradients[i] * self.gamma) + (self.learningRate * gradients[i])\n",
    "            self.previousGradients[i] = v\n",
    "            self.weights_matrices[weight_index] =  self.weights_matrices[weight_index] + v\n",
    "            weight_index -= 1\n",
    "    \n",
    "    \n",
    "    def train(self, data_array, \n",
    "              labels_one_hot_array,\n",
    "              batch_size,\n",
    "              epochs=1,\n",
    "              intermediate_results=False):\n",
    "        \n",
    "        intermediate_weights = []\n",
    "        \n",
    "        \n",
    "        loss_list = []\n",
    "        iterations = []\n",
    "        accuracy_list = []\n",
    "                        \n",
    "        iteration_count = 1\n",
    "        for epoch in range(epochs):  \n",
    "            print(\"Epoch {}\".format(str(epoch+1)), end=\"\")\n",
    "        \n",
    "            for iteration in np.arange(0,len(data_array+1), batch_size): #Move index a batch size for every run\n",
    "                #print(iteration)\n",
    "                start_index = iteration\n",
    "                end_index = iteration+batch_size-1\n",
    "               \n",
    "                features = data_array[start_index : end_index]\n",
    "                targets = labels_one_hot_array[start_index : end_index]\n",
    "                \n",
    "                self.train_single(features, targets) #Train the batch size\n",
    "                                \n",
    "               ##For intermediate evaluation\n",
    "                if ((iteration_count % 120 ) == 0 ): #We pick an iteration number to save the loss abnd accuracy\n",
    "                \n",
    "                    predicted = self.feedForward(X_training_scaled) # get network ouput\n",
    "                  \n",
    "                    \n",
    "                    predicted_encoded = [np.argmax(x) for x in predicted] \n",
    "                    loss = self.cross_entropy(predicted,y_training_one_hot_unscaled) # Changed from MSE\n",
    "                    #loss = self.MSE(predicted_encoded, y_training.flatten())\n",
    "                    loss_list.append(loss)    \n",
    "                    #print(loss)\n",
    "                    acc = self.acc( y_training.flatten(), predicted_encoded)\n",
    "                    accuracy_list.append(acc)\n",
    "              \n",
    "                   \n",
    "                    \n",
    "                    np.set_printoptions(precision=2)\n",
    "                    print(\"Predicted\", predicted[:1])\n",
    "                    print(\"Iteration {0} -  loss: {1:.2f}, accuracy: {2:.2f}\".format(iteration_count, loss,acc, ))\n",
    "            \n",
    "\n",
    "                    iterations.append(iteration_count)                                \n",
    "                \n",
    "                iteration_count += 1\n",
    "            if intermediate_results:\n",
    "                intermediate_weights.append(self.weights_matrices)                \n",
    "            \n",
    "        return intermediate_weights, loss_list, accuracy_list,iterations\n",
    "\n",
    "  \n",
    "    ###Evaluations\n",
    "    \n",
    "    def evaluate(self, actual, predicted):\n",
    "        corrects, wrongs = 0, 0\n",
    "        corrects = len(actual[actual == predicted])\n",
    "        wrongs = len(actual[actual != predicted])\n",
    "        \n",
    "        return corrects, wrongs\n",
    "    \n",
    "    \n",
    "    def acc(self,actual, predicted):\n",
    "        correct, wrongs = self.evaluate(actual, predicted)\n",
    "        \n",
    "        return correct / (correct + wrongs)\n",
    "    \n",
    "    def confusion_matrix(self, actual, predicted):\n",
    "        length = len(np.unique(actual))\n",
    "        width = length\n",
    "        cm = np.zeros((width, length))\n",
    "        for i in range(len(actual)):\n",
    "            cm[actual[i],predicted[i]] += 1\n",
    "        return cm7\n",
    "          \n",
    "    def precision(self, label, confusion_matrix): \n",
    "        col = confusion_matrix[:, label]\n",
    "        return confusion_matrix[label, label] / col.sum()\n",
    "    \n",
    "    def recall(self, label, confusion_matrix):\n",
    "        row = confusion_matrix[label, :]\n",
    "        return confusion_matrix[label, label] / row.sum()\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "inside init weghts\n",
      "inside init weghts\n",
      "inside init weghts\n",
      "[array([[-0.22,  0.02,  0.02,  0.02,  0.02,  0.03,  0.02,  0.02,  0.02,\n",
      "         0.03],\n",
      "       [-0.43,  0.03,  0.04,  0.04,  0.03,  0.05,  0.04,  0.05,  0.05,\n",
      "         0.06],\n",
      "       [-0.37,  0.03,  0.04,  0.03,  0.03,  0.04,  0.03,  0.04,  0.04,\n",
      "         0.05],\n",
      "       [-0.13,  0.01,  0.01,  0.01,  0.01,  0.02,  0.01,  0.01,  0.01,\n",
      "         0.02],\n",
      "       [-0.27,  0.02,  0.03,  0.03,  0.02,  0.03,  0.02,  0.03,  0.03,\n",
      "         0.04],\n",
      "       [-0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,  0.  ,\n",
      "         0.  ],\n",
      "       [-0.26,  0.02,  0.03,  0.02,  0.02,  0.03,  0.02,  0.03,  0.03,\n",
      "         0.03],\n",
      "       [-0.14,  0.01,  0.01,  0.01,  0.01,  0.02,  0.01,  0.01,  0.02,\n",
      "         0.02],\n",
      "       [-0.13,  0.01,  0.01,  0.01,  0.01,  0.02,  0.01,  0.01,  0.01,\n",
      "         0.02],\n",
      "       [-0.06,  0.  ,  0.01,  0.01,  0.  ,  0.01,  0.01,  0.01,  0.01,\n",
      "         0.01],\n",
      "       [-0.22,  0.02,  0.02,  0.02,  0.02,  0.03,  0.02,  0.02,  0.02,\n",
      "         0.03],\n",
      "       [-0.38,  0.03,  0.04,  0.04,  0.03,  0.05,  0.03,  0.04,  0.04,\n",
      "         0.05],\n",
      "       [-0.09,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,  0.01,\n",
      "         0.01],\n",
      "       [-0.14,  0.01,  0.01,  0.01,  0.01,  0.02,  0.01,  0.01,  0.02,\n",
      "         0.02],\n",
      "       [-0.35,  0.03,  0.04,  0.03,  0.03,  0.04,  0.03,  0.04,  0.04,\n",
      "         0.05],\n",
      "       [-0.22,  0.02,  0.02,  0.02,  0.02,  0.03,  0.02,  0.02,  0.02,\n",
      "         0.03],\n",
      "       [-0.84,  0.06,  0.09,  0.08,  0.06,  0.1 ,  0.08,  0.09,  0.09,\n",
      "         0.11]]), array([[ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 9.79e-03, -3.42e-02, -2.38e-02,  7.58e-03, -3.97e-03,  0.00e+00,\n",
      "        -1.99e-02, -2.55e-02,  6.40e-03, -2.38e-02, -1.91e-02, -2.23e-02,\n",
      "         3.18e-04, -6.18e-03, -2.02e-02,  7.68e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.55e-02, -5.41e-02, -3.76e-02,  1.20e-02, -6.29e-03,  0.00e+00,\n",
      "        -3.16e-02, -4.04e-02,  1.01e-02, -3.77e-02, -3.02e-02, -3.53e-02,\n",
      "         5.04e-04, -9.78e-03, -3.19e-02,  1.22e-02],\n",
      "       [ 1.55e-02, -5.41e-02, -3.76e-02,  1.20e-02, -6.29e-03,  0.00e+00,\n",
      "        -3.16e-02, -4.04e-02,  1.01e-02, -3.77e-02, -3.02e-02, -3.53e-02,\n",
      "         5.04e-04, -9.78e-03, -3.19e-02,  1.22e-02],\n",
      "       [ 1.68e-02, -5.87e-02, -4.08e-02,  1.30e-02, -6.82e-03,  0.00e+00,\n",
      "        -3.42e-02, -4.38e-02,  1.10e-02, -4.09e-02, -3.28e-02, -3.83e-02,\n",
      "         5.47e-04, -1.06e-02, -3.46e-02,  1.32e-02],\n",
      "       [ 1.77e-02, -6.18e-02, -4.29e-02,  1.37e-02, -7.18e-03,  0.00e+00,\n",
      "        -3.60e-02, -4.61e-02,  1.16e-02, -4.31e-02, -3.45e-02, -4.03e-02,\n",
      "         5.76e-04, -1.12e-02, -3.64e-02,  1.39e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 1.57e-02, -5.49e-02, -3.81e-02,  1.22e-02, -6.38e-03,  0.00e+00,\n",
      "        -3.20e-02, -4.10e-02,  1.03e-02, -3.82e-02, -3.06e-02, -3.58e-02,\n",
      "         5.11e-04, -9.91e-03, -3.24e-02,  1.23e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.77e-02, -6.18e-02, -4.29e-02,  1.37e-02, -7.18e-03,  0.00e+00,\n",
      "        -3.60e-02, -4.61e-02,  1.16e-02, -4.31e-02, -3.45e-02, -4.03e-02,\n",
      "         5.76e-04, -1.12e-02, -3.64e-02,  1.39e-02],\n",
      "       [ 1.48e-02, -5.18e-02, -3.60e-02,  1.15e-02, -6.02e-03,  0.00e+00,\n",
      "        -3.02e-02, -3.87e-02,  9.70e-03, -3.61e-02, -2.89e-02, -3.38e-02,\n",
      "         4.83e-04, -9.36e-03, -3.06e-02,  1.16e-02],\n",
      "       [ 1.46e-02, -5.10e-02, -3.55e-02,  1.13e-02, -5.93e-03,  0.00e+00,\n",
      "        -2.98e-02, -3.81e-02,  9.55e-03, -3.56e-02, -2.85e-02, -3.33e-02,\n",
      "         4.76e-04, -9.22e-03, -3.01e-02,  1.15e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 3.64e-03, -1.27e-02, -8.84e-03,  2.82e-03, -1.48e-03,  0.00e+00,\n",
      "        -7.42e-03, -9.50e-03,  2.38e-03, -8.87e-03, -7.11e-03, -8.31e-03,\n",
      "         1.19e-04, -2.30e-03, -7.51e-03,  2.86e-03],\n",
      "       [ 3.64e-03, -1.27e-02, -8.84e-03,  2.82e-03, -1.48e-03,  0.00e+00,\n",
      "        -7.42e-03, -9.50e-03,  2.38e-03, -8.87e-03, -7.11e-03, -8.31e-03,\n",
      "         1.19e-04, -2.30e-03, -7.51e-03,  2.86e-03],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 1.57e-02, -5.49e-02, -3.81e-02,  1.22e-02, -6.38e-03,  0.00e+00,\n",
      "        -3.20e-02, -4.10e-02,  1.03e-02, -3.82e-02, -3.06e-02, -3.58e-02,\n",
      "         5.11e-04, -9.91e-03, -3.24e-02,  1.23e-02],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 1.57e-02, -5.49e-02, -3.81e-02,  1.22e-02, -6.38e-03,  0.00e+00,\n",
      "        -3.20e-02, -4.10e-02,  1.03e-02, -3.82e-02, -3.06e-02, -3.58e-02,\n",
      "         5.11e-04, -9.91e-03, -3.24e-02,  1.23e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 1.46e-02, -5.10e-02, -3.55e-02,  1.13e-02, -5.93e-03,  0.00e+00,\n",
      "        -2.98e-02, -3.81e-02,  9.55e-03, -3.56e-02, -2.85e-02, -3.33e-02,\n",
      "         4.76e-04, -9.22e-03, -3.01e-02,  1.15e-02],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 1.42e-02, -4.95e-02, -3.44e-02,  1.10e-02, -5.75e-03,  0.00e+00,\n",
      "        -2.89e-02, -3.69e-02,  9.27e-03, -3.45e-02, -2.77e-02, -3.23e-02,\n",
      "         4.61e-04, -8.94e-03, -2.92e-02,  1.11e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 1.22e-02, -4.26e-02, -2.96e-02,  9.45e-03, -4.95e-03,  0.00e+00,\n",
      "        -2.49e-02, -3.18e-02,  7.98e-03, -2.97e-02, -2.38e-02, -2.78e-02,\n",
      "         3.97e-04, -7.70e-03, -2.51e-02,  9.58e-03],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 1.66e-02, -5.79e-02, -4.03e-02,  1.28e-02, -6.73e-03,  0.00e+00,\n",
      "        -3.38e-02, -4.32e-02,  1.08e-02, -4.04e-02, -3.24e-02, -3.78e-02,\n",
      "         5.40e-04, -1.05e-02, -3.42e-02,  1.30e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 6.06e-03, -2.12e-02, -1.47e-02,  4.69e-03, -2.46e-03,  0.00e+00,\n",
      "        -1.23e-02, -1.58e-02,  3.96e-03, -1.47e-02, -1.18e-02, -1.38e-02,\n",
      "         1.97e-04, -3.82e-03, -1.25e-02,  4.76e-03],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 1.11e-02, -3.88e-02, -2.70e-02,  8.60e-03, -4.51e-03,  0.00e+00,\n",
      "        -2.26e-02, -2.89e-02,  7.26e-03, -2.70e-02, -2.17e-02, -2.53e-02,\n",
      "         3.61e-04, -7.01e-03, -2.29e-02,  8.72e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.40e-02, -4.87e-02, -3.39e-02,  1.08e-02, -5.67e-03,  0.00e+00,\n",
      "        -2.84e-02, -3.64e-02,  9.12e-03, -3.40e-02, -2.72e-02, -3.18e-02,\n",
      "         4.54e-04, -8.81e-03, -2.88e-02,  1.10e-02],\n",
      "       [ 1.77e-02, -6.18e-02, -4.29e-02,  1.37e-02, -7.18e-03,  0.00e+00,\n",
      "        -3.60e-02, -4.61e-02,  1.16e-02, -4.31e-02, -3.45e-02, -4.03e-02,\n",
      "         5.76e-04, -1.12e-02, -3.64e-02,  1.39e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 6.06e-03, -2.12e-02, -1.47e-02,  4.69e-03, -2.46e-03,  0.00e+00,\n",
      "        -1.23e-02, -1.58e-02,  3.96e-03, -1.47e-02, -1.18e-02, -1.38e-02,\n",
      "         1.97e-04, -3.82e-03, -1.25e-02,  4.76e-03],\n",
      "       [ 6.06e-03, -2.12e-02, -1.47e-02,  4.69e-03, -2.46e-03,  0.00e+00,\n",
      "        -1.23e-02, -1.58e-02,  3.96e-03, -1.47e-02, -1.18e-02, -1.38e-02,\n",
      "         1.97e-04, -3.82e-03, -1.25e-02,  4.76e-03],\n",
      "       [ 1.18e-02, -4.11e-02, -2.85e-02,  9.11e-03, -4.77e-03,  0.00e+00,\n",
      "        -2.40e-02, -3.07e-02,  7.69e-03, -2.86e-02, -2.29e-02, -2.68e-02,\n",
      "         3.83e-04, -7.42e-03, -2.42e-02,  9.24e-03],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 1.04e-02, -3.65e-02, -2.54e-02,  8.09e-03, -4.24e-03,  0.00e+00,\n",
      "        -2.13e-02, -2.72e-02,  6.83e-03, -2.54e-02, -2.04e-02, -2.38e-02,\n",
      "         3.40e-04, -6.59e-03, -2.15e-02,  8.20e-03],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 1.13e-02, -3.95e-02, -2.75e-02,  8.77e-03, -4.60e-03,  0.00e+00,\n",
      "        -2.31e-02, -2.95e-02,  7.40e-03, -2.76e-02, -2.21e-02, -2.58e-02,\n",
      "         3.68e-04, -7.14e-03, -2.33e-02,  8.89e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 1.18e-02, -4.11e-02, -2.85e-02,  9.11e-03, -4.77e-03,  0.00e+00,\n",
      "        -2.40e-02, -3.07e-02,  7.69e-03, -2.86e-02, -2.29e-02, -2.68e-02,\n",
      "         3.83e-04, -7.42e-03, -2.42e-02,  9.24e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 5.40e-03, -1.89e-02, -1.31e-02,  4.18e-03, -2.19e-03,  0.00e+00,\n",
      "        -1.10e-02, -1.41e-02,  3.53e-03, -1.31e-02, -1.05e-02, -1.23e-02,\n",
      "         1.76e-04, -3.41e-03, -1.11e-02,  4.24e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 1.20e-02, -4.18e-02, -2.91e-02,  9.28e-03, -4.86e-03,  0.00e+00,\n",
      "        -2.44e-02, -3.12e-02,  7.83e-03, -2.92e-02, -2.34e-02, -2.73e-02,\n",
      "         3.90e-04, -7.56e-03, -2.47e-02,  9.41e-03],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 1.59e-02, -5.56e-02, -3.87e-02,  1.23e-02, -6.47e-03,  0.00e+00,\n",
      "        -3.25e-02, -4.15e-02,  1.04e-02, -3.88e-02, -3.11e-02, -3.63e-02,\n",
      "         5.18e-04, -1.01e-02, -3.28e-02,  1.25e-02],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 5.84e-03, -2.04e-02, -1.42e-02,  4.52e-03, -2.37e-03,  0.00e+00,\n",
      "        -1.19e-02, -1.52e-02,  3.82e-03, -1.42e-02, -1.14e-02, -1.33e-02,\n",
      "         1.90e-04, -3.68e-03, -1.20e-02,  4.58e-03],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 8.91e-03, -3.11e-02, -2.16e-02,  6.90e-03, -3.62e-03,  0.00e+00,\n",
      "        -1.82e-02, -2.32e-02,  5.82e-03, -2.17e-02, -1.74e-02, -2.03e-02,\n",
      "         2.90e-04, -5.62e-03, -1.84e-02,  7.00e-03],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 1.15e-02, -4.03e-02, -2.80e-02,  8.94e-03, -4.69e-03,  0.00e+00,\n",
      "        -2.35e-02, -3.01e-02,  7.55e-03, -2.81e-02, -2.25e-02, -2.63e-02,\n",
      "         3.76e-04, -7.28e-03, -2.38e-02,  9.06e-03],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 1.40e-02, -4.87e-02, -3.39e-02,  1.08e-02, -5.67e-03,  0.00e+00,\n",
      "        -2.84e-02, -3.64e-02,  9.12e-03, -3.40e-02, -2.72e-02, -3.18e-02,\n",
      "         4.54e-04, -8.81e-03, -2.88e-02,  1.10e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 8.91e-03, -3.11e-02, -2.16e-02,  6.90e-03, -3.62e-03,  0.00e+00,\n",
      "        -1.82e-02, -2.32e-02,  5.82e-03, -2.17e-02, -1.74e-02, -2.03e-02,\n",
      "         2.90e-04, -5.62e-03, -1.84e-02,  7.00e-03],\n",
      "       [ 6.28e-03, -2.19e-02, -1.52e-02,  4.86e-03, -2.55e-03,  0.00e+00,\n",
      "        -1.28e-02, -1.64e-02,  4.10e-03, -1.53e-02, -1.22e-02, -1.43e-02,\n",
      "         2.04e-04, -3.96e-03, -1.29e-02,  4.93e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.26e-02, -4.41e-02, -3.07e-02,  9.79e-03, -5.13e-03,  0.00e+00,\n",
      "        -2.58e-02, -3.29e-02,  8.26e-03, -3.08e-02, -2.47e-02, -2.88e-02,\n",
      "         4.11e-04, -7.98e-03, -2.60e-02,  9.92e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.57e-02, -5.49e-02, -3.81e-02,  1.22e-02, -6.38e-03,  0.00e+00,\n",
      "        -3.20e-02, -4.10e-02,  1.03e-02, -3.82e-02, -3.06e-02, -3.58e-02,\n",
      "         5.11e-04, -9.91e-03, -3.24e-02,  1.23e-02],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 1.09e-02, -3.80e-02, -2.64e-02,  8.43e-03, -4.42e-03,  0.00e+00,\n",
      "        -2.22e-02, -2.84e-02,  7.11e-03, -2.65e-02, -2.12e-02, -2.48e-02,\n",
      "         3.54e-04, -6.87e-03, -2.24e-02,  8.55e-03],\n",
      "       [ 1.40e-02, -4.87e-02, -3.39e-02,  1.08e-02, -5.67e-03,  0.00e+00,\n",
      "        -2.84e-02, -3.64e-02,  9.12e-03, -3.40e-02, -2.72e-02, -3.18e-02,\n",
      "         4.54e-04, -8.81e-03, -2.88e-02,  1.10e-02],\n",
      "       [ 1.40e-02, -4.87e-02, -3.39e-02,  1.08e-02, -5.67e-03,  0.00e+00,\n",
      "        -2.84e-02, -3.64e-02,  9.12e-03, -3.40e-02, -2.72e-02, -3.18e-02,\n",
      "         4.54e-04, -8.81e-03, -2.88e-02,  1.10e-02],\n",
      "       [ 1.77e-02, -6.18e-02, -4.29e-02,  1.37e-02, -7.18e-03,  0.00e+00,\n",
      "        -3.60e-02, -4.61e-02,  1.16e-02, -4.31e-02, -3.45e-02, -4.03e-02,\n",
      "         5.76e-04, -1.12e-02, -3.64e-02,  1.39e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 8.91e-03, -3.11e-02, -2.16e-02,  6.90e-03, -3.62e-03,  0.00e+00,\n",
      "        -1.82e-02, -2.32e-02,  5.82e-03, -2.17e-02, -1.74e-02, -2.03e-02,\n",
      "         2.90e-04, -5.62e-03, -1.84e-02,  7.00e-03],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 1.57e-02, -5.49e-02, -3.81e-02,  1.22e-02, -6.38e-03,  0.00e+00,\n",
      "        -3.20e-02, -4.10e-02,  1.03e-02, -3.82e-02, -3.06e-02, -3.58e-02,\n",
      "         5.11e-04, -9.91e-03, -3.24e-02,  1.23e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 6.28e-03, -2.19e-02, -1.52e-02,  4.86e-03, -2.55e-03,  0.00e+00,\n",
      "        -1.28e-02, -1.64e-02,  4.10e-03, -1.53e-02, -1.22e-02, -1.43e-02,\n",
      "         2.04e-04, -3.96e-03, -1.29e-02,  4.93e-03],\n",
      "       [ 1.09e-02, -3.80e-02, -2.64e-02,  8.43e-03, -4.42e-03,  0.00e+00,\n",
      "        -2.22e-02, -2.84e-02,  7.11e-03, -2.65e-02, -2.12e-02, -2.48e-02,\n",
      "         3.54e-04, -6.87e-03, -2.24e-02,  8.55e-03],\n",
      "       [ 1.77e-02, -6.18e-02, -4.29e-02,  1.37e-02, -7.18e-03,  0.00e+00,\n",
      "        -3.60e-02, -4.61e-02,  1.16e-02, -4.31e-02, -3.45e-02, -4.03e-02,\n",
      "         5.76e-04, -1.12e-02, -3.64e-02,  1.39e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.42e-02, -4.95e-02, -3.44e-02,  1.10e-02, -5.75e-03,  0.00e+00,\n",
      "        -2.89e-02, -3.69e-02,  9.27e-03, -3.45e-02, -2.77e-02, -3.23e-02,\n",
      "         4.61e-04, -8.94e-03, -2.92e-02,  1.11e-02],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 1.48e-02, -5.18e-02, -3.60e-02,  1.15e-02, -6.02e-03,  0.00e+00,\n",
      "        -3.02e-02, -3.87e-02,  9.70e-03, -3.61e-02, -2.89e-02, -3.38e-02,\n",
      "         4.83e-04, -9.36e-03, -3.06e-02,  1.16e-02],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 6.06e-03, -2.12e-02, -1.47e-02,  4.69e-03, -2.46e-03,  0.00e+00,\n",
      "        -1.23e-02, -1.58e-02,  3.96e-03, -1.47e-02, -1.18e-02, -1.38e-02,\n",
      "         1.97e-04, -3.82e-03, -1.25e-02,  4.76e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.48e-02, -5.18e-02, -3.60e-02,  1.15e-02, -6.02e-03,  0.00e+00,\n",
      "        -3.02e-02, -3.87e-02,  9.70e-03, -3.61e-02, -2.89e-02, -3.38e-02,\n",
      "         4.83e-04, -9.36e-03, -3.06e-02,  1.16e-02],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.04e-02, -3.65e-02, -2.54e-02,  8.09e-03, -4.24e-03,  0.00e+00,\n",
      "        -2.13e-02, -2.72e-02,  6.83e-03, -2.54e-02, -2.04e-02, -2.38e-02,\n",
      "         3.40e-04, -6.59e-03, -2.15e-02,  8.20e-03],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.09e-02, -3.80e-02, -2.64e-02,  8.43e-03, -4.42e-03,  0.00e+00,\n",
      "        -2.22e-02, -2.84e-02,  7.11e-03, -2.65e-02, -2.12e-02, -2.48e-02,\n",
      "         3.54e-04, -6.87e-03, -2.24e-02,  8.55e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 5.84e-03, -2.04e-02, -1.42e-02,  4.52e-03, -2.37e-03,  0.00e+00,\n",
      "        -1.19e-02, -1.52e-02,  3.82e-03, -1.42e-02, -1.14e-02, -1.33e-02,\n",
      "         1.90e-04, -3.68e-03, -1.20e-02,  4.58e-03],\n",
      "       [ 1.18e-02, -4.11e-02, -2.85e-02,  9.11e-03, -4.77e-03,  0.00e+00,\n",
      "        -2.40e-02, -3.07e-02,  7.69e-03, -2.86e-02, -2.29e-02, -2.68e-02,\n",
      "         3.83e-04, -7.42e-03, -2.42e-02,  9.24e-03],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 1.66e-02, -5.79e-02, -4.03e-02,  1.28e-02, -6.73e-03,  0.00e+00,\n",
      "        -3.38e-02, -4.32e-02,  1.08e-02, -4.04e-02, -3.24e-02, -3.78e-02,\n",
      "         5.40e-04, -1.05e-02, -3.42e-02,  1.30e-02],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 5.18e-03, -1.81e-02, -1.26e-02,  4.01e-03, -2.10e-03,  0.00e+00,\n",
      "        -1.06e-02, -1.35e-02,  3.39e-03, -1.26e-02, -1.01e-02, -1.18e-02,\n",
      "         1.69e-04, -3.27e-03, -1.07e-02,  4.07e-03],\n",
      "       [ 5.18e-03, -1.81e-02, -1.26e-02,  4.01e-03, -2.10e-03,  0.00e+00,\n",
      "        -1.06e-02, -1.35e-02,  3.39e-03, -1.26e-02, -1.01e-02, -1.18e-02,\n",
      "         1.69e-04, -3.27e-03, -1.07e-02,  4.07e-03],\n",
      "       [ 4.30e-03, -1.50e-02, -1.04e-02,  3.33e-03, -1.75e-03,  0.00e+00,\n",
      "        -8.76e-03, -1.12e-02,  2.81e-03, -1.05e-02, -8.39e-03, -9.81e-03,\n",
      "         1.40e-04, -2.71e-03, -8.86e-03,  3.38e-03],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 1.31e-02, -4.57e-02, -3.17e-02,  1.01e-02, -5.31e-03,  0.00e+00,\n",
      "        -2.66e-02, -3.41e-02,  8.55e-03, -3.18e-02, -2.55e-02, -2.98e-02,\n",
      "         4.26e-04, -8.25e-03, -2.69e-02,  1.03e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 9.13e-03, -3.19e-02, -2.22e-02,  7.07e-03, -3.71e-03,  0.00e+00,\n",
      "        -1.86e-02, -2.38e-02,  5.97e-03, -2.22e-02, -1.78e-02, -2.08e-02,\n",
      "         2.97e-04, -5.76e-03, -1.88e-02,  7.17e-03],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 1.46e-02, -5.10e-02, -3.55e-02,  1.13e-02, -5.93e-03,  0.00e+00,\n",
      "        -2.98e-02, -3.81e-02,  9.55e-03, -3.56e-02, -2.85e-02, -3.33e-02,\n",
      "         4.76e-04, -9.22e-03, -3.01e-02,  1.15e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 6.28e-03, -2.19e-02, -1.52e-02,  4.86e-03, -2.55e-03,  0.00e+00,\n",
      "        -1.28e-02, -1.64e-02,  4.10e-03, -1.53e-02, -1.22e-02, -1.43e-02,\n",
      "         2.04e-04, -3.96e-03, -1.29e-02,  4.93e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 5.18e-03, -1.81e-02, -1.26e-02,  4.01e-03, -2.10e-03,  0.00e+00,\n",
      "        -1.06e-02, -1.35e-02,  3.39e-03, -1.26e-02, -1.01e-02, -1.18e-02,\n",
      "         1.69e-04, -3.27e-03, -1.07e-02,  4.07e-03],\n",
      "       [ 1.31e-02, -4.57e-02, -3.17e-02,  1.01e-02, -5.31e-03,  0.00e+00,\n",
      "        -2.66e-02, -3.41e-02,  8.55e-03, -3.18e-02, -2.55e-02, -2.98e-02,\n",
      "         4.26e-04, -8.25e-03, -2.69e-02,  1.03e-02],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 9.13e-03, -3.19e-02, -2.22e-02,  7.07e-03, -3.71e-03,  0.00e+00,\n",
      "        -1.86e-02, -2.38e-02,  5.97e-03, -2.22e-02, -1.78e-02, -2.08e-02,\n",
      "         2.97e-04, -5.76e-03, -1.88e-02,  7.17e-03],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 1.70e-02, -5.95e-02, -4.13e-02,  1.32e-02, -6.91e-03,  0.00e+00,\n",
      "        -3.47e-02, -4.44e-02,  1.11e-02, -4.15e-02, -3.32e-02, -3.88e-02,\n",
      "         5.54e-04, -1.07e-02, -3.51e-02,  1.34e-02],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.59e-02, -5.56e-02, -3.87e-02,  1.23e-02, -6.47e-03,  0.00e+00,\n",
      "        -3.25e-02, -4.15e-02,  1.04e-02, -3.88e-02, -3.11e-02, -3.63e-02,\n",
      "         5.18e-04, -1.01e-02, -3.28e-02,  1.25e-02],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 3.42e-03, -1.20e-02, -8.31e-03,  2.65e-03, -1.39e-03,  0.00e+00,\n",
      "        -6.97e-03, -8.92e-03,  2.24e-03, -8.33e-03, -6.68e-03, -7.81e-03,\n",
      "         1.11e-04, -2.16e-03, -7.05e-03,  2.69e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 1.15e-02, -4.03e-02, -2.80e-02,  8.94e-03, -4.69e-03,  0.00e+00,\n",
      "        -2.35e-02, -3.01e-02,  7.55e-03, -2.81e-02, -2.25e-02, -2.63e-02,\n",
      "         3.76e-04, -7.28e-03, -2.38e-02,  9.06e-03],\n",
      "       [ 1.42e-02, -4.95e-02, -3.44e-02,  1.10e-02, -5.75e-03,  0.00e+00,\n",
      "        -2.89e-02, -3.69e-02,  9.27e-03, -3.45e-02, -2.77e-02, -3.23e-02,\n",
      "         4.61e-04, -8.94e-03, -2.92e-02,  1.11e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 1.15e-02, -4.03e-02, -2.80e-02,  8.94e-03, -4.69e-03,  0.00e+00,\n",
      "        -2.35e-02, -3.01e-02,  7.55e-03, -2.81e-02, -2.25e-02, -2.63e-02,\n",
      "         3.76e-04, -7.28e-03, -2.38e-02,  9.06e-03],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 1.04e-02, -3.65e-02, -2.54e-02,  8.09e-03, -4.24e-03,  0.00e+00,\n",
      "        -2.13e-02, -2.72e-02,  6.83e-03, -2.54e-02, -2.04e-02, -2.38e-02,\n",
      "         3.40e-04, -6.59e-03, -2.15e-02,  8.20e-03],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.48e-02, -5.18e-02, -3.60e-02,  1.15e-02, -6.02e-03,  0.00e+00,\n",
      "        -3.02e-02, -3.87e-02,  9.70e-03, -3.61e-02, -2.89e-02, -3.38e-02,\n",
      "         4.83e-04, -9.36e-03, -3.06e-02,  1.16e-02],\n",
      "       [ 5.40e-03, -1.89e-02, -1.31e-02,  4.18e-03, -2.19e-03,  0.00e+00,\n",
      "        -1.10e-02, -1.41e-02,  3.53e-03, -1.31e-02, -1.05e-02, -1.23e-02,\n",
      "         1.76e-04, -3.41e-03, -1.11e-02,  4.24e-03],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 3.42e-03, -1.20e-02, -8.31e-03,  2.65e-03, -1.39e-03,  0.00e+00,\n",
      "        -6.97e-03, -8.92e-03,  2.24e-03, -8.33e-03, -6.68e-03, -7.81e-03,\n",
      "         1.11e-04, -2.16e-03, -7.05e-03,  2.69e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 1.07e-02, -3.72e-02, -2.59e-02,  8.26e-03, -4.33e-03,  0.00e+00,\n",
      "        -2.17e-02, -2.78e-02,  6.97e-03, -2.60e-02, -2.08e-02, -2.43e-02,\n",
      "         3.47e-04, -6.73e-03, -2.20e-02,  8.37e-03],\n",
      "       [ 1.46e-02, -5.10e-02, -3.55e-02,  1.13e-02, -5.93e-03,  0.00e+00,\n",
      "        -2.98e-02, -3.81e-02,  9.55e-03, -3.56e-02, -2.85e-02, -3.33e-02,\n",
      "         4.76e-04, -9.22e-03, -3.01e-02,  1.15e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.66e-02, -5.79e-02, -4.03e-02,  1.28e-02, -6.73e-03,  0.00e+00,\n",
      "        -3.38e-02, -4.32e-02,  1.08e-02, -4.04e-02, -3.24e-02, -3.78e-02,\n",
      "         5.40e-04, -1.05e-02, -3.42e-02,  1.30e-02],\n",
      "       [ 9.13e-03, -3.19e-02, -2.22e-02,  7.07e-03, -3.71e-03,  0.00e+00,\n",
      "        -1.86e-02, -2.38e-02,  5.97e-03, -2.22e-02, -1.78e-02, -2.08e-02,\n",
      "         2.97e-04, -5.76e-03, -1.88e-02,  7.17e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 1.11e-02, -3.88e-02, -2.70e-02,  8.60e-03, -4.51e-03,  0.00e+00,\n",
      "        -2.26e-02, -2.89e-02,  7.26e-03, -2.70e-02, -2.17e-02, -2.53e-02,\n",
      "         3.61e-04, -7.01e-03, -2.29e-02,  8.72e-03],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 5.84e-03, -2.04e-02, -1.42e-02,  4.52e-03, -2.37e-03,  0.00e+00,\n",
      "        -1.19e-02, -1.52e-02,  3.82e-03, -1.42e-02, -1.14e-02, -1.33e-02,\n",
      "         1.90e-04, -3.68e-03, -1.20e-02,  4.58e-03],\n",
      "       [ 3.42e-03, -1.20e-02, -8.31e-03,  2.65e-03, -1.39e-03,  0.00e+00,\n",
      "        -6.97e-03, -8.92e-03,  2.24e-03, -8.33e-03, -6.68e-03, -7.81e-03,\n",
      "         1.11e-04, -2.16e-03, -7.05e-03,  2.69e-03],\n",
      "       [ 9.13e-03, -3.19e-02, -2.22e-02,  7.07e-03, -3.71e-03,  0.00e+00,\n",
      "        -1.86e-02, -2.38e-02,  5.97e-03, -2.22e-02, -1.78e-02, -2.08e-02,\n",
      "         2.97e-04, -5.76e-03, -1.88e-02,  7.17e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 6.28e-03, -2.19e-02, -1.52e-02,  4.86e-03, -2.55e-03,  0.00e+00,\n",
      "        -1.28e-02, -1.64e-02,  4.10e-03, -1.53e-02, -1.22e-02, -1.43e-02,\n",
      "         2.04e-04, -3.96e-03, -1.29e-02,  4.93e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 1.40e-02, -4.87e-02, -3.39e-02,  1.08e-02, -5.67e-03,  0.00e+00,\n",
      "        -2.84e-02, -3.64e-02,  9.12e-03, -3.40e-02, -2.72e-02, -3.18e-02,\n",
      "         4.54e-04, -8.81e-03, -2.88e-02,  1.10e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.68e-02, -5.87e-02, -4.08e-02,  1.30e-02, -6.82e-03,  0.00e+00,\n",
      "        -3.42e-02, -4.38e-02,  1.10e-02, -4.09e-02, -3.28e-02, -3.83e-02,\n",
      "         5.47e-04, -1.06e-02, -3.46e-02,  1.32e-02],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.11e-02, -3.88e-02, -2.70e-02,  8.60e-03, -4.51e-03,  0.00e+00,\n",
      "        -2.26e-02, -2.89e-02,  7.26e-03, -2.70e-02, -2.17e-02, -2.53e-02,\n",
      "         3.61e-04, -7.01e-03, -2.29e-02,  8.72e-03],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 3.20e-03, -1.12e-02, -7.78e-03,  2.48e-03, -1.30e-03,  0.00e+00,\n",
      "        -6.53e-03, -8.35e-03,  2.09e-03, -7.80e-03, -6.25e-03, -7.31e-03,\n",
      "         1.04e-04, -2.02e-03, -6.60e-03,  2.52e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.26e-02, -4.41e-02, -3.07e-02,  9.79e-03, -5.13e-03,  0.00e+00,\n",
      "        -2.58e-02, -3.29e-02,  8.26e-03, -3.08e-02, -2.47e-02, -2.88e-02,\n",
      "         4.11e-04, -7.98e-03, -2.60e-02,  9.92e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 6.06e-03, -2.12e-02, -1.47e-02,  4.69e-03, -2.46e-03,  0.00e+00,\n",
      "        -1.23e-02, -1.58e-02,  3.96e-03, -1.47e-02, -1.18e-02, -1.38e-02,\n",
      "         1.97e-04, -3.82e-03, -1.25e-02,  4.76e-03],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 6.28e-03, -2.19e-02, -1.52e-02,  4.86e-03, -2.55e-03,  0.00e+00,\n",
      "        -1.28e-02, -1.64e-02,  4.10e-03, -1.53e-02, -1.22e-02, -1.43e-02,\n",
      "         2.04e-04, -3.96e-03, -1.29e-02,  4.93e-03],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.18e-02, -4.11e-02, -2.85e-02,  9.11e-03, -4.77e-03,  0.00e+00,\n",
      "        -2.40e-02, -3.07e-02,  7.69e-03, -2.86e-02, -2.29e-02, -2.68e-02,\n",
      "         3.83e-04, -7.42e-03, -2.42e-02,  9.24e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 1.31e-02, -4.57e-02, -3.17e-02,  1.01e-02, -5.31e-03,  0.00e+00,\n",
      "        -2.66e-02, -3.41e-02,  8.55e-03, -3.18e-02, -2.55e-02, -2.98e-02,\n",
      "         4.26e-04, -8.25e-03, -2.69e-02,  1.03e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 1.46e-02, -5.10e-02, -3.55e-02,  1.13e-02, -5.93e-03,  0.00e+00,\n",
      "        -2.98e-02, -3.81e-02,  9.55e-03, -3.56e-02, -2.85e-02, -3.33e-02,\n",
      "         4.76e-04, -9.22e-03, -3.01e-02,  1.15e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.11e-02, -3.88e-02, -2.70e-02,  8.60e-03, -4.51e-03,  0.00e+00,\n",
      "        -2.26e-02, -2.89e-02,  7.26e-03, -2.70e-02, -2.17e-02, -2.53e-02,\n",
      "         3.61e-04, -7.01e-03, -2.29e-02,  8.72e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 5.40e-03, -1.89e-02, -1.31e-02,  4.18e-03, -2.19e-03,  0.00e+00,\n",
      "        -1.10e-02, -1.41e-02,  3.53e-03, -1.31e-02, -1.05e-02, -1.23e-02,\n",
      "         1.76e-04, -3.41e-03, -1.11e-02,  4.24e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 1.40e-02, -4.87e-02, -3.39e-02,  1.08e-02, -5.67e-03,  0.00e+00,\n",
      "        -2.84e-02, -3.64e-02,  9.12e-03, -3.40e-02, -2.72e-02, -3.18e-02,\n",
      "         4.54e-04, -8.81e-03, -2.88e-02,  1.10e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 6.28e-03, -2.19e-02, -1.52e-02,  4.86e-03, -2.55e-03,  0.00e+00,\n",
      "        -1.28e-02, -1.64e-02,  4.10e-03, -1.53e-02, -1.22e-02, -1.43e-02,\n",
      "         2.04e-04, -3.96e-03, -1.29e-02,  4.93e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.29e-02, -4.49e-02, -3.12e-02,  9.96e-03, -5.22e-03,  0.00e+00,\n",
      "        -2.62e-02, -3.35e-02,  8.41e-03, -3.13e-02, -2.51e-02, -2.93e-02,\n",
      "         4.18e-04, -8.11e-03, -2.65e-02,  1.01e-02],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 1.31e-02, -4.57e-02, -3.17e-02,  1.01e-02, -5.31e-03,  0.00e+00,\n",
      "        -2.66e-02, -3.41e-02,  8.55e-03, -3.18e-02, -2.55e-02, -2.98e-02,\n",
      "         4.26e-04, -8.25e-03, -2.69e-02,  1.03e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.68e-02, -5.87e-02, -4.08e-02,  1.30e-02, -6.82e-03,  0.00e+00,\n",
      "        -3.42e-02, -4.38e-02,  1.10e-02, -4.09e-02, -3.28e-02, -3.83e-02,\n",
      "         5.47e-04, -1.06e-02, -3.46e-02,  1.32e-02],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 1.20e-02, -4.18e-02, -2.91e-02,  9.28e-03, -4.86e-03,  0.00e+00,\n",
      "        -2.44e-02, -3.12e-02,  7.83e-03, -2.92e-02, -2.34e-02, -2.73e-02,\n",
      "         3.90e-04, -7.56e-03, -2.47e-02,  9.41e-03],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.20e-02, -4.18e-02, -2.91e-02,  9.28e-03, -4.86e-03,  0.00e+00,\n",
      "        -2.44e-02, -3.12e-02,  7.83e-03, -2.92e-02, -2.34e-02, -2.73e-02,\n",
      "         3.90e-04, -7.56e-03, -2.47e-02,  9.41e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 1.57e-02, -5.49e-02, -3.81e-02,  1.22e-02, -6.38e-03,  0.00e+00,\n",
      "        -3.20e-02, -4.10e-02,  1.03e-02, -3.82e-02, -3.06e-02, -3.58e-02,\n",
      "         5.11e-04, -9.91e-03, -3.24e-02,  1.23e-02],\n",
      "       [ 5.18e-03, -1.81e-02, -1.26e-02,  4.01e-03, -2.10e-03,  0.00e+00,\n",
      "        -1.06e-02, -1.35e-02,  3.39e-03, -1.26e-02, -1.01e-02, -1.18e-02,\n",
      "         1.69e-04, -3.27e-03, -1.07e-02,  4.07e-03],\n",
      "       [ 3.42e-03, -1.20e-02, -8.31e-03,  2.65e-03, -1.39e-03,  0.00e+00,\n",
      "        -6.97e-03, -8.92e-03,  2.24e-03, -8.33e-03, -6.68e-03, -7.81e-03,\n",
      "         1.11e-04, -2.16e-03, -7.05e-03,  2.69e-03],\n",
      "       [ 3.64e-03, -1.27e-02, -8.84e-03,  2.82e-03, -1.48e-03,  0.00e+00,\n",
      "        -7.42e-03, -9.50e-03,  2.38e-03, -8.87e-03, -7.11e-03, -8.31e-03,\n",
      "         1.19e-04, -2.30e-03, -7.51e-03,  2.86e-03],\n",
      "       [ 4.30e-03, -1.50e-02, -1.04e-02,  3.33e-03, -1.75e-03,  0.00e+00,\n",
      "        -8.76e-03, -1.12e-02,  2.81e-03, -1.05e-02, -8.39e-03, -9.81e-03,\n",
      "         1.40e-04, -2.71e-03, -8.86e-03,  3.38e-03],\n",
      "       [ 1.18e-02, -4.11e-02, -2.85e-02,  9.11e-03, -4.77e-03,  0.00e+00,\n",
      "        -2.40e-02, -3.07e-02,  7.69e-03, -2.86e-02, -2.29e-02, -2.68e-02,\n",
      "         3.83e-04, -7.42e-03, -2.42e-02,  9.24e-03],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.11e-02, -3.88e-02, -2.70e-02,  8.60e-03, -4.51e-03,  0.00e+00,\n",
      "        -2.26e-02, -2.89e-02,  7.26e-03, -2.70e-02, -2.17e-02, -2.53e-02,\n",
      "         3.61e-04, -7.01e-03, -2.29e-02,  8.72e-03],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.22e-02, -4.26e-02, -2.96e-02,  9.45e-03, -4.95e-03,  0.00e+00,\n",
      "        -2.49e-02, -3.18e-02,  7.98e-03, -2.97e-02, -2.38e-02, -2.78e-02,\n",
      "         3.97e-04, -7.70e-03, -2.51e-02,  9.58e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 1.42e-02, -4.95e-02, -3.44e-02,  1.10e-02, -5.75e-03,  0.00e+00,\n",
      "        -2.89e-02, -3.69e-02,  9.27e-03, -3.45e-02, -2.77e-02, -3.23e-02,\n",
      "         4.61e-04, -8.94e-03, -2.92e-02,  1.11e-02],\n",
      "       [ 1.57e-02, -5.49e-02, -3.81e-02,  1.22e-02, -6.38e-03,  0.00e+00,\n",
      "        -3.20e-02, -4.10e-02,  1.03e-02, -3.82e-02, -3.06e-02, -3.58e-02,\n",
      "         5.11e-04, -9.91e-03, -3.24e-02,  1.23e-02],\n",
      "       [ 1.29e-02, -4.49e-02, -3.12e-02,  9.96e-03, -5.22e-03,  0.00e+00,\n",
      "        -2.62e-02, -3.35e-02,  8.41e-03, -3.13e-02, -2.51e-02, -2.93e-02,\n",
      "         4.18e-04, -8.11e-03, -2.65e-02,  1.01e-02],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 8.91e-03, -3.11e-02, -2.16e-02,  6.90e-03, -3.62e-03,  0.00e+00,\n",
      "        -1.82e-02, -2.32e-02,  5.82e-03, -2.17e-02, -1.74e-02, -2.03e-02,\n",
      "         2.90e-04, -5.62e-03, -1.84e-02,  7.00e-03],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 1.22e-02, -4.26e-02, -2.96e-02,  9.45e-03, -4.95e-03,  0.00e+00,\n",
      "        -2.49e-02, -3.18e-02,  7.98e-03, -2.97e-02, -2.38e-02, -2.78e-02,\n",
      "         3.97e-04, -7.70e-03, -2.51e-02,  9.58e-03],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 1.15e-02, -4.03e-02, -2.80e-02,  8.94e-03, -4.69e-03,  0.00e+00,\n",
      "        -2.35e-02, -3.01e-02,  7.55e-03, -2.81e-02, -2.25e-02, -2.63e-02,\n",
      "         3.76e-04, -7.28e-03, -2.38e-02,  9.06e-03],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.70e-02, -5.95e-02, -4.13e-02,  1.32e-02, -6.91e-03,  0.00e+00,\n",
      "        -3.47e-02, -4.44e-02,  1.11e-02, -4.15e-02, -3.32e-02, -3.88e-02,\n",
      "         5.54e-04, -1.07e-02, -3.51e-02,  1.34e-02],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 4.30e-03, -1.50e-02, -1.04e-02,  3.33e-03, -1.75e-03,  0.00e+00,\n",
      "        -8.76e-03, -1.12e-02,  2.81e-03, -1.05e-02, -8.39e-03, -9.81e-03,\n",
      "         1.40e-04, -2.71e-03, -8.86e-03,  3.38e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 3.42e-03, -1.20e-02, -8.31e-03,  2.65e-03, -1.39e-03,  0.00e+00,\n",
      "        -6.97e-03, -8.92e-03,  2.24e-03, -8.33e-03, -6.68e-03, -7.81e-03,\n",
      "         1.11e-04, -2.16e-03, -7.05e-03,  2.69e-03],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 8.91e-03, -3.11e-02, -2.16e-02,  6.90e-03, -3.62e-03,  0.00e+00,\n",
      "        -1.82e-02, -2.32e-02,  5.82e-03, -2.17e-02, -1.74e-02, -2.03e-02,\n",
      "         2.90e-04, -5.62e-03, -1.84e-02,  7.00e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.46e-02, -5.10e-02, -3.55e-02,  1.13e-02, -5.93e-03,  0.00e+00,\n",
      "        -2.98e-02, -3.81e-02,  9.55e-03, -3.56e-02, -2.85e-02, -3.33e-02,\n",
      "         4.76e-04, -9.22e-03, -3.01e-02,  1.15e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 1.20e-02, -4.18e-02, -2.91e-02,  9.28e-03, -4.86e-03,  0.00e+00,\n",
      "        -2.44e-02, -3.12e-02,  7.83e-03, -2.92e-02, -2.34e-02, -2.73e-02,\n",
      "         3.90e-04, -7.56e-03, -2.47e-02,  9.41e-03],\n",
      "       [ 1.04e-02, -3.65e-02, -2.54e-02,  8.09e-03, -4.24e-03,  0.00e+00,\n",
      "        -2.13e-02, -2.72e-02,  6.83e-03, -2.54e-02, -2.04e-02, -2.38e-02,\n",
      "         3.40e-04, -6.59e-03, -2.15e-02,  8.20e-03],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 1.07e-02, -3.72e-02, -2.59e-02,  8.26e-03, -4.33e-03,  0.00e+00,\n",
      "        -2.17e-02, -2.78e-02,  6.97e-03, -2.60e-02, -2.08e-02, -2.43e-02,\n",
      "         3.47e-04, -6.73e-03, -2.20e-02,  8.37e-03],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.04e-02, -3.65e-02, -2.54e-02,  8.09e-03, -4.24e-03,  0.00e+00,\n",
      "        -2.13e-02, -2.72e-02,  6.83e-03, -2.54e-02, -2.04e-02, -2.38e-02,\n",
      "         3.40e-04, -6.59e-03, -2.15e-02,  8.20e-03],\n",
      "       [ 3.64e-03, -1.27e-02, -8.84e-03,  2.82e-03, -1.48e-03,  0.00e+00,\n",
      "        -7.42e-03, -9.50e-03,  2.38e-03, -8.87e-03, -7.11e-03, -8.31e-03,\n",
      "         1.19e-04, -2.30e-03, -7.51e-03,  2.86e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 4.30e-03, -1.50e-02, -1.04e-02,  3.33e-03, -1.75e-03,  0.00e+00,\n",
      "        -8.76e-03, -1.12e-02,  2.81e-03, -1.05e-02, -8.39e-03, -9.81e-03,\n",
      "         1.40e-04, -2.71e-03, -8.86e-03,  3.38e-03],\n",
      "       [ 5.40e-03, -1.89e-02, -1.31e-02,  4.18e-03, -2.19e-03,  0.00e+00,\n",
      "        -1.10e-02, -1.41e-02,  3.53e-03, -1.31e-02, -1.05e-02, -1.23e-02,\n",
      "         1.76e-04, -3.41e-03, -1.11e-02,  4.24e-03],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 6.06e-03, -2.12e-02, -1.47e-02,  4.69e-03, -2.46e-03,  0.00e+00,\n",
      "        -1.23e-02, -1.58e-02,  3.96e-03, -1.47e-02, -1.18e-02, -1.38e-02,\n",
      "         1.97e-04, -3.82e-03, -1.25e-02,  4.76e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.55e-02, -5.41e-02, -3.76e-02,  1.20e-02, -6.29e-03,  0.00e+00,\n",
      "        -3.16e-02, -4.04e-02,  1.01e-02, -3.77e-02, -3.02e-02, -3.53e-02,\n",
      "         5.04e-04, -9.78e-03, -3.19e-02,  1.22e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.79e-02, -6.25e-02, -4.35e-02,  1.39e-02, -7.27e-03,  0.00e+00,\n",
      "        -3.65e-02, -4.67e-02,  1.17e-02, -4.36e-02, -3.49e-02, -4.08e-02,\n",
      "         5.83e-04, -1.13e-02, -3.69e-02,  1.41e-02],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 1.33e-02, -4.64e-02, -3.23e-02,  1.03e-02, -5.40e-03,  0.00e+00,\n",
      "        -2.71e-02, -3.47e-02,  8.69e-03, -3.24e-02, -2.59e-02, -3.03e-02,\n",
      "         4.33e-04, -8.39e-03, -2.74e-02,  1.04e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.20e-02, -4.18e-02, -2.91e-02,  9.28e-03, -4.86e-03,  0.00e+00,\n",
      "        -2.44e-02, -3.12e-02,  7.83e-03, -2.92e-02, -2.34e-02, -2.73e-02,\n",
      "         3.90e-04, -7.56e-03, -2.47e-02,  9.41e-03],\n",
      "       [ 3.42e-03, -1.20e-02, -8.31e-03,  2.65e-03, -1.39e-03,  0.00e+00,\n",
      "        -6.97e-03, -8.92e-03,  2.24e-03, -8.33e-03, -6.68e-03, -7.81e-03,\n",
      "         1.11e-04, -2.16e-03, -7.05e-03,  2.69e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 1.35e-02, -4.72e-02, -3.28e-02,  1.05e-02, -5.49e-03,  0.00e+00,\n",
      "        -2.75e-02, -3.52e-02,  8.84e-03, -3.29e-02, -2.64e-02, -3.08e-02,\n",
      "         4.40e-04, -8.53e-03, -2.78e-02,  1.06e-02],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.07e-02, -3.72e-02, -2.59e-02,  8.26e-03, -4.33e-03,  0.00e+00,\n",
      "        -2.17e-02, -2.78e-02,  6.97e-03, -2.60e-02, -2.08e-02, -2.43e-02,\n",
      "         3.47e-04, -6.73e-03, -2.20e-02,  8.37e-03],\n",
      "       [ 6.71e-03, -2.34e-02, -1.63e-02,  5.20e-03, -2.73e-03,  0.00e+00,\n",
      "        -1.37e-02, -1.75e-02,  4.39e-03, -1.63e-02, -1.31e-02, -1.53e-02,\n",
      "         2.19e-04, -4.24e-03, -1.38e-02,  5.27e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.04e-02, -3.65e-02, -2.54e-02,  8.09e-03, -4.24e-03,  0.00e+00,\n",
      "        -2.13e-02, -2.72e-02,  6.83e-03, -2.54e-02, -2.04e-02, -2.38e-02,\n",
      "         3.40e-04, -6.59e-03, -2.15e-02,  8.20e-03],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.29e-02, -4.49e-02, -3.12e-02,  9.96e-03, -5.22e-03,  0.00e+00,\n",
      "        -2.62e-02, -3.35e-02,  8.41e-03, -3.13e-02, -2.51e-02, -2.93e-02,\n",
      "         4.18e-04, -8.11e-03, -2.65e-02,  1.01e-02],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 3.64e-03, -1.27e-02, -8.84e-03,  2.82e-03, -1.48e-03,  0.00e+00,\n",
      "        -7.42e-03, -9.50e-03,  2.38e-03, -8.87e-03, -7.11e-03, -8.31e-03,\n",
      "         1.19e-04, -2.30e-03, -7.51e-03,  2.86e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 5.40e-03, -1.89e-02, -1.31e-02,  4.18e-03, -2.19e-03,  0.00e+00,\n",
      "        -1.10e-02, -1.41e-02,  3.53e-03, -1.31e-02, -1.05e-02, -1.23e-02,\n",
      "         1.76e-04, -3.41e-03, -1.11e-02,  4.24e-03],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 1.31e-02, -4.57e-02, -3.17e-02,  1.01e-02, -5.31e-03,  0.00e+00,\n",
      "        -2.66e-02, -3.41e-02,  8.55e-03, -3.18e-02, -2.55e-02, -2.98e-02,\n",
      "         4.26e-04, -8.25e-03, -2.69e-02,  1.03e-02],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 5.40e-03, -1.89e-02, -1.31e-02,  4.18e-03, -2.19e-03,  0.00e+00,\n",
      "        -1.10e-02, -1.41e-02,  3.53e-03, -1.31e-02, -1.05e-02, -1.23e-02,\n",
      "         1.76e-04, -3.41e-03, -1.11e-02,  4.24e-03],\n",
      "       [ 3.20e-03, -1.12e-02, -7.78e-03,  2.48e-03, -1.30e-03,  0.00e+00,\n",
      "        -6.53e-03, -8.35e-03,  2.09e-03, -7.80e-03, -6.25e-03, -7.31e-03,\n",
      "         1.04e-04, -2.02e-03, -6.60e-03,  2.52e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.18e-02, -4.11e-02, -2.85e-02,  9.11e-03, -4.77e-03,  0.00e+00,\n",
      "        -2.40e-02, -3.07e-02,  7.69e-03, -2.86e-02, -2.29e-02, -2.68e-02,\n",
      "         3.83e-04, -7.42e-03, -2.42e-02,  9.24e-03],\n",
      "       [ 8.03e-03, -2.80e-02, -1.95e-02,  6.22e-03, -3.26e-03,  0.00e+00,\n",
      "        -1.64e-02, -2.09e-02,  5.25e-03, -1.96e-02, -1.57e-02, -1.83e-02,\n",
      "         2.61e-04, -5.07e-03, -1.65e-02,  6.31e-03],\n",
      "       [ 1.04e-02, -3.65e-02, -2.54e-02,  8.09e-03, -4.24e-03,  0.00e+00,\n",
      "        -2.13e-02, -2.72e-02,  6.83e-03, -2.54e-02, -2.04e-02, -2.38e-02,\n",
      "         3.40e-04, -6.59e-03, -2.15e-02,  8.20e-03],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 6.28e-03, -2.19e-02, -1.52e-02,  4.86e-03, -2.55e-03,  0.00e+00,\n",
      "        -1.28e-02, -1.64e-02,  4.10e-03, -1.53e-02, -1.22e-02, -1.43e-02,\n",
      "         2.04e-04, -3.96e-03, -1.29e-02,  4.93e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 1.07e-02, -3.72e-02, -2.59e-02,  8.26e-03, -4.33e-03,  0.00e+00,\n",
      "        -2.17e-02, -2.78e-02,  6.97e-03, -2.60e-02, -2.08e-02, -2.43e-02,\n",
      "         3.47e-04, -6.73e-03, -2.20e-02,  8.37e-03],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 6.06e-03, -2.12e-02, -1.47e-02,  4.69e-03, -2.46e-03,  0.00e+00,\n",
      "        -1.23e-02, -1.58e-02,  3.96e-03, -1.47e-02, -1.18e-02, -1.38e-02,\n",
      "         1.97e-04, -3.82e-03, -1.25e-02,  4.76e-03],\n",
      "       [ 3.20e-03, -1.12e-02, -7.78e-03,  2.48e-03, -1.30e-03,  0.00e+00,\n",
      "        -6.53e-03, -8.35e-03,  2.09e-03, -7.80e-03, -6.25e-03, -7.31e-03,\n",
      "         1.04e-04, -2.02e-03, -6.60e-03,  2.52e-03],\n",
      "       [ 4.52e-03, -1.58e-02, -1.10e-02,  3.50e-03, -1.84e-03,  0.00e+00,\n",
      "        -9.21e-03, -1.18e-02,  2.96e-03, -1.10e-02, -8.82e-03, -1.03e-02,\n",
      "         1.47e-04, -2.85e-03, -9.31e-03,  3.55e-03],\n",
      "       [ 3.86e-03, -1.35e-02, -9.37e-03,  2.99e-03, -1.57e-03,  0.00e+00,\n",
      "        -7.87e-03, -1.01e-02,  2.52e-03, -9.40e-03, -7.53e-03, -8.81e-03,\n",
      "         1.26e-04, -2.44e-03, -7.96e-03,  3.03e-03],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.10e-02, -7.33e-02, -5.09e-02,  1.62e-02, -8.52e-03,  0.00e+00,\n",
      "        -4.27e-02, -5.47e-02,  1.37e-02, -5.11e-02, -4.09e-02, -4.78e-02,\n",
      "         6.83e-04, -1.32e-02, -4.32e-02,  1.65e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 8.47e-03, -2.96e-02, -2.06e-02,  6.56e-03, -3.44e-03,  0.00e+00,\n",
      "        -1.73e-02, -2.21e-02,  5.54e-03, -2.06e-02, -1.65e-02, -1.93e-02,\n",
      "         2.76e-04, -5.34e-03, -1.75e-02,  6.65e-03],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 1.20e-02, -4.18e-02, -2.91e-02,  9.28e-03, -4.86e-03,  0.00e+00,\n",
      "        -2.44e-02, -3.12e-02,  7.83e-03, -2.92e-02, -2.34e-02, -2.73e-02,\n",
      "         3.90e-04, -7.56e-03, -2.47e-02,  9.41e-03],\n",
      "       [ 6.93e-03, -2.42e-02, -1.68e-02,  5.37e-03, -2.81e-03,  0.00e+00,\n",
      "        -1.41e-02, -1.81e-02,  4.53e-03, -1.69e-02, -1.35e-02, -1.58e-02,\n",
      "         2.26e-04, -4.38e-03, -1.43e-02,  5.44e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 9.13e-03, -3.19e-02, -2.22e-02,  7.07e-03, -3.71e-03,  0.00e+00,\n",
      "        -1.86e-02, -2.38e-02,  5.97e-03, -2.22e-02, -1.78e-02, -2.08e-02,\n",
      "         2.97e-04, -5.76e-03, -1.88e-02,  7.17e-03],\n",
      "       [ 1.68e-02, -5.87e-02, -4.08e-02,  1.30e-02, -6.82e-03,  0.00e+00,\n",
      "        -3.42e-02, -4.38e-02,  1.10e-02, -4.09e-02, -3.28e-02, -3.83e-02,\n",
      "         5.47e-04, -1.06e-02, -3.46e-02,  1.32e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 5.40e-03, -1.89e-02, -1.31e-02,  4.18e-03, -2.19e-03,  0.00e+00,\n",
      "        -1.10e-02, -1.41e-02,  3.53e-03, -1.31e-02, -1.05e-02, -1.23e-02,\n",
      "         1.76e-04, -3.41e-03, -1.11e-02,  4.24e-03],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.66e-02, -5.79e-02, -4.03e-02,  1.28e-02, -6.73e-03,  0.00e+00,\n",
      "        -3.38e-02, -4.32e-02,  1.08e-02, -4.04e-02, -3.24e-02, -3.78e-02,\n",
      "         5.40e-04, -1.05e-02, -3.42e-02,  1.30e-02],\n",
      "       [ 8.25e-03, -2.88e-02, -2.00e-02,  6.39e-03, -3.35e-03,  0.00e+00,\n",
      "        -1.68e-02, -2.15e-02,  5.39e-03, -2.01e-02, -1.61e-02, -1.88e-02,\n",
      "         2.68e-04, -5.21e-03, -1.70e-02,  6.48e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.09e-02, -3.80e-02, -2.64e-02,  8.43e-03, -4.42e-03,  0.00e+00,\n",
      "        -2.22e-02, -2.84e-02,  7.11e-03, -2.65e-02, -2.12e-02, -2.48e-02,\n",
      "         3.54e-04, -6.87e-03, -2.24e-02,  8.55e-03],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 1.13e-02, -3.95e-02, -2.75e-02,  8.77e-03, -4.60e-03,  0.00e+00,\n",
      "        -2.31e-02, -2.95e-02,  7.40e-03, -2.76e-02, -2.21e-02, -2.58e-02,\n",
      "         3.68e-04, -7.14e-03, -2.33e-02,  8.89e-03],\n",
      "       [ 6.49e-03, -2.27e-02, -1.58e-02,  5.03e-03, -2.64e-03,  0.00e+00,\n",
      "        -1.32e-02, -1.69e-02,  4.25e-03, -1.58e-02, -1.27e-02, -1.48e-02,\n",
      "         2.11e-04, -4.10e-03, -1.34e-02,  5.10e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 9.79e-03, -3.42e-02, -2.38e-02,  7.58e-03, -3.97e-03,  0.00e+00,\n",
      "        -1.99e-02, -2.55e-02,  6.40e-03, -2.38e-02, -1.91e-02, -2.23e-02,\n",
      "         3.18e-04, -6.18e-03, -2.02e-02,  7.68e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.18e-02, -4.11e-02, -2.85e-02,  9.11e-03, -4.77e-03,  0.00e+00,\n",
      "        -2.40e-02, -3.07e-02,  7.69e-03, -2.86e-02, -2.29e-02, -2.68e-02,\n",
      "         3.83e-04, -7.42e-03, -2.42e-02,  9.24e-03],\n",
      "       [ 3.20e-03, -1.12e-02, -7.78e-03,  2.48e-03, -1.30e-03,  0.00e+00,\n",
      "        -6.53e-03, -8.35e-03,  2.09e-03, -7.80e-03, -6.25e-03, -7.31e-03,\n",
      "         1.04e-04, -2.02e-03, -6.60e-03,  2.52e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.26e-02, -4.41e-02, -3.07e-02,  9.79e-03, -5.13e-03,  0.00e+00,\n",
      "        -2.58e-02, -3.29e-02,  8.26e-03, -3.08e-02, -2.47e-02, -2.88e-02,\n",
      "         4.11e-04, -7.98e-03, -2.60e-02,  9.92e-03],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 1.00e-02, -3.49e-02, -2.43e-02,  7.75e-03, -4.06e-03,  0.00e+00,\n",
      "        -2.04e-02, -2.61e-02,  6.54e-03, -2.44e-02, -1.95e-02, -2.28e-02,\n",
      "         3.26e-04, -6.31e-03, -2.06e-02,  7.86e-03],\n",
      "       [ 1.48e-02, -5.18e-02, -3.60e-02,  1.15e-02, -6.02e-03,  0.00e+00,\n",
      "        -3.02e-02, -3.87e-02,  9.70e-03, -3.61e-02, -2.89e-02, -3.38e-02,\n",
      "         4.83e-04, -9.36e-03, -3.06e-02,  1.16e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 1.07e-02, -3.72e-02, -2.59e-02,  8.26e-03, -4.33e-03,  0.00e+00,\n",
      "        -2.17e-02, -2.78e-02,  6.97e-03, -2.60e-02, -2.08e-02, -2.43e-02,\n",
      "         3.47e-04, -6.73e-03, -2.20e-02,  8.37e-03],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 1.53e-02, -5.33e-02, -3.71e-02,  1.18e-02, -6.20e-03,  0.00e+00,\n",
      "        -3.11e-02, -3.98e-02,  9.98e-03, -3.72e-02, -2.98e-02, -3.48e-02,\n",
      "         4.97e-04, -9.64e-03, -3.15e-02,  1.20e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 4.08e-03, -1.43e-02, -9.91e-03,  3.16e-03, -1.66e-03,  0.00e+00,\n",
      "        -8.32e-03, -1.06e-02,  2.67e-03, -9.94e-03, -7.96e-03, -9.31e-03,\n",
      "         1.33e-04, -2.58e-03, -8.41e-03,  3.20e-03],\n",
      "       [ 4.74e-03, -1.66e-02, -1.15e-02,  3.67e-03, -1.92e-03,  0.00e+00,\n",
      "        -9.66e-03, -1.24e-02,  3.10e-03, -1.15e-02, -9.25e-03, -1.08e-02,\n",
      "         1.54e-04, -2.99e-03, -9.77e-03,  3.72e-03],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.40e-02, -8.40e-02, -5.84e-02,  1.86e-02, -9.76e-03,  0.00e+00,\n",
      "        -4.90e-02, -6.27e-02,  1.57e-02, -5.85e-02, -4.69e-02, -5.49e-02,\n",
      "         7.83e-04, -1.52e-02, -4.95e-02,  1.89e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 9.57e-03, -3.34e-02, -2.32e-02,  7.41e-03, -3.88e-03,  0.00e+00,\n",
      "        -1.95e-02, -2.49e-02,  6.25e-03, -2.33e-02, -1.87e-02, -2.18e-02,\n",
      "         3.11e-04, -6.04e-03, -1.97e-02,  7.51e-03],\n",
      "       [ 7.15e-03, -2.50e-02, -1.74e-02,  5.54e-03, -2.90e-03,  0.00e+00,\n",
      "        -1.46e-02, -1.86e-02,  4.68e-03, -1.74e-02, -1.40e-02, -1.63e-02,\n",
      "         2.33e-04, -4.51e-03, -1.47e-02,  5.62e-03],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 8.91e-03, -3.11e-02, -2.16e-02,  6.90e-03, -3.62e-03,  0.00e+00,\n",
      "        -1.82e-02, -2.32e-02,  5.82e-03, -2.17e-02, -1.74e-02, -2.03e-02,\n",
      "         2.90e-04, -5.62e-03, -1.84e-02,  7.00e-03],\n",
      "       [ 8.69e-03, -3.03e-02, -2.11e-02,  6.73e-03, -3.53e-03,  0.00e+00,\n",
      "        -1.77e-02, -2.26e-02,  5.68e-03, -2.12e-02, -1.70e-02, -1.98e-02,\n",
      "         2.83e-04, -5.48e-03, -1.79e-02,  6.82e-03],\n",
      "       [ 8.91e-03, -3.11e-02, -2.16e-02,  6.90e-03, -3.62e-03,  0.00e+00,\n",
      "        -1.82e-02, -2.32e-02,  5.82e-03, -2.17e-02, -1.74e-02, -2.03e-02,\n",
      "         2.90e-04, -5.62e-03, -1.84e-02,  7.00e-03],\n",
      "       [ 1.15e-02, -4.03e-02, -2.80e-02,  8.94e-03, -4.69e-03,  0.00e+00,\n",
      "        -2.35e-02, -3.01e-02,  7.55e-03, -2.81e-02, -2.25e-02, -2.63e-02,\n",
      "         3.76e-04, -7.28e-03, -2.38e-02,  9.06e-03],\n",
      "       [ 1.02e-02, -3.57e-02, -2.48e-02,  7.92e-03, -4.15e-03,  0.00e+00,\n",
      "        -2.08e-02, -2.67e-02,  6.68e-03, -2.49e-02, -1.99e-02, -2.33e-02,\n",
      "         3.33e-04, -6.45e-03, -2.11e-02,  8.03e-03],\n",
      "       [ 7.59e-03, -2.65e-02, -1.84e-02,  5.88e-03, -3.08e-03,  0.00e+00,\n",
      "        -1.55e-02, -1.98e-02,  4.96e-03, -1.85e-02, -1.48e-02, -1.73e-02,\n",
      "         2.47e-04, -4.79e-03, -1.56e-02,  5.96e-03],\n",
      "       [ 7.81e-03, -2.73e-02, -1.90e-02,  6.05e-03, -3.17e-03,  0.00e+00,\n",
      "        -1.59e-02, -2.04e-02,  5.11e-03, -1.90e-02, -1.52e-02, -1.78e-02,\n",
      "         2.54e-04, -4.93e-03, -1.61e-02,  6.13e-03],\n",
      "       [ 1.13e-02, -3.95e-02, -2.75e-02,  8.77e-03, -4.60e-03,  0.00e+00,\n",
      "        -2.31e-02, -2.95e-02,  7.40e-03, -2.76e-02, -2.21e-02, -2.58e-02,\n",
      "         3.68e-04, -7.14e-03, -2.33e-02,  8.89e-03],\n",
      "       [ 1.29e-02, -4.49e-02, -3.12e-02,  9.96e-03, -5.22e-03,  0.00e+00,\n",
      "        -2.62e-02, -3.35e-02,  8.41e-03, -3.13e-02, -2.51e-02, -2.93e-02,\n",
      "         4.18e-04, -8.11e-03, -2.65e-02,  1.01e-02],\n",
      "       [ 1.72e-02, -6.02e-02, -4.19e-02,  1.34e-02, -7.00e-03,  0.00e+00,\n",
      "        -3.51e-02, -4.50e-02,  1.13e-02, -4.20e-02, -3.36e-02, -3.93e-02,\n",
      "         5.61e-04, -1.09e-02, -3.55e-02,  1.35e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.75e-02, -6.10e-02, -4.24e-02,  1.35e-02, -7.09e-03,  0.00e+00,\n",
      "        -3.56e-02, -4.55e-02,  1.14e-02, -4.25e-02, -3.41e-02, -3.98e-02,\n",
      "         5.68e-04, -1.10e-02, -3.60e-02,  1.37e-02],\n",
      "       [ 1.66e-02, -5.79e-02, -4.03e-02,  1.28e-02, -6.73e-03,  0.00e+00,\n",
      "        -3.38e-02, -4.32e-02,  1.08e-02, -4.04e-02, -3.24e-02, -3.78e-02,\n",
      "         5.40e-04, -1.05e-02, -3.42e-02,  1.30e-02],\n",
      "       [ 9.35e-03, -3.26e-02, -2.27e-02,  7.24e-03, -3.79e-03,  0.00e+00,\n",
      "        -1.90e-02, -2.44e-02,  6.11e-03, -2.28e-02, -1.82e-02, -2.13e-02,\n",
      "         3.04e-04, -5.90e-03, -1.93e-02,  7.34e-03],\n",
      "       [ 3.42e-03, -1.20e-02, -8.31e-03,  2.65e-03, -1.39e-03,  0.00e+00,\n",
      "        -6.97e-03, -8.92e-03,  2.24e-03, -8.33e-03, -6.68e-03, -7.81e-03,\n",
      "         1.11e-04, -2.16e-03, -7.05e-03,  2.69e-03],\n",
      "       [ 4.30e-03, -1.50e-02, -1.04e-02,  3.33e-03, -1.75e-03,  0.00e+00,\n",
      "        -8.76e-03, -1.12e-02,  2.81e-03, -1.05e-02, -8.39e-03, -9.81e-03,\n",
      "         1.40e-04, -2.71e-03, -8.86e-03,  3.38e-03],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.23e-02, -7.79e-02, -5.41e-02,  1.73e-02, -9.05e-03,  0.00e+00,\n",
      "        -4.54e-02, -5.81e-02,  1.46e-02, -5.43e-02, -4.35e-02, -5.08e-02,\n",
      "         7.25e-04, -1.41e-02, -4.59e-02,  1.75e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.66e-02, -5.79e-02, -4.03e-02,  1.28e-02, -6.73e-03,  0.00e+00,\n",
      "        -3.38e-02, -4.32e-02,  1.08e-02, -4.04e-02, -3.24e-02, -3.78e-02,\n",
      "         5.40e-04, -1.05e-02, -3.42e-02,  1.30e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 1.55e-02, -5.41e-02, -3.76e-02,  1.20e-02, -6.29e-03,  0.00e+00,\n",
      "        -3.16e-02, -4.04e-02,  1.01e-02, -3.77e-02, -3.02e-02, -3.53e-02,\n",
      "         5.04e-04, -9.78e-03, -3.19e-02,  1.22e-02],\n",
      "       [ 1.46e-02, -5.10e-02, -3.55e-02,  1.13e-02, -5.93e-03,  0.00e+00,\n",
      "        -2.98e-02, -3.81e-02,  9.55e-03, -3.56e-02, -2.85e-02, -3.33e-02,\n",
      "         4.76e-04, -9.22e-03, -3.01e-02,  1.15e-02],\n",
      "       [ 1.55e-02, -5.41e-02, -3.76e-02,  1.20e-02, -6.29e-03,  0.00e+00,\n",
      "        -3.16e-02, -4.04e-02,  1.01e-02, -3.77e-02, -3.02e-02, -3.53e-02,\n",
      "         5.04e-04, -9.78e-03, -3.19e-02,  1.22e-02],\n",
      "       [ 1.44e-02, -5.03e-02, -3.49e-02,  1.11e-02, -5.84e-03,  0.00e+00,\n",
      "        -2.93e-02, -3.75e-02,  9.41e-03, -3.50e-02, -2.81e-02, -3.28e-02,\n",
      "         4.68e-04, -9.08e-03, -2.97e-02,  1.13e-02],\n",
      "       [ 1.59e-02, -5.56e-02, -3.87e-02,  1.23e-02, -6.47e-03,  0.00e+00,\n",
      "        -3.25e-02, -4.15e-02,  1.04e-02, -3.88e-02, -3.11e-02, -3.63e-02,\n",
      "         5.18e-04, -1.01e-02, -3.28e-02,  1.25e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.37e-02, -4.80e-02, -3.33e-02,  1.06e-02, -5.58e-03,  0.00e+00,\n",
      "        -2.80e-02, -3.58e-02,  8.98e-03, -3.34e-02, -2.68e-02, -3.13e-02,\n",
      "         4.47e-04, -8.67e-03, -2.83e-02,  1.08e-02],\n",
      "       [ 1.31e-02, -4.57e-02, -3.17e-02,  1.01e-02, -5.31e-03,  0.00e+00,\n",
      "        -2.66e-02, -3.41e-02,  8.55e-03, -3.18e-02, -2.55e-02, -2.98e-02,\n",
      "         4.26e-04, -8.25e-03, -2.69e-02,  1.03e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 1.61e-02, -5.64e-02, -3.92e-02,  1.25e-02, -6.56e-03,  0.00e+00,\n",
      "        -3.29e-02, -4.21e-02,  1.06e-02, -3.93e-02, -3.15e-02, -3.68e-02,\n",
      "         5.26e-04, -1.02e-02, -3.33e-02,  1.27e-02],\n",
      "       [ 1.88e-02, -6.56e-02, -4.56e-02,  1.45e-02, -7.62e-03,  0.00e+00,\n",
      "        -3.83e-02, -4.90e-02,  1.23e-02, -4.57e-02, -3.66e-02, -4.28e-02,\n",
      "         6.11e-04, -1.19e-02, -3.87e-02,  1.47e-02],\n",
      "       [ 2.14e-02, -7.48e-02, -5.20e-02,  1.66e-02, -8.69e-03,  0.00e+00,\n",
      "        -4.36e-02, -5.58e-02,  1.40e-02, -5.21e-02, -4.18e-02, -4.88e-02,\n",
      "         6.97e-04, -1.35e-02, -4.41e-02,  1.68e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.40e-02, -8.40e-02, -5.84e-02,  1.86e-02, -9.76e-03,  0.00e+00,\n",
      "        -4.90e-02, -6.27e-02,  1.57e-02, -5.85e-02, -4.69e-02, -5.49e-02,\n",
      "         7.83e-04, -1.52e-02, -4.95e-02,  1.89e-02],\n",
      "       [ 2.43e-02, -8.48e-02, -5.89e-02,  1.88e-02, -9.85e-03,  0.00e+00,\n",
      "        -4.94e-02, -6.33e-02,  1.59e-02, -5.91e-02, -4.73e-02, -5.54e-02,\n",
      "         7.90e-04, -1.53e-02, -5.00e-02,  1.91e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.81e-02, -6.33e-02, -4.40e-02,  1.40e-02, -7.36e-03,  0.00e+00,\n",
      "        -3.69e-02, -4.72e-02,  1.18e-02, -4.41e-02, -3.54e-02, -4.13e-02,\n",
      "         5.90e-04, -1.14e-02, -3.73e-02,  1.42e-02],\n",
      "       [ 1.42e-02, -4.95e-02, -3.44e-02,  1.10e-02, -5.75e-03,  0.00e+00,\n",
      "        -2.89e-02, -3.69e-02,  9.27e-03, -3.45e-02, -2.77e-02, -3.23e-02,\n",
      "         4.61e-04, -8.94e-03, -2.92e-02,  1.11e-02],\n",
      "       [ 5.18e-03, -1.81e-02, -1.26e-02,  4.01e-03, -2.10e-03,  0.00e+00,\n",
      "        -1.06e-02, -1.35e-02,  3.39e-03, -1.26e-02, -1.01e-02, -1.18e-02,\n",
      "         1.69e-04, -3.27e-03, -1.07e-02,  4.07e-03],\n",
      "       [ 4.96e-03, -1.73e-02, -1.20e-02,  3.84e-03, -2.01e-03,  0.00e+00,\n",
      "        -1.01e-02, -1.29e-02,  3.24e-03, -1.21e-02, -9.67e-03, -1.13e-02,\n",
      "         1.61e-04, -3.13e-03, -1.02e-02,  3.89e-03],\n",
      "       [ 1.97e-02, -6.87e-02, -4.77e-02,  1.52e-02, -7.98e-03,  0.00e+00,\n",
      "        -4.01e-02, -5.12e-02,  1.29e-02, -4.79e-02, -3.84e-02, -4.48e-02,\n",
      "         6.40e-04, -1.24e-02, -4.05e-02,  1.54e-02],\n",
      "       [ 2.40e-02, -8.40e-02, -5.84e-02,  1.86e-02, -9.76e-03,  0.00e+00,\n",
      "        -4.90e-02, -6.27e-02,  1.57e-02, -5.85e-02, -4.69e-02, -5.49e-02,\n",
      "         7.83e-04, -1.52e-02, -4.95e-02,  1.89e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.05e-02, -7.17e-02, -4.99e-02,  1.59e-02, -8.34e-03,  0.00e+00,\n",
      "        -4.18e-02, -5.35e-02,  1.34e-02, -5.00e-02, -4.01e-02, -4.68e-02,\n",
      "         6.68e-04, -1.30e-02, -4.23e-02,  1.61e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 2.08e-02, -7.25e-02, -5.04e-02,  1.61e-02, -8.43e-03,  0.00e+00,\n",
      "        -4.23e-02, -5.41e-02,  1.36e-02, -5.05e-02, -4.05e-02, -4.73e-02,\n",
      "         6.75e-04, -1.31e-02, -4.28e-02,  1.63e-02],\n",
      "       [ 1.99e-02, -6.94e-02, -4.83e-02,  1.54e-02, -8.07e-03,  0.00e+00,\n",
      "        -4.05e-02, -5.18e-02,  1.30e-02, -4.84e-02, -3.88e-02, -4.53e-02,\n",
      "         6.47e-04, -1.25e-02, -4.10e-02,  1.56e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 1.90e-02, -6.64e-02, -4.61e-02,  1.47e-02, -7.71e-03,  0.00e+00,\n",
      "        -3.87e-02, -4.95e-02,  1.24e-02, -4.63e-02, -3.71e-02, -4.33e-02,\n",
      "         6.18e-04, -1.20e-02, -3.92e-02,  1.49e-02],\n",
      "       [ 1.94e-02, -6.79e-02, -4.72e-02,  1.51e-02, -7.89e-03,  0.00e+00,\n",
      "        -3.96e-02, -5.07e-02,  1.27e-02, -4.73e-02, -3.79e-02, -4.43e-02,\n",
      "         6.33e-04, -1.23e-02, -4.01e-02,  1.53e-02],\n",
      "       [ 1.86e-02, -6.48e-02, -4.51e-02,  1.44e-02, -7.54e-03,  0.00e+00,\n",
      "        -3.78e-02, -4.84e-02,  1.21e-02, -4.52e-02, -3.62e-02, -4.23e-02,\n",
      "         6.04e-04, -1.17e-02, -3.82e-02,  1.46e-02],\n",
      "       [ 1.77e-02, -6.18e-02, -4.29e-02,  1.37e-02, -7.18e-03,  0.00e+00,\n",
      "        -3.60e-02, -4.61e-02,  1.16e-02, -4.31e-02, -3.45e-02, -4.03e-02,\n",
      "         5.76e-04, -1.12e-02, -3.64e-02,  1.39e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.07e-02, -3.72e-02, -2.59e-02,  8.26e-03, -4.33e-03,  0.00e+00,\n",
      "        -2.17e-02, -2.78e-02,  6.97e-03, -2.60e-02, -2.08e-02, -2.43e-02,\n",
      "         3.47e-04, -6.73e-03, -2.20e-02,  8.37e-03],\n",
      "       [ 5.62e-03, -1.96e-02, -1.36e-02,  4.35e-03, -2.28e-03,  0.00e+00,\n",
      "        -1.14e-02, -1.46e-02,  3.67e-03, -1.37e-02, -1.10e-02, -1.28e-02,\n",
      "         1.83e-04, -3.54e-03, -1.16e-02,  4.41e-03],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.45e-02, -8.55e-02, -5.94e-02,  1.90e-02, -9.94e-03,  0.00e+00,\n",
      "        -4.99e-02, -6.38e-02,  1.60e-02, -5.96e-02, -4.78e-02, -5.59e-02,\n",
      "         7.97e-04, -1.55e-02, -5.05e-02,  1.92e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.12e-02, -7.40e-02, -5.14e-02,  1.64e-02, -8.60e-03,  0.00e+00,\n",
      "        -4.32e-02, -5.52e-02,  1.39e-02, -5.16e-02, -4.14e-02, -4.83e-02,\n",
      "         6.90e-04, -1.34e-02, -4.37e-02,  1.66e-02],\n",
      "       [ 2.16e-02, -7.56e-02, -5.25e-02,  1.68e-02, -8.78e-03,  0.00e+00,\n",
      "        -4.41e-02, -5.64e-02,  1.41e-02, -5.27e-02, -4.22e-02, -4.93e-02,\n",
      "         7.04e-04, -1.37e-02, -4.46e-02,  1.70e-02],\n",
      "       [ 2.21e-02, -7.71e-02, -5.36e-02,  1.71e-02, -8.96e-03,  0.00e+00,\n",
      "        -4.50e-02, -5.75e-02,  1.44e-02, -5.37e-02, -4.31e-02, -5.03e-02,\n",
      "         7.18e-04, -1.39e-02, -4.55e-02,  1.73e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.19e-02, -7.63e-02, -5.30e-02,  1.69e-02, -8.87e-03,  0.00e+00,\n",
      "        -4.45e-02, -5.70e-02,  1.43e-02, -5.32e-02, -4.26e-02, -4.98e-02,\n",
      "         7.11e-04, -1.38e-02, -4.50e-02,  1.72e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.47e-02, -8.63e-02, -6.00e-02,  1.91e-02, -1.00e-02,  0.00e+00,\n",
      "        -5.03e-02, -6.44e-02,  1.62e-02, -6.01e-02, -4.82e-02, -5.64e-02,\n",
      "         8.04e-04, -1.56e-02, -5.09e-02,  1.94e-02],\n",
      "       [ 2.56e-02, -8.93e-02, -6.21e-02,  1.98e-02, -1.04e-02,  0.00e+00,\n",
      "        -5.21e-02, -6.67e-02,  1.67e-02, -6.23e-02, -4.99e-02, -5.84e-02,\n",
      "         8.33e-04, -1.61e-02, -5.27e-02,  2.01e-02],\n",
      "       [ 2.47e-02, -8.63e-02, -6.00e-02,  1.91e-02, -1.00e-02,  0.00e+00,\n",
      "        -5.03e-02, -6.44e-02,  1.62e-02, -6.01e-02, -4.82e-02, -5.64e-02,\n",
      "         8.04e-04, -1.56e-02, -5.09e-02,  1.94e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 2.01e-02, -7.02e-02, -4.88e-02,  1.56e-02, -8.16e-03,  0.00e+00,\n",
      "        -4.10e-02, -5.24e-02,  1.31e-02, -4.89e-02, -3.92e-02, -4.58e-02,\n",
      "         6.54e-04, -1.27e-02, -4.14e-02,  1.58e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.92e-02, -6.71e-02, -4.67e-02,  1.49e-02, -7.80e-03,  0.00e+00,\n",
      "        -3.92e-02, -5.01e-02,  1.26e-02, -4.68e-02, -3.75e-02, -4.38e-02,\n",
      "         6.26e-04, -1.21e-02, -3.96e-02,  1.51e-02],\n",
      "       [ 1.83e-02, -6.41e-02, -4.45e-02,  1.42e-02, -7.45e-03,  0.00e+00,\n",
      "        -3.74e-02, -4.78e-02,  1.20e-02, -4.47e-02, -3.58e-02, -4.18e-02,\n",
      "         5.97e-04, -1.16e-02, -3.78e-02,  1.44e-02],\n",
      "       [ 1.64e-02, -5.72e-02, -3.97e-02,  1.27e-02, -6.64e-03,  0.00e+00,\n",
      "        -3.34e-02, -4.27e-02,  1.07e-02, -3.98e-02, -3.19e-02, -3.73e-02,\n",
      "         5.33e-04, -1.03e-02, -3.37e-02,  1.29e-02],\n",
      "       [ 7.37e-03, -2.57e-02, -1.79e-02,  5.71e-03, -2.99e-03,  0.00e+00,\n",
      "        -1.50e-02, -1.92e-02,  4.82e-03, -1.79e-02, -1.44e-02, -1.68e-02,\n",
      "         2.40e-04, -4.65e-03, -1.52e-02,  5.79e-03],\n",
      "       [ 2.03e-02, -7.10e-02, -4.93e-02,  1.57e-02, -8.25e-03,  0.00e+00,\n",
      "        -4.14e-02, -5.30e-02,  1.33e-02, -4.95e-02, -3.96e-02, -4.63e-02,\n",
      "         6.61e-04, -1.28e-02, -4.19e-02,  1.60e-02],\n",
      "       [ 2.51e-02, -8.78e-02, -6.10e-02,  1.95e-02, -1.02e-02,  0.00e+00,\n",
      "        -5.12e-02, -6.55e-02,  1.64e-02, -6.12e-02, -4.91e-02, -5.74e-02,\n",
      "         8.18e-04, -1.59e-02, -5.18e-02,  1.97e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.43e-02, -8.48e-02, -5.89e-02,  1.88e-02, -9.85e-03,  0.00e+00,\n",
      "        -4.94e-02, -6.33e-02,  1.59e-02, -5.91e-02, -4.73e-02, -5.54e-02,\n",
      "         7.90e-04, -1.53e-02, -5.00e-02,  1.91e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.45e-02, -8.55e-02, -5.94e-02,  1.90e-02, -9.94e-03,  0.00e+00,\n",
      "        -4.99e-02, -6.38e-02,  1.60e-02, -5.96e-02, -4.78e-02, -5.59e-02,\n",
      "         7.97e-04, -1.55e-02, -5.05e-02,  1.92e-02],\n",
      "       [ 2.36e-02, -8.25e-02, -5.73e-02,  1.83e-02, -9.58e-03,  0.00e+00,\n",
      "        -4.81e-02, -6.15e-02,  1.54e-02, -5.75e-02, -4.61e-02, -5.39e-02,\n",
      "         7.68e-04, -1.49e-02, -4.86e-02,  1.85e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.27e-02, -7.94e-02, -5.52e-02,  1.76e-02, -9.23e-03,  0.00e+00,\n",
      "        -4.63e-02, -5.93e-02,  1.49e-02, -5.53e-02, -4.43e-02, -5.18e-02,\n",
      "         7.40e-04, -1.43e-02, -4.68e-02,  1.78e-02],\n",
      "       [ 2.25e-02, -7.86e-02, -5.46e-02,  1.74e-02, -9.14e-03,  0.00e+00,\n",
      "        -4.59e-02, -5.87e-02,  1.47e-02, -5.48e-02, -4.39e-02, -5.13e-02,\n",
      "         7.33e-04, -1.42e-02, -4.64e-02,  1.77e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.30e-02, -8.02e-02, -5.57e-02,  1.78e-02, -9.32e-03,  0.00e+00,\n",
      "        -4.68e-02, -5.98e-02,  1.50e-02, -5.59e-02, -4.48e-02, -5.23e-02,\n",
      "         7.47e-04, -1.45e-02, -4.73e-02,  1.80e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 2.38e-02, -8.32e-02, -5.78e-02,  1.85e-02, -9.67e-03,  0.00e+00,\n",
      "        -4.86e-02, -6.21e-02,  1.56e-02, -5.80e-02, -4.65e-02, -5.44e-02,\n",
      "         7.75e-04, -1.50e-02, -4.91e-02,  1.87e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 2.34e-02, -8.17e-02, -5.68e-02,  1.81e-02, -9.50e-03,  0.00e+00,\n",
      "        -4.77e-02, -6.10e-02,  1.53e-02, -5.69e-02, -4.56e-02, -5.34e-02,\n",
      "         7.61e-04, -1.48e-02, -4.82e-02,  1.84e-02],\n",
      "       [ 2.43e-02, -8.48e-02, -5.89e-02,  1.88e-02, -9.85e-03,  0.00e+00,\n",
      "        -4.94e-02, -6.33e-02,  1.59e-02, -5.91e-02, -4.73e-02, -5.54e-02,\n",
      "         7.90e-04, -1.53e-02, -5.00e-02,  1.91e-02],\n",
      "       [ 2.49e-02, -8.71e-02, -6.05e-02,  1.93e-02, -1.01e-02,  0.00e+00,\n",
      "        -5.08e-02, -6.50e-02,  1.63e-02, -6.07e-02, -4.86e-02, -5.69e-02,\n",
      "         8.11e-04, -1.57e-02, -5.14e-02,  1.96e-02],\n",
      "       [ 2.45e-02, -8.55e-02, -5.94e-02,  1.90e-02, -9.94e-03,  0.00e+00,\n",
      "        -4.99e-02, -6.38e-02,  1.60e-02, -5.96e-02, -4.78e-02, -5.59e-02,\n",
      "         7.97e-04, -1.55e-02, -5.05e-02,  1.92e-02],\n",
      "       [ 2.32e-02, -8.09e-02, -5.62e-02,  1.79e-02, -9.41e-03,  0.00e+00,\n",
      "        -4.72e-02, -6.04e-02,  1.51e-02, -5.64e-02, -4.52e-02, -5.29e-02,\n",
      "         7.54e-04, -1.46e-02, -4.77e-02,  1.82e-02],\n",
      "       [ 5.71e-02, -1.99e-01, -1.39e-01,  4.42e-02, -2.32e-02,  0.00e+00,\n",
      "        -1.16e-01, -1.49e-01,  3.73e-02, -1.39e-01, -1.11e-01, -1.30e-01,\n",
      "         1.86e-03, -3.60e-02, -1.18e-01,  4.48e-02]])]\n"
     ]
    }
   ],
   "source": [
    "full_connected_NN_Momentum = full_connected_NN_Momentum(bias=True,network_structure=[1024,16, 10], learning_rate=0.2)\n",
    "full_connected_NN_Momentum.initlize_momentum(X_training_scaled[0], y_training_one_hot[0])\n",
    "print(full_connected_NN_Momentum.previousGradients)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/douglas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:183: RuntimeWarning: divide by zero encountered in log\n",
      "/home/douglas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:183: RuntimeWarning: invalid value encountered in multiply\n",
      "/home/douglas/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:7: RuntimeWarning: invalid value encountered in subtract\n",
      "  import sys\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicted [[0. 0. 0. 0. 0. 1. 0. 0. 0. 0.]]\n",
      "Iteration 120 -  loss: nan, accuracy: 0.08\n",
      "Predicted [[nan nan nan nan nan nan nan nan nan nan]]\n",
      "Iteration 240 -  loss: nan, accuracy: 0.19\n",
      "Predicted [[nan nan nan nan nan nan nan nan nan nan]]\n",
      "Iteration 360 -  loss: nan, accuracy: 0.19\n",
      "Predicted [[nan nan nan nan nan nan nan nan nan nan]]\n",
      "Iteration 480 -  loss: nan, accuracy: 0.19\n",
      "Predicted [[nan nan nan nan nan nan nan nan nan nan]]\n",
      "Iteration 600 -  loss: nan, accuracy: 0.19\n",
      "Predicted [[nan nan nan nan nan nan nan nan nan nan]]\n",
      "Iteration 720 -  loss: nan, accuracy: 0.19\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-114-cf96fc35441f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfull_connected_NN_Momentum\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_training_one_hot\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintermediate_results\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-112-443fde34a6e8>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self, data_array, labels_one_hot_array, batch_size, epochs, intermediate_results)\u001b[0m\n\u001b[1;32m    231\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miteration_count\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0;36m120\u001b[0m \u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;31m#We pick an iteration number to save the loss abnd accuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    232\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 233\u001b[0;31m                     \u001b[0mpredicted\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_training_scaled\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# get network ouput\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    234\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-112-443fde34a6e8>\u001b[0m in \u001b[0;36mfeedForward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     87\u001b[0m             \u001b[0mz\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0min_vector\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweights_matrices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlayer_index\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 89\u001b[0;31m             \u001b[0ma\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mz\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m#sigmoid activation function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     91\u001b[0m             \u001b[0min_vector\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0ma\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2089\u001b[0m             \u001b[0mvargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0m_n\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0m_n\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2091\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_vectorize_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mvargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2092\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2093\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_get_ufunc_and_otypes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/numpy/lib/function_base.py\u001b[0m in \u001b[0;36m_vectorize_call\u001b[0;34m(self, func, args)\u001b[0m\n\u001b[1;32m   2165\u001b[0m                       for a in args]\n\u001b[1;32m   2166\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2167\u001b[0;31m             \u001b[0moutputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2169\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mufunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnout\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-27-454940e3c5d0>\u001b[0m in \u001b[0;36mReLU\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mReLU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmaximum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0.0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;31m#derivation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m@\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvectorize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "full_connected_NN_Momentum.train(X_training_scaled, y_training_one_hot,batch_size=5, epochs=50, intermediate_results=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
